{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7vWEEU2Blld"
      },
      "source": [
        "## Installs and API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F1KstXXstz-u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "OPENAI_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RdooGk5wBw9y",
        "outputId": "3f9b53bc-fc46-4075-9df0-238def065cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (0.31.2)\n",
            "Requirement already satisfied: langchain in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.25)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.17)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.24)\n",
            "Requirement already satisfied: langchain_core in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.3.60)\n",
            "Requirement already satisfied: langchain_huggingface in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: langchain_experimental in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.3.4)\n",
            "Requirement already satisfied: langgraph in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.4.5)\n",
            "Requirement already satisfied: duckduckgo-search>=2.9.5 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (8.0.2)\n",
            "Requirement already satisfied: deep-translator in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: openai in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (1.78.1)\n",
            "Requirement already satisfied: wikipedia in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (2.2.5)\n",
            "Requirement already satisfied: nltk in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.9.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (4.51.3)\n",
            "Requirement already satisfied: accelerate in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (1.7.0)\n",
            "Requirement already satisfied: transformers_stream_generator in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.0.5)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (0.9.0)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 20)) (1.11.0)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from -r requirements.txt (line 21)) (8.1.7)\n",
            "Requirement already satisfied: filelock in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from huggingface_hub->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_community->-r requirements.txt (line 4)) (3.11.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_community->-r requirements.txt (line 4)) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_community->-r requirements.txt (line 4)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_community->-r requirements.txt (line 4)) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_community->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_core->-r requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_huggingface->-r requirements.txt (line 6)) (0.21.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain_huggingface->-r requirements.txt (line 6)) (4.1.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 8)) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 8)) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 8)) (0.1.69)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: click>=8.1.8 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from duckduckgo-search>=2.9.5->-r requirements.txt (line 9)) (8.2.0)\n",
            "Requirement already satisfied: primp>=0.15.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from duckduckgo-search>=2.9.5->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from duckduckgo-search>=2.9.5->-r requirements.txt (line 9)) (5.4.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from deep-translator->-r requirements.txt (line 10)) (4.13.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 11)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 13)) (2025.2)\n",
            "Requirement already satisfied: joblib in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from nltk->-r requirements.txt (line 15)) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from nltk->-r requirements.txt (line 15)) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 16)) (0.5.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from accelerate->-r requirements.txt (line 17)) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from accelerate->-r requirements.txt (line 17)) (2.2.0+cu121)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 21)) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 21)) (9.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 21)) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 21)) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 21)) (3.0.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 4)) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator->-r requirements.txt (line 10)) (2.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from click>=8.1.8->duckduckgo-search>=2.9.5->-r requirements.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 11)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.6.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph->-r requirements.txt (line 8)) (1.9.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph-sdk>=0.1.42->langgraph->-r requirements.txt (line 8)) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 13)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->huggingface_hub->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: Pillow in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r requirements.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 17)) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 17)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 17)) (3.1.6)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate->-r requirements.txt (line 17)) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 21)) (0.2.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate->-r requirements.txt (line 17)) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.2.0+cu121 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (2.2.0+cu121)\n",
            "Requirement already satisfied: torchvision==0.17.0+cu121 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (0.17.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.2.0+cu121 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (2.2.0+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (4.13.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torch==2.2.0+cu121) (2025.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torchvision==0.17.0+cu121) (2.2.5)\n",
            "Requirement already satisfied: requests in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torchvision==0.17.0+cu121) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from torchvision==0.17.0+cu121) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from jinja2->torch==2.2.0+cu121) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->torchvision==0.17.0+cu121) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->torchvision==0.17.0+cu121) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->torchvision==0.17.0+cu121) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests->torchvision==0.17.0+cu121) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rbrul\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from sympy->torch==2.2.0+cu121) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required dependencies from the requirements file and specific PyTorch versions\n",
        "!pip install torch==2.2.0+cu121 torchvision==0.17.0+cu121 torchaudio==2.2.0+cu121 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"C:\\Users\\rbrul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 638, in run_forever\n",
            "    self._run_once()\n",
            "  File \"C:\\Users\\rbrul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1971, in _run_once\n",
            "    handle._run()\n",
            "  File \"C:\\Users\\rbrul\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\rbrul\\AppData\\Local\\Temp\\ipykernel_34824\\3365633317.py\", line 1, in <module>\n",
            "    import torch\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 1471, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "NVIDIA GeForce RTX 4080 SUPER\n"
          ]
        }
      ],
      "source": [
        "# Verify if CUDA is available and display the GPU name\n",
        "import torch\n",
        "print(torch.cuda.get_device_name(0))  # GPU name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybFHOxdG4oH5"
      },
      "source": [
        "## LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6kKGHx7Tzkyu",
        "outputId": "51059592-534d-4ec8-d600-2178a1cad832"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import from LangChain\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool, DuckDuckGoSearchResults\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain'"
          ]
        }
      ],
      "source": [
        "# Import from LangChain\n",
        "from langchain.tools import Tool, DuckDuckGoSearchResults\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from deep_translator import GoogleTranslator\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import wikipedia\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLY7F_dfbPO5"
      },
      "source": [
        "### QwenCoder Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Yt8ppZfQbV8g",
        "outputId": "14a82a5f-e609-4f33-e0b8-0053f2d36467"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-df9debd22266>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Qwen/Qwen2.5-Coder-7B\"\u001b[0m  \u001b[0;31m# or \"Qwen/Qwen-7B-Instruct\" if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackboneMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeHintParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_json_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m from .doc import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the model\n",
        "model_name = \"Qwen/Qwen2.5-Coder-7B\"  # or \"Qwen/Qwen-7B-Instruct\" if available\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,   # or torch.bfloat16 if your GPU supports it\n",
        "    device_map=\"auto\",           # automatically put on GPU if available\n",
        "    trust_remote_code=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4N-dWclbdOu"
      },
      "outputs": [],
      "source": [
        "# Define a function to interact with the QwenCoder model\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.2,   # low temp = more deterministic, better for code\n",
        "        do_sample=True\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result.split(prompt)[-1].strip()  # Only return the assistant's reply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMXMgHgdbesk"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "code_assistant_tool = Tool(\n",
        "    name=\"LocalCodeAssistant\",\n",
        "    func=local_code_assistant,\n",
        "    description=\"Helps generate, fix, and explain Python code locally using QwenCoder.\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJEVtLkzj4Gt"
      },
      "source": [
        "### Pandas Analysis Tool Logic\n",
        "This section generates a sample dataset and performs basic analysis using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "900Dop0AHBMu",
        "outputId": "d05a6365-31c8-4341-afdd-757a2292324c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First few rows of the generated data:\n",
            "        Date      Make  Model   Color  Year     Price  Mileage  EngineSize  \\\n",
            "0 2022-01-01     Honda    Van   Green  2021  27044.28  78913.0         1.6   \n",
            "1 2022-01-02    Toyota    Van    Blue  2022  70485.31  38172.0         4.0   \n",
            "2 2022-01-03    Nissan  Sedan  Silver  2017  25308.67  40089.0         2.5   \n",
            "3 2022-01-04    Toyota    SUV    Blue  2018  22381.82  50492.0         3.5   \n",
            "4 2022-01-05  Mercedes  Truck   White  2015  53677.16  73909.0         2.5   \n",
            "\n",
            "   FuelEfficiency SalesPerson  \n",
            "0            25.3         Bob  \n",
            "1            22.2         Bob  \n",
            "2            30.0         Eva  \n",
            "3            36.5       David  \n",
            "4            31.2       Alice  \n",
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 10 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   Date            1000 non-null   datetime64[ns]\n",
            " 1   Make            1000 non-null   object        \n",
            " 2   Model           1000 non-null   object        \n",
            " 3   Color           1000 non-null   object        \n",
            " 4   Year            1000 non-null   int64         \n",
            " 5   Price           1000 non-null   float64       \n",
            " 6   Mileage         1000 non-null   float64       \n",
            " 7   EngineSize      1000 non-null   float64       \n",
            " 8   FuelEfficiency  1000 non-null   float64       \n",
            " 9   SalesPerson     1000 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
            "memory usage: 78.3+ KB\n",
            "\n",
            "Summary statistics:\n",
            "                      Date         Year         Price       Mileage  \\\n",
            "count                 1000  1000.000000   1000.000000   1000.000000   \n",
            "mean   2023-05-15 12:00:00  2018.466000  50289.979370  49632.778000   \n",
            "min    2022-01-01 00:00:00  2015.000000  20026.290000      3.000000   \n",
            "25%    2022-09-07 18:00:00  2016.000000  34292.015000  25796.000000   \n",
            "50%    2023-05-15 12:00:00  2018.000000  51101.700000  49894.000000   \n",
            "75%    2024-01-20 06:00:00  2021.000000  64790.772500  72534.500000   \n",
            "max    2024-09-26 00:00:00  2022.000000  79965.470000  99923.000000   \n",
            "std                    NaN     2.327716  17550.072447  28087.847227   \n",
            "\n",
            "        EngineSize  FuelEfficiency  \n",
            "count  1000.000000     1000.000000  \n",
            "mean      2.732000       30.153800  \n",
            "min       1.600000       20.000000  \n",
            "25%       2.000000       25.100000  \n",
            "50%       2.500000       30.100000  \n",
            "75%       3.500000       35.400000  \n",
            "max       4.000000       40.000000  \n",
            "std       0.834249        5.868919  \n"
          ]
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "\n",
        "# Generate sample data\n",
        "n_rows = 1000\n",
        "\n",
        "# Generate dates\n",
        "start_date = datetime(2022, 1, 1)\n",
        "dates = [start_date + timedelta(days=i) for i in range(n_rows)]\n",
        "\n",
        "# Define data categories\n",
        "makes = ['Toyota', 'Honda', 'Ford', 'Chevrolet', 'Nissan', 'BMW', 'Mercedes', 'Audi', 'Hyundai', 'Kia']\n",
        "models = ['Sedan', 'SUV', 'Truck', 'Hatchback', 'Coupe', 'Van']\n",
        "colors = ['Red', 'Blue', 'Black', 'White', 'Silver', 'Gray', 'Green']\n",
        "\n",
        "# Create the dataset\n",
        "data = {\n",
        "    'Date': dates,\n",
        "    'Make': np.random.choice(makes, n_rows),\n",
        "    'Model': np.random.choice(models, n_rows),\n",
        "    'Color': np.random.choice(colors, n_rows),\n",
        "    'Year': np.random.randint(2015, 2023, n_rows),\n",
        "    'Price': np.random.uniform(20000, 80000, n_rows).round(2),\n",
        "    'Mileage': np.random.uniform(0, 100000, n_rows).round(0),\n",
        "    'EngineSize': np.random.choice([1.6, 2.0, 2.5, 3.0, 3.5, 4.0], n_rows),\n",
        "    'FuelEfficiency': np.random.uniform(20, 40, n_rows).round(1),\n",
        "    'SalesPerson': np.random.choice(['Alice', 'Bob', 'Charlie', 'David', 'Eva'], n_rows)\n",
        "}\n",
        "\n",
        "# Create DataFrame and sort by date\n",
        "df = pd.DataFrame(data).sort_values('Date')\n",
        "\n",
        "# Display sample data and statistics\n",
        "print(\"\\nFirst few rows of the generated data:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataFrame info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAvD9wJXIUH_",
        "outputId": "d4e80ef5-bcfb-41ee-e1f0-737f3f83426e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-3ea9bb3d3ba5>:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY),\n"
          ]
        }
      ],
      "source": [
        "pandas_agent = create_pandas_dataframe_agent(\n",
        "    ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY),\n",
        "    df,\n",
        "    verbose=True,\n",
        "    allow_dangerous_code=True,  # Only set this if you're comfortable with code execution\n",
        "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-PR34eQfv1V"
      },
      "source": [
        "### DuckDuckGo Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgcGGWw3fT75"
      },
      "outputs": [],
      "source": [
        "search = DuckDuckGoSearchResults()\n",
        "class SummarizeText(BaseModel):\n",
        "    \"\"\"Model for text to be summarized.\"\"\"\n",
        "    text: str = Field(..., title=\"Text to summarize\", description=\"The text to be summarized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTay7Kn1fA3W"
      },
      "outputs": [],
      "source": [
        "def parse_search_results(results_string: str) -> List[dict]:\n",
        "    \"\"\"Parse a string representation of search results into a list of dictionaries.\"\"\"\n",
        "    results = []\n",
        "    entries = results_string.split(', snippet: ')\n",
        "    for entry in entries[1:]:  # Skip the first split as it's empty\n",
        "        parts = entry.split(', title: ')\n",
        "        if len(parts) == 2:\n",
        "            snippet = parts[0]\n",
        "            title_link = parts[1].split(', link: ')\n",
        "            if len(title_link) == 2:\n",
        "                title, link = title_link\n",
        "                results.append({\n",
        "                    'snippet': snippet,\n",
        "                    'title': title,\n",
        "                    'link': link\n",
        "                })\n",
        "    return results\n",
        "\n",
        "def perform_web_search(query: str, specific_site: Optional[str] = None) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"Perform a web search based on a query, optionally including a specific website.\"\"\"\n",
        "    try:\n",
        "        if specific_site:\n",
        "            specific_query = f\"site:{specific_site} {query}\"\n",
        "            print(f\"Searching for: {specific_query}\")\n",
        "            specific_results = search.run(specific_query)\n",
        "            print(f\"Specific search results: {specific_results}\")\n",
        "            specific_parsed = parse_search_results(specific_results)\n",
        "\n",
        "            general_query = f\"-site:{specific_site} {query}\"\n",
        "            print(f\"Searching for: {general_query}\")\n",
        "            general_results = search.run(general_query)\n",
        "            print(f\"General search results: {general_results}\")\n",
        "            general_parsed = parse_search_results(general_results)\n",
        "\n",
        "            combined_results = (specific_parsed + general_parsed)[:3]\n",
        "        else:\n",
        "            print(f\"Searching for: {query}\")\n",
        "            web_results = search.run(query)\n",
        "            print(f\"Web results: {web_results}\")\n",
        "            combined_results = parse_search_results(web_results)[:3]\n",
        "\n",
        "        web_knowledge = [result.get('snippet', '') for result in combined_results]\n",
        "        sources = [(result.get('title', 'Untitled'), result.get('link', '')) for result in combined_results]\n",
        "\n",
        "        print(f\"Processed web_knowledge: {web_knowledge}\")\n",
        "        print(f\"Processed sources: {sources}\")\n",
        "        return web_knowledge, sources\n",
        "    except Exception as e:\n",
        "        print(f\"Error in perform_web_search: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return [], []\n",
        "\n",
        "def summarize_text(text: str, source: Tuple[str, str]) -> str:\n",
        "    \"\"\"Summarize the given text using OpenAI's language model.\"\"\"\n",
        "    try:\n",
        "        # Instantiate your ChatOpenAI with a desired model and temperature.\n",
        "        llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\",openai_api_key=OPENAI_API_KEY)\n",
        "        prompt_template = \"Please summarize the following text in a listed bullet point format:\\n\\n{text}\\n\\nSummary:\"\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"text\"],\n",
        "        )\n",
        "        # Chain the prompt with the LLM (here we use a simple invocation)\n",
        "        summary_chain = prompt | llm\n",
        "        input_data = {\"text\": text}\n",
        "        summary = summary_chain.invoke(input_data)\n",
        "\n",
        "        # If the summary has a content attribute, use it; otherwise convert to string.\n",
        "        summary_content = summary.content if hasattr(summary, 'content') else str(summary)\n",
        "        formatted_summary = f\"Source: {source[0]} ({source[1]})\\n{summary_content.strip()}\\n\"\n",
        "        return formatted_summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error in summarize_text: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def search_summarize(query: str, specific_site: Optional[str] = None) -> str:\n",
        "    \"\"\"Perform a web search and summarize the results.\"\"\"\n",
        "    web_knowledge, sources = perform_web_search(query, specific_site)\n",
        "\n",
        "    if not web_knowledge or not sources:\n",
        "        print(\"No web knowledge or sources found.\")\n",
        "        return \"\"\n",
        "\n",
        "    # Create a list of summaries—only add non-empty summaries\n",
        "    summaries = []\n",
        "    for knowledge, source in zip(web_knowledge, sources):\n",
        "        summary = summarize_text(knowledge, source)\n",
        "        if summary:\n",
        "            summaries.append(summary)\n",
        "\n",
        "    combined_summary = \"\\n\".join(summaries)\n",
        "    return combined_summary\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Wrap the above `search_summarize` function as a LangChain Tool\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "duckduckgo_search_summarize_tool = Tool(\n",
        "    name=\"DuckDuckGoSearchSummarize\",\n",
        "    func=search_summarize,\n",
        "    description=(\n",
        "        \"Performs a web search using DuckDuckGo based on the input query \"\n",
        "        \"and summarizes the top 3 search results using an OpenAI LLM. \"\n",
        "        \"Optionally, you can restrict the search to a specific site by providing the 'specific_site' parameter.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vJCfbr5gDcJ"
      },
      "source": [
        "### Inital Tools Test and Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVql3NjEzgzH"
      },
      "outputs": [],
      "source": [
        "# Calculator Tool (basic arithmetic)\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    try:\n",
        "        result = eval(expression)  # In production, consider a safer math parser.\n",
        "        return f\"The result of '{expression}' is {result}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression '{expression}': {e}\"\n",
        "\n",
        "calculator = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=calculator_tool,\n",
        "    description=\"Evaluates simple mathematical expressions, e.g. '2+2'.\"\n",
        ")\n",
        "\n",
        "# Python Code Execution Tool\n",
        "def code_execution_tool(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes Python code in a restricted environment.\n",
        "    WARNING: Using exec can be a security risk. Use a sandbox in production.\n",
        "    \"\"\"\n",
        "    import io\n",
        "    import contextlib\n",
        "\n",
        "    output_buffer = io.StringIO()\n",
        "    try:\n",
        "        with contextlib.redirect_stdout(output_buffer):\n",
        "            exec(code, {\"__builtins__\": {}})\n",
        "        return output_buffer.getvalue() or \"Code executed successfully with no output.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {str(e)}\"\n",
        "\n",
        "code_executor = Tool(\n",
        "    name=\"CodeExecutor\",\n",
        "    func=code_execution_tool,\n",
        "    description=\"Executes a snippet of Python code and returns its output. Use carefully!\"\n",
        ")\n",
        "\n",
        "# Wikipedia Summary Tool\n",
        "def wikipedia_tool(query: str) -> str:\n",
        "    try:\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve Wikipedia summary for '{query}': {str(e)}\"\n",
        "\n",
        "wikipedia_search = Tool(\n",
        "    name=\"WikipediaSearch\",\n",
        "    func=wikipedia_tool,\n",
        "    description=\"Looks up a summary of a topic using Wikipedia.\"\n",
        ")\n",
        "\n",
        "# Translation Tool (using deep-translator)\n",
        "def translation_tool(text: str, target_language: str = \"en\") -> str:\n",
        "    try:\n",
        "        translated_text = GoogleTranslator(source='auto', target=target_language).translate(text)\n",
        "        return f\"Translated text: {translated_text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {str(e)}\"\n",
        "\n",
        "translator = Tool(\n",
        "    name=\"Translator\",\n",
        "    func=translation_tool,\n",
        "    description=\"Translates the given text into a specified language (default is English).\"\n",
        ")\n",
        "\n",
        "# Sentiment Analysis Tool (simple keyword-based approach)\n",
        "def sentiment_analysis_tool(text: str) -> str:\n",
        "    lower_text = text.lower()\n",
        "    if any(word in lower_text for word in [\"happy\", \"excellent\", \"great\", \"good\"]):\n",
        "        return \"Positive sentiment detected.\"\n",
        "    elif any(word in lower_text for word in [\"sad\", \"bad\", \"terrible\", \"awful\"]):\n",
        "        return \"Negative sentiment detected.\"\n",
        "    else:\n",
        "        return \"Neutral or no clear sentiment detected.\"\n",
        "\n",
        "sentiment_analyzer = Tool(\n",
        "    name=\"SentimentAnalysis\",\n",
        "    func=sentiment_analysis_tool,\n",
        "    description=\"Analyzes the sentiment of a given text (positive, negative, or neutral).\"\n",
        ")\n",
        "\n",
        "\n",
        "def pandas_analysis_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool calls the Pandas DataFrame agent with a natural language query.\n",
        "    Returns the agent's response as a string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = pandas_agent.run(query)\n",
        "        return str(response)\n",
        "    except Exception as e:\n",
        "        return f\"Error in Pandas DataFrame tool: {str(e)}\"\n",
        "\n",
        "pandas_tool = Tool(\n",
        "    name=\"PandasDataAnalysis\",\n",
        "    func=pandas_analysis_tool,\n",
        "    description=(\n",
        "        \"Use this tool to ask questions about the loaded Pandas DataFrame. \"\n",
        "        \"For example, you can filter, describe statistics, or transform the data.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "duckduckgo_search_summarize_tool = Tool(\n",
        "    name=\"DuckDuckGoSearchSummarize\",\n",
        "    func=search_summarize,\n",
        "    description=(\n",
        "        \"Performs a web search using DuckDuckGo based on the input query \"\n",
        "        \"and summarizes the top 3 search results using an OpenAI LLM. \"\n",
        "        \"Optionally, you can restrict the search to a specific site by providing the 'specific_site' parameter.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# --- 3. Combine Tools into a Single Agent -------------------------------------\n",
        "\n",
        "tools = [\n",
        "    calculator,\n",
        "    code_executor,\n",
        "    wikipedia_search,\n",
        "    translator,\n",
        "    sentiment_analyzer,\n",
        "    pandas_tool,\n",
        "    duckduckgo_search_summarize_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Gy0oth0RDf"
      },
      "outputs": [],
      "source": [
        "# Initialize the OpenAI language model with your API key.\n",
        "# Replace 'your_openai_api_key_here' with your actual API key.\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize the agent with the provided tool and language model.\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    allow_dangerous_code=True,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # ReAct agent\n",
        "    verbose=True,  # see chain-of-thought reasoning\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CgzeT7uIeoa0"
      },
      "outputs": [],
      "source": [
        "query = (\n",
        "        \"\"\"\n",
        "        1) Calculate 3*7.\n",
        "        2) Check a brief Wikipedia summary about 'Large language models'.\n",
        "        3) Translate the summary to Spanish.\n",
        "        4) Analyze if the text is positive or negative.\n",
        "        5) Summarize it in 1 paragraph.\n",
        "        6) Then show me a simulated web search on that topic.\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "print(\"USER QUERY:\", query)\n",
        "result = agent.run(query)\n",
        "print(\"\\nAGENT RESULT:\\n\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lpWjsHVf2T_u"
      },
      "outputs": [],
      "source": [
        "\n",
        "query = (\n",
        "    \"\"\"\n",
        "    \"Search online the benefits of renewable energy\"\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"USER QUERY:\", query)\n",
        "result = agent.run(query)\n",
        "print(\"\\nAGENT RESULT:\\n\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks7Q5-uV1GZX"
      },
      "source": [
        "### Tree Of Thought Simple Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyDx-Zi91Kbc"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "import os\n",
        "from typing import List\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# -------------------------------\n",
        "# Reasoner Agent: Generate Multiple Reasoning Paths\n",
        "# -------------------------------\n",
        "def generate_reasoning_paths(query: str, num_paths: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generates multiple distinct reasoning paths for a given query.\n",
        "    Uses a Tree-of-Thought style prompt to have the LLM propose different paths.\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(temperature=0.7, model=\"gpt-4\", openai_api_key=OPENAI_API_KEY)\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=(\n",
        "            \"You are a reasoning agent. Given the following query: '{query}', \"\n",
        "            \"generate {num_paths} distinct reasoning paths. \"\n",
        "            \"For each path, include detailed chain-of-thought steps and a final answer. \"\n",
        "            \"Format your response as follows:\\n\\n\"\n",
        "            \"Path 1:\\n<reasoning steps>\\nAnswer: <final answer>\\n\\n\"\n",
        "            \"Path 2:\\n<reasoning steps>\\nAnswer: <final answer>\\n\\n\"\n",
        "            \"Path 3:\\n<reasoning steps>\\nAnswer: <final answer>\\n\\n\"\n",
        "            \"Ensure each path is logically sound.\"\n",
        "        ),\n",
        "        input_variables=[\"query\", \"num_paths\"]\n",
        "    )\n",
        "    prompt = prompt_template.format(query=query, num_paths=num_paths)\n",
        "    response = llm.predict(prompt)\n",
        "    # Assume the response is structured with \"Path 1:\" markers\n",
        "    paths = []\n",
        "    for segment in response.split(\"Path \"):\n",
        "        segment = segment.strip()\n",
        "        if segment:\n",
        "            # Prepend \"Path \" back to each segment for clarity\n",
        "            paths.append(\"Path \" + segment)\n",
        "    return paths[:num_paths]\n",
        "\n",
        "# -------------------------------\n",
        "# Thought Validator Agent: Validate Reasoning\n",
        "# -------------------------------\n",
        "def validate_reasoning_path(reasoning: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validates a reasoning path using a dedicated prompt.\n",
        "    Returns True if the reasoning is valid, or False otherwise.\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(temperature=0.5, model=\"gpt-4\", openai_api_key=OPENAI_API_KEY)\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=(\n",
        "            \"You are a Thought Validator. Evaluate the following reasoning chain \"\n",
        "            \"and determine if it is logically sound, factually accurate, and complete.\\n\\n\"\n",
        "            \"Reasoning:\\n{reasoning}\\n\\n\"\n",
        "            \"Respond with only 'Valid' if the reasoning is acceptable, or 'Invalid' if it is not, \"\n",
        "            \"followed by a brief explanation.\"\n",
        "        ),\n",
        "        input_variables=[\"reasoning\"]\n",
        "    )\n",
        "    prompt = prompt_template.format(reasoning=reasoning)\n",
        "    validation_response = llm.predict(prompt)\n",
        "    # If response starts with \"Valid\" (ignore case), then consider it valid\n",
        "    if validation_response.strip().lower().startswith(\"valid\"):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# -------------------------------\n",
        "# Combined Multi-Agent ToT Reasoner with Thought Validator\n",
        "# -------------------------------\n",
        "def multi_agent_tot_reasoner(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Orchestrates the multi-agent Tree-of-Thought reasoning process:\n",
        "      1. Generates multiple reasoning paths for the query.\n",
        "      2. Validates each path.\n",
        "      3. Selects a consensus (first valid) path.\n",
        "      4. Returns a detailed output showing all reasoning paths along with their validation status,\n",
        "         the chosen consensus path, and the final answer extracted from that path.\n",
        "    \"\"\"\n",
        "    # Generate multiple reasoning paths\n",
        "    paths = generate_reasoning_paths(query, num_paths=3)\n",
        "\n",
        "    # Validate each path and record its status (True=Valid, False=Invalid)\n",
        "    valid_flags = []\n",
        "    for path in paths:\n",
        "        is_valid = validate_reasoning_path(path)\n",
        "        valid_flags.append(is_valid)\n",
        "\n",
        "    # Select the first valid path; if none are valid, choose the first path as a fallback\n",
        "    consensus_idx = None\n",
        "    for i, valid in enumerate(valid_flags):\n",
        "        if valid:\n",
        "            consensus_idx = i\n",
        "            break\n",
        "    if consensus_idx is None:\n",
        "        consensus_idx = 0  # Fallback if no path is valid\n",
        "\n",
        "    consensus_path = paths[consensus_idx]\n",
        "\n",
        "    # Extract the final answer from the consensus path\n",
        "    # Look for a line that starts with \"Answer:\" (case-insensitive)\n",
        "    final_answer = \"No final answer found.\"\n",
        "    for line in consensus_path.splitlines():\n",
        "        if line.strip().lower().startswith(\"answer:\"):\n",
        "            final_answer = line.split(\"Answer:\", 1)[1].strip()\n",
        "            break\n",
        "\n",
        "    # Build a string that includes all paths and marks each as VALID/INVALID\n",
        "    all_paths_str = \"\"\n",
        "    for i, (path, is_valid) in enumerate(zip(paths, valid_flags), start=1):\n",
        "        status = \"VALID\" if is_valid else \"INVALID\"\n",
        "        all_paths_str += f\"--- Path {i} ({status}) ---\\n{path}\\n\\n\"\n",
        "\n",
        "    result = (\n",
        "        f\"All Generated Reasoning Paths:\\n{all_paths_str}\"\n",
        "        f\"--- Consensus Path (Path {consensus_idx+1}) ---\\n{consensus_path}\\n\\n\"\n",
        "        f\"Final Answer: {final_answer}\"\n",
        "    )\n",
        "    return result\n",
        "\n",
        "# -------------------------------\n",
        "# Wrap as a LangChain Tool\n",
        "# -------------------------------\n",
        "tot_reasoner_tool = Tool(\n",
        "    name=\"MultiAgentToTReasoner\",\n",
        "    func=multi_agent_tot_reasoner,\n",
        "    description=(\n",
        "        \"A multi-agent Tree-of-Thought reasoning tool with a Thought Validator. \"\n",
        "        \"Generates multiple reasoning paths for a given query, validates them, \"\n",
        "        \"and returns all paths (with their VALID/INVALID status), along with a consensus reasoning \"\n",
        "        \"and the final answer extracted from it.\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgtepEIS2W-4"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Example Integration into a LangChain Agent\n",
        "# -------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Set your API key here or use your environment configuration\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "    # Example query for complex reasoning\n",
        "    query = \"How can I optimize a sorting algorithm in Python for large datasets?\"\n",
        "    answer = tot_reasoner_tool.func(query)\n",
        "    print(\"Multi-Agent ToT Reasoner Tool Output:\\n\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHffMEPtASPt"
      },
      "source": [
        "### Memory Types Testing - Episodic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbUqdT9IZ4o5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Any, Dict, List\n",
        "from taskweaver.agent import Agent as TaskWeaverAgent\n",
        "from langchain import LLMChain\n",
        "from langchain.schema import BaseMemory\n",
        "from langchain.memory import ConversationBufferMemory, CombinedMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, AgentType, Tool\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# --- Define your tools -----------------------------------------------------\n",
        "\n",
        "# Calculator Tool (basic arithmetic)\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    try:\n",
        "        result = eval(expression)  # In production, consider a safer math parser.\n",
        "        return f\"The result of '{expression}' is {result}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression '{expression}': {e}\"\n",
        "\n",
        "calculator = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=calculator_tool,\n",
        "    description=\"Evaluates simple mathematical expressions, e.g. '2+2'.\"\n",
        ")\n",
        "\n",
        "# Python Code Execution Tool\n",
        "def code_execution_tool(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes Python code in a restricted environment.\n",
        "    WARNING: Using exec can be a security risk. Use a sandbox in production.\n",
        "    \"\"\"\n",
        "    import io\n",
        "    import contextlib\n",
        "\n",
        "    output_buffer = io.StringIO()\n",
        "    try:\n",
        "        with contextlib.redirect_stdout(output_buffer):\n",
        "            exec(code, {\"__builtins__\": {}})\n",
        "        return output_buffer.getvalue() or \"Code executed successfully with no output.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {str(e)}\"\n",
        "\n",
        "code_executor = Tool(\n",
        "    name=\"CodeExecutor\",\n",
        "    func=code_execution_tool,\n",
        "    description=\"Executes a snippet of Python code and returns its output. Use carefully!\"\n",
        ")\n",
        "\n",
        "# Wikipedia Summary Tool\n",
        "def wikipedia_tool(query: str) -> str:\n",
        "    try:\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve Wikipedia summary for '{query}': {str(e)}\"\n",
        "\n",
        "wikipedia_search = Tool(\n",
        "    name=\"WikipediaSearch\",\n",
        "    func=wikipedia_tool,\n",
        "    description=\"Looks up a summary of a topic using Wikipedia.\"\n",
        ")\n",
        "\n",
        "# Translation Tool (using deep-translator)\n",
        "def translation_tool(text: str, target_language: str = \"en\") -> str:\n",
        "    try:\n",
        "        translated_text = GoogleTranslator(source='auto', target=target_language).translate(text)\n",
        "        return f\"Translated text: {translated_text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {str(e)}\"\n",
        "\n",
        "translator = Tool(\n",
        "    name=\"Translator\",\n",
        "    func=translation_tool,\n",
        "    description=\"Translates the given text into a specified language (default is English).\"\n",
        ")\n",
        "\n",
        "# Sentiment Analysis Tool (simple keyword-based approach)\n",
        "def sentiment_analysis_tool(text: str) -> str:\n",
        "    lower_text = text.lower()\n",
        "    if any(word in lower_text for word in [\"happy\", \"excellent\", \"great\", \"good\"]):\n",
        "        return \"Positive sentiment detected.\"\n",
        "    elif any(word in lower_text for word in [\"sad\", \"bad\", \"terrible\", \"awful\"]):\n",
        "        return \"Negative sentiment detected.\"\n",
        "    else:\n",
        "        return \"Neutral or no clear sentiment detected.\"\n",
        "\n",
        "sentiment_analyzer = Tool(\n",
        "    name=\"SentimentAnalysis\",\n",
        "    func=sentiment_analysis_tool,\n",
        "    description=\"Analyzes the sentiment of a given text (positive, negative, or neutral).\"\n",
        ")\n",
        "\n",
        "\n",
        "def pandas_analysis_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool calls the Pandas DataFrame agent with a natural language query.\n",
        "    Returns the agent's response as a string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = pandas_agent.run(query)\n",
        "        return str(response)\n",
        "    except Exception as e:\n",
        "        return f\"Error in Pandas DataFrame tool: {str(e)}\"\n",
        "\n",
        "pandas_tool = Tool(\n",
        "    name=\"PandasDataAnalysis\",\n",
        "    func=pandas_analysis_tool,\n",
        "    description=(\n",
        "        \"Use this tool to ask questions about the loaded Pandas DataFrame. \"\n",
        "        \"For example, you can filter, describe statistics, or transform the data.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "duckduckgo_search_summarize_tool = Tool(\n",
        "    name=\"DuckDuckGoSearchSummarize\",\n",
        "    func=search_summarize,\n",
        "    description=(\n",
        "        \"Performs a web search using DuckDuckGo based on the input query \"\n",
        "        \"and summarizes the top 3 search results using an OpenAI LLM. \"\n",
        "        \"Optionally, you can restrict the search to a specific site by providing the 'specific_site' parameter.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# --- Combine Tools into a Single Agent -------------------------------------\n",
        "\n",
        "tools = [\n",
        "    calculator,\n",
        "    code_executor,\n",
        "    wikipedia_search,\n",
        "    translator,\n",
        "    sentiment_analyzer,\n",
        "    pandas_tool,\n",
        "    duckduckgo_search_summarize_tool\n",
        "]\n",
        "\n",
        "\n",
        "# --- Long-term Memory & QA Cache Helpers -----------------------------------\n",
        "\n",
        "_long_term_store: Dict[str, List[str]] = {}\n",
        "_qa_cache: Dict[str, str] = {}\n",
        "_qa_embeddings: Dict[str, List[float]] = {}\n",
        "\n",
        "def update_long_term_memory(session_id: str, user_input: str, assistant_output: str) -> None:\n",
        "    mem = _long_term_store.setdefault(session_id, [])\n",
        "    if user_input:\n",
        "        mem.append(f\"User said: {user_input}\")\n",
        "    if assistant_output:\n",
        "        mem.append(f\"Assistant responded: {assistant_output}\")\n",
        "    _long_term_store[session_id] = mem[-10:]\n",
        "\n",
        "def get_long_term_memory(session_id: str) -> str:\n",
        "    return \"\\n\".join(_long_term_store.get(session_id, []))\n",
        "\n",
        "# setup embedding model\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "# --- Implement LongTermChatMemory -----------------------------------------\n",
        "\n",
        "class LongTermChatMemory(BaseMemory):\n",
        "    session_id: str\n",
        "\n",
        "    @property\n",
        "    def memory_key(self) -> str:\n",
        "        return \"long_term_memory\"\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        return [self.memory_key]\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
        "        return {self.memory_key: get_long_term_memory(self.session_id)}\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
        "        update_long_term_memory(\n",
        "            self.session_id,\n",
        "            inputs.get(\"input\", \"\"),\n",
        "            outputs.get(\"output\", \"\"),\n",
        "        )\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        _long_term_store[self.session_id] = []\n",
        "\n",
        "# --- Build CombinedMemory for a single session -----------------------------\n",
        "\n",
        "SESSION_ID = \"user_123\"\n",
        "short_term = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"input\",\n",
        "    return_messages=True,\n",
        ")\n",
        "long_term = LongTermChatMemory(session_id=SESSION_ID)\n",
        "combined_memory = CombinedMemory(memories=[short_term, long_term])\n",
        "\n",
        "# --- Pure Chat LLMChain setup ---------------------------------------------\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    (\"system\", \"Conversation so far:\\n{chat_history}\"),\n",
        "    (\"system\", \"Long‑term memory:\\n{long_term_memory}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "])\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "chat_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    memory=combined_memory,\n",
        ")\n",
        "\n",
        "# --- Initialize the ReAct agent with memory -------------------------------\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    memory=combined_memory,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "     handle_parsing_errors=True,  # allow agent to retry on parse failures\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# --- Dispatcher & Semantic Cache ------------------------------------------\n",
        "\n",
        "TOOL_KEYWORDS = [\n",
        "    \"calculate\", \"translate\", \"search\", \"list\", \"give me\", \"find\",\n",
        "    \"what is\", \"what are\", \"who is\", \"summarize\", \"analyze\",\n",
        "]\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.85\n",
        "\n",
        "def is_tool_query(text: str) -> bool:\n",
        "    low = text.strip().lower()\n",
        "    for kw in TOOL_KEYWORDS:\n",
        "        if low.startswith(kw):\n",
        "            return True\n",
        "    if \";\" in text or \"\\n\" in text:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def find_similar_cached(query: str) -> str:\n",
        "    vec = np.array(embeddings.embed_query(query)).reshape(1, -1)\n",
        "    for orig, orig_vec in _qa_embeddings.items():\n",
        "        sim = cosine_similarity(vec, np.array(orig_vec).reshape(1, -1))[0][0]\n",
        "        if sim >= SIMILARITY_THRESHOLD:\n",
        "            return orig\n",
        "    return None\n",
        "\n",
        "\n",
        "def converse(user_input: str) -> str:\n",
        "    low = user_input.lower().strip()\n",
        "    # memory recall shortcut\n",
        "    if \"remember\" in low or \"previous\" in low or \"asked you\" in low:\n",
        "        memory = get_long_term_memory(SESSION_ID)\n",
        "        return f\"Here's what I remember:\\n{memory}\"\n",
        "\n",
        "    if is_tool_query(user_input):\n",
        "        # semantic cache lookup\n",
        "        similar = find_similar_cached(user_input)\n",
        "        if similar:\n",
        "            return _qa_cache[similar]\n",
        "        # run agent\n",
        "        result = agent.run(user_input)\n",
        "        # cache text and embedding\n",
        "        _qa_cache[user_input] = result\n",
        "        _qa_embeddings[user_input] = embeddings.embed_query(user_input)\n",
        "        return result\n",
        "\n",
        "    # fallback to pure chat\n",
        "    return chat_chain.run(user_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4pE_JuhvrAc"
      },
      "outputs": [],
      "source": [
        "# ————————————————————————————————\n",
        "# 8) Example Usage\n",
        "# ————————————————————————————————\n",
        "\n",
        "print(\"AI:\", converse(\"Do you remember our previous questions?\"))\n",
        "print(\"AGENT:\", converse(\"Search and find me a list of the most popular foods in the world.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knIpUTgj2Bn1"
      },
      "outputs": [],
      "source": [
        "print(\"AGENT:\", converse(\"Do you remember our previous questions?\"))\n",
        "print(\"AGENT:\", converse(\"Search and find me a list of the most popular foods in the world.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkTu9tgb2bY1"
      },
      "outputs": [],
      "source": [
        "print(\"AGENT:\", converse(\"What are the most popular foods you found?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwOGtQjm2s66"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from langgraph.graph import Graph\n",
        "    from IPython.display import Image, display\n",
        "    from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "\n",
        "    # Create a simple Graph to illustrate memory lifecycle\n",
        "    workflow = Graph()\n",
        "\n",
        "    # Node functions operate on a shared state dict\n",
        "    def load_memory(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        # Load from long-term store into state\n",
        "        state['memory'] = get_long_term_memory(SESSION_ID).split(\"\")\n",
        "        return state\n",
        "\n",
        "    def use_memory(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        # Placeholder: use memory in reasoning\n",
        "        return state\n",
        "\n",
        "    def save_memory(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        # Save any updates back to long-term store\n",
        "        update_long_term_memory(SESSION_ID, state.get('input', ''), state.get('output', ''))\n",
        "        return state\n",
        "\n",
        "    # Add nodes and define workflow\n",
        "    workflow.add_node('LoadMemory', load_memory)\n",
        "    workflow.add_node('UseMemory', use_memory)\n",
        "    workflow.add_node('SaveMemory', save_memory)\n",
        "\n",
        "    # Set entry and finish points\n",
        "    workflow.set_entry_point('LoadMemory')\n",
        "    workflow.add_edge('LoadMemory', 'UseMemory')\n",
        "    workflow.add_edge('UseMemory', 'SaveMemory')\n",
        "    workflow.set_finish_point('SaveMemory')\n",
        "\n",
        "    # Compile the workflow (optional)\n",
        "    compiled = workflow.compile()\n",
        "    # Print out the workflow nodes directly from the Graph instance\n",
        "    print('Memory Workflow nodes:', workflow.nodes)\n",
        "\n",
        "except Exception as e:\n",
        "    print('LangGraph Graph unavailable:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2iNi_7SA5JG"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Define the state schema (placeholder fields)\n",
        "class AgentState(TypedDict):\n",
        "    chat_history: List[Any]\n",
        "    long_term_memory: str\n",
        "\n",
        "# Initialize the StateGraph\n",
        "graph_builder = StateGraph(state_schema=AgentState)\n",
        "\n",
        "# 1) Add each tool as a ToolNode\n",
        "for tool in tools:\n",
        "    graph_builder.add_node(tool.name, ToolNode([tool]))\n",
        "\n",
        "# 2) Add memory nodes (loading short- and long-term memory)\n",
        "def load_short_term(state: AgentState) -> AgentState:\n",
        "    state['chat_history'] = short_term.load_memory_variables({})['chat_history']\n",
        "    return state\n",
        "\n",
        "def load_long_term(state: AgentState) -> AgentState:\n",
        "    state['long_term_memory'] = long_term.load_memory_variables({})['long_term_memory']\n",
        "    return state\n",
        "\n",
        "graph_builder.add_node('LoadShortTermMemory', load_short_term)\n",
        "graph_builder.add_node('LoadLongTermMemory', load_long_term)\n",
        "\n",
        "# 3) Add CombinedMemory node which merges both memories\n",
        "def combine_memory(state: AgentState) -> AgentState:\n",
        "    # This node symbolizes the CombinedMemory action\n",
        "    return state\n",
        "\n",
        "graph_builder.add_node('CombineMemory', combine_memory)\n",
        "\n",
        "# 4) Add Agent Initialization node\n",
        "def init_agent(state: AgentState) -> AgentState:\n",
        "    # Placeholder: agent would be initialized with tools and memory here\n",
        "    return state\n",
        "\n",
        "graph_builder.add_node('AgentInit', init_agent)\n",
        "\n",
        "# 5) Define the workflow edges\n",
        "# Start -> load memories\n",
        "graph_builder.add_edge(START, 'LoadShortTermMemory')\n",
        "graph_builder.add_edge(START, 'LoadLongTermMemory')\n",
        "# Memories -> combine\n",
        "graph_builder.add_edge('LoadShortTermMemory', 'CombineMemory')\n",
        "graph_builder.add_edge('LoadLongTermMemory', 'CombineMemory')\n",
        "# Tools feed into agent init\n",
        "for tool in tools:\n",
        "    graph_builder.add_edge(tool.name, 'CombineMemory')\n",
        "# CombinedMemory -> AgentInit\n",
        "graph_builder.add_edge('CombineMemory', 'AgentInit')\n",
        "# AgentInit -> End\n",
        "graph_builder.add_edge('AgentInit', END)\n",
        "\n",
        "compiled = graph_builder.compile(checkpointer=combined_memory)\n",
        "graph = compiled.get_graph()\n",
        "\n",
        "# Render using Mermaid draw method\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    # Render PNG via the API method\n",
        "    png_bytes = graph.draw_mermaid_png(\n",
        "        draw_method=MermaidDrawMethod.API\n",
        "    )\n",
        "    display(Image(png_bytes))\n",
        "except Exception as e:\n",
        "    # Fallback: output Mermaid text source\n",
        "    mermaid_code = graph.draw_mermaid()\n",
        "    print(\"Mermaid source fallback:\", mermaid_code)\n",
        "    print(\"Failed to render PNG:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn2D3A2lGrWh"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/Mermaid_Memory_PNG.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCTPDuPQunjL"
      },
      "source": [
        "## LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DamlE-jWvSos"
      },
      "source": [
        "### Router Logic Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uWlpVVsq2IHE",
        "outputId": "d0092520-abc2-467a-a82b-445b7ecdc6aa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'search_summarize' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-21b875d03e2c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m duckduckgo_search_summarize_tool = Tool(\n\u001b[1;32m    122\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DuckDuckGoSearchSummarize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_summarize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     description=(\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"Performs a web search using DuckDuckGo based on the input query \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'search_summarize' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Any, Dict, List\n",
        "import subprocess\n",
        "from langchain import LLMChain\n",
        "from langchain.schema import BaseMemory\n",
        "from langchain.memory import ConversationBufferMemory, CombinedMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, AgentType, Tool\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from deep_translator import GoogleTranslator\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# --- Define your tools -----------------------------------------------------\n",
        "\n",
        "# Calculator Tool (basic arithmetic)\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    try:\n",
        "        result = eval(expression)  # In production, consider a safer math parser.\n",
        "        return f\"The result of '{expression}' is {result}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression '{expression}': {e}\"\n",
        "\n",
        "calculator = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=calculator_tool,\n",
        "    description=\"Evaluates simple mathematical expressions, e.g. '2+2'.\"\n",
        ")\n",
        "\n",
        "# Python Code Execution Tool\n",
        "def code_execution_tool(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes Python code in a restricted environment.\n",
        "    WARNING: Using exec can be a security risk. Use a sandbox in production.\n",
        "    \"\"\"\n",
        "    import io\n",
        "    import contextlib\n",
        "\n",
        "    output_buffer = io.StringIO()\n",
        "    try:\n",
        "        with contextlib.redirect_stdout(output_buffer):\n",
        "            exec(code, {\"__builtins__\": {}})\n",
        "        return output_buffer.getvalue() or \"Code executed successfully with no output.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {str(e)}\"\n",
        "\n",
        "code_executor = Tool(\n",
        "    name=\"CodeExecutor\",\n",
        "    func=code_execution_tool,\n",
        "    description=\"Executes a snippet of Python code and returns its output. Use carefully!\"\n",
        ")\n",
        "\n",
        "# Wikipedia Summary Tool\n",
        "def wikipedia_tool(query: str) -> str:\n",
        "    try:\n",
        "        summary = wikipedia.summary(query, sentences=2)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve Wikipedia summary for '{query}': {str(e)}\"\n",
        "\n",
        "wikipedia_search = Tool(\n",
        "    name=\"WikipediaSearch\",\n",
        "    func=wikipedia_tool,\n",
        "    description=\"Looks up a summary of a topic using Wikipedia.\"\n",
        ")\n",
        "\n",
        "# Translation Tool (using deep-translator)\n",
        "def translation_tool(text: str, target_language: str = \"en\") -> str:\n",
        "    try:\n",
        "        translated_text = GoogleTranslator(source='auto', target=target_language).translate(text)\n",
        "        return f\"Translated text: {translated_text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {str(e)}\"\n",
        "\n",
        "translator = Tool(\n",
        "    name=\"Translator\",\n",
        "    func=translation_tool,\n",
        "    description=\"Translates the given text into a specified language (default is English).\"\n",
        ")\n",
        "\n",
        "# Sentiment Analysis Tool (simple keyword-based approach)\n",
        "def sentiment_analysis_tool(text: str) -> str:\n",
        "    lower_text = text.lower()\n",
        "    if any(word in lower_text for word in [\"happy\", \"excellent\", \"great\", \"good\"]):\n",
        "        return \"Positive sentiment detected.\"\n",
        "    elif any(word in lower_text for word in [\"sad\", \"bad\", \"terrible\", \"awful\"]):\n",
        "        return \"Negative sentiment detected.\"\n",
        "    else:\n",
        "        return \"Neutral or no clear sentiment detected.\"\n",
        "\n",
        "sentiment_analyzer = Tool(\n",
        "    name=\"SentimentAnalysis\",\n",
        "    func=sentiment_analysis_tool,\n",
        "    description=\"Analyzes the sentiment of a given text (positive, negative, or neutral).\"\n",
        ")\n",
        "\n",
        "\n",
        "def pandas_analysis_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool calls the Pandas DataFrame agent with a natural language query.\n",
        "    Returns the agent's response as a string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = pandas_agent.run(query)\n",
        "        return str(response)\n",
        "    except Exception as e:\n",
        "        return f\"Error in Pandas DataFrame tool: {str(e)}\"\n",
        "\n",
        "pandas_tool = Tool(\n",
        "    name=\"PandasDataAnalysis\",\n",
        "    func=pandas_analysis_tool,\n",
        "    description=(\n",
        "        \"Use this tool to ask questions about the loaded Pandas DataFrame. \"\n",
        "        \"For example, you can filter, describe statistics, or transform the data.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "duckduckgo_search_summarize_tool = Tool(\n",
        "    name=\"DuckDuckGoSearchSummarize\",\n",
        "    func=search_summarize,\n",
        "    description=(\n",
        "        \"Performs a web search using DuckDuckGo based on the input query \"\n",
        "        \"and summarizes the top 3 search results using an OpenAI LLM. \"\n",
        "        \"Optionally, you can restrict the search to a specific site by providing the 'specific_site' parameter.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# code_assistant_tool = Tool(\n",
        "#     name=\"LocalCodeAssistant\",\n",
        "#     func=local_code_assistant,\n",
        "#     description=\"Helps generate, fix, and explain Python code locally using QwenCoder.\"\n",
        "# )\n",
        "\n",
        "\n",
        "# --- Combine Tools into a Single Agent -------------------------------------\n",
        "\n",
        "tools = [\n",
        "    calculator,\n",
        "    code_executor,\n",
        "    wikipedia_search,\n",
        "    translator,\n",
        "    sentiment_analyzer,\n",
        "    pandas_tool,\n",
        "    duckduckgo_search_summarize_tool,\n",
        "    # code_assistant_tool\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn4_Cq4d1nET",
        "outputId": "c1c08d9a-985c-4cb4-f7dc-a546b62044e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 'Calculate 3 * 8'\n",
            "→ Routed to: Calculator\n",
            "→ Output   :\n",
            " The result of '3 * 8' is 24. \n",
            "\n",
            ">>> \"Translate 'hello' to spanish\"\n",
            "→ Routed to: Translator\n",
            "→ Output   :\n",
            " Translated text: Hola \n",
            "\n",
            "Searching for: Check a brief Wikipedia summary about 'Large language models'.\n",
            "Web results: snippet: A large language model is a type of artificial intelligence algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots ..., title: What is a Large Language Model (LLM) - GeeksforGeeks, link: https://www.geeksforgeeks.org/large-language-model-llm/, snippet: Language models serve as a cornerstone in natural language processing, utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has ..., title: History, development, and principles of large language models: an ..., link: https://link.springer.com/article/10.1007/s43681-024-00583-7, snippet: Large language models (LLMs) are AI systems based on transformer architectures and trained on vast amounts of text data to understand and generate human-like text. Using deep learning techniques, LLMs process and produce accurate responses rapidly. ... Let's take a brief tour through the world of large language models. 5 key features and ..., title: 5 key features and benefits of large language models, link: https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/10/09/5-key-features-and-benefits-of-large-language-models/, snippet: The generative AI (gen AI) boom has put a spotlight on the driving force behind it: large language models (LLMs).Dozens of LLMs already exist, but with the technology advancing rapidly, more of these artificial intelligence (AI) models continue to crop up.. Think of it through the lens of the auto industry. Hundreds of car manufacturers across the world have their own models catering to varied ..., title: A List of Large Language Models - IBM, link: https://www.ibm.com/think/topics/large-language-models-list\n",
            "Processed web_knowledge: ['Language models serve as a cornerstone in natural language processing, utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has ...', \"Large language models (LLMs) are AI systems based on transformer architectures and trained on vast amounts of text data to understand and generate human-like text. Using deep learning techniques, LLMs process and produce accurate responses rapidly. ... Let's take a brief tour through the world of large language models. 5 key features and ...\", 'The generative AI (gen AI) boom has put a spotlight on the driving force behind it: large language models (LLMs).Dozens of LLMs already exist, but with the technology advancing rapidly, more of these artificial intelligence (AI) models continue to crop up.. Think of it through the lens of the auto industry. Hundreds of car manufacturers across the world have their own models catering to varied ...']\n",
            "Processed sources: [('History, development, and principles of large language models: an ...', 'https://link.springer.com/article/10.1007/s43681-024-00583-7'), ('5 key features and benefits of large language models', 'https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/10/09/5-key-features-and-benefits-of-large-language-models/'), ('A List of Large Language Models - IBM', 'https://www.ibm.com/think/topics/large-language-models-list')]\n",
            ">>> \"Check a brief Wikipedia summary about 'Large language models'.\"\n",
            "→ Routed to: WikipediaSearch\n",
            "→ Output   :\n",
            " - Language models are fundamental in natural language processing (NLP).\n",
            "- They apply mathematical methods to generalize language rules and knowledge for prediction and generation.\n",
            "- Research in language modeling has advanced significantly over decades.\n",
            "- Progression from early statistical language models to modern large language models (LLMs) is notable.\n",
            "- The rapid evolution of LLMs is a key highlight in the field.\n",
            "- Large language models (LLMs) are AI systems utilizing transformer architectures.\n",
            "- They are trained on extensive text data to comprehend and generate human-like text.\n",
            "- LLMs employ deep learning techniques for efficient processing and rapid response generation.\n",
            "- The text introduces a brief overview of LLMs and highlights five key features.\n",
            "- The generative AI boom highlights the importance of large language models (LLMs).\n",
            "- Numerous LLMs are currently available, with more continuously being developed.\n",
            "- The rapid advancement of technology contributes to the proliferation of these AI models.\n",
            "- The situation can be compared to the auto industry, where many car manufacturers offer diverse models to meet different needs. \n",
            "\n",
            ">>> 'What are the most popular foods in the world?'\n",
            "→ Routed to: WikipediaSearch\n",
            "→ Output   :\n",
            " This is a categorically organized list of foods. Food is any substance consumed to provide nutritional support for the body. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict, Any, Dict\n",
        "import re\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# --- State schema -------------------------------------------------------------\n",
        "class RouterState(TypedDict):\n",
        "    input: str\n",
        "    decision: str\n",
        "    output: Any\n",
        "\n",
        "# --- 1) Routing logic ---------------------------------------------------------\n",
        "def llm_call_router(state: RouterState) -> RouterState:\n",
        "    text = state[\"input\"].strip().lower()\n",
        "    if text.startswith(\"calculate\") or re.match(r\"^[0-9+\\-*/\\s\\.]+$\", text):\n",
        "        state[\"decision\"] = \"Calculator\"\n",
        "    elif text.startswith(\"translate\"):\n",
        "        state[\"decision\"] = \"Translator\"\n",
        "    elif \"sql\" in text or \"database\" in text:\n",
        "        state[\"decision\"] = \"PandasDataAnalysis\"\n",
        "    elif \"summary\" in text or text.startswith(\"give me a summary\"):\n",
        "        state[\"decision\"] = \"WikipediaSearch\"\n",
        "    elif text.startswith((\"search\", \"find\", \"what is\")):\n",
        "        state[\"decision\"] = \"DuckDuckGoSearchSummarize\"\n",
        "    elif any(keyword in text for keyword in [\"write a function\", \"python code\", \"fix this code\", \"explain this code\", \"Write a Python function\"]):\n",
        "        state[\"decision\"] = \"CodeAssistant\"\n",
        "    else:\n",
        "        state[\"decision\"] = \"WikipediaSearch\"\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "# --- 2) Tool runners ---------------------------------------------------------\n",
        "\n",
        "def run_Calculator(state: RouterState) -> RouterState:\n",
        "    expr = re.sub(r'^(calculate|calc)\\s+', '', state[\"input\"], flags=re.IGNORECASE)\n",
        "    state[\"output\"] = calculator_tool(expr)\n",
        "    return state\n",
        "\n",
        "def run_Translator(state: RouterState) -> RouterState:\n",
        "    m = re.match(r'translate\\s+[\\'\"](.+?)[\\'\"]\\s+to\\s+(\\w+)', state[\"input\"], flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        txt, lang = m.group(1), m.group(2)\n",
        "    else:\n",
        "        txt, lang = state[\"input\"], \"en\"\n",
        "    state[\"output\"] = translation_tool(txt, lang)\n",
        "    return state\n",
        "\n",
        "def run_CodeExecutor(state: RouterState) -> RouterState:\n",
        "    state[\"output\"] = code_execution_tool(state[\"input\"])\n",
        "    return state\n",
        "\n",
        "def run_WikipediaSearch(state: RouterState) -> RouterState:\n",
        "    # strip off any “give me a summary on” prefix\n",
        "    topic = re.sub(r'^(give me a summary (on|of)\\s+)', '', state[\"input\"], flags=re.IGNORECASE)\n",
        "    summary = wikipedia_tool(topic)\n",
        "    if summary.startswith(\"Could not retrieve\"):\n",
        "        # fallback to web search bullets\n",
        "        raw = search_summarize(topic)\n",
        "        bullets = [line for line in raw.splitlines() if line.strip().startswith(\"-\")]\n",
        "        state[\"output\"] = \"\\n\".join(bullets) or raw\n",
        "    else:\n",
        "        state[\"output\"] = summary\n",
        "    return state\n",
        "\n",
        "def run_SentimentAnalysis(state: RouterState) -> RouterState:\n",
        "    state[\"output\"] = sentiment_analysis_tool(state[\"input\"])\n",
        "    return state\n",
        "\n",
        "def run_PandasDataAnalysis(state: RouterState) -> RouterState:\n",
        "    state[\"output\"] = pandas_analysis_tool(state[\"input\"])\n",
        "    return state\n",
        "\n",
        "def run_DuckDuckGoSearchSummarize(state: RouterState) -> RouterState:\n",
        "    raw = search_summarize(state[\"input\"])\n",
        "    # only keep the bullet points\n",
        "    bullets = [line for line in raw.splitlines() if line.strip().startswith(\"-\")]\n",
        "    state[\"output\"] = \"\\n\".join(bullets) or raw\n",
        "    return state\n",
        "\n",
        "def run_CodeAssistant(state: RouterState) -> RouterState:\n",
        "    state[\"output\"] = code_assistant_tool(state[\"input\"])\n",
        "    return state\n",
        "\n",
        "\n",
        "# Map tool names to runner functions\n",
        "tool_funcs = {\n",
        "    \"Calculator\": run_Calculator,\n",
        "    \"Translator\": run_Translator,\n",
        "    \"CodeExecutor\": run_CodeExecutor,\n",
        "    \"WikipediaSearch\": run_WikipediaSearch,\n",
        "    \"SentimentAnalysis\": run_SentimentAnalysis,\n",
        "    \"PandasDataAnalysis\": run_PandasDataAnalysis,\n",
        "    \"DuckDuckGoSearchSummarize\": run_DuckDuckGoSearchSummarize,\n",
        "    \"CodeAssistant\": run_CodeAssistant,\n",
        "}\n",
        "\n",
        "\n",
        "# --- 3) Build & wire the router ----------------------------------------------\n",
        "router_builder = StateGraph(state_schema=RouterState)\n",
        "\n",
        "router_builder.add_node(\"llm_call_router\", llm_call_router)\n",
        "for name, fn in tool_funcs.items():\n",
        "    router_builder.add_node(name, fn)\n",
        "\n",
        "router_builder.add_edge(START, \"llm_call_router\")\n",
        "router_builder.add_conditional_edges(\n",
        "    \"llm_call_router\",\n",
        "    lambda st: st[\"decision\"],\n",
        "    {name: name for name in tool_funcs},\n",
        ")\n",
        "for name in tool_funcs:\n",
        "    router_builder.add_edge(name, END)\n",
        "router_builder.set_entry_point(\"llm_call_router\")\n",
        "\n",
        "# --- 4) Compile & test -------------------------------------------------------\n",
        "router_workflow = router_builder.compile()\n",
        "\n",
        "tests = [\n",
        "    \"Calculate 3 * 8\",\n",
        "    \"Translate 'hello' to spanish\",\n",
        "    \"Check a brief Wikipedia summary about 'Large language models'.\",\n",
        "    \"What are the most popular foods in the world?\",\n",
        "    # \"Write a function that creates a square in my output\"\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    state = router_workflow.invoke({\"input\": q})\n",
        "    print(f\">>> {q!r}\")\n",
        "    print(\"→ Routed to:\", state[\"decision\"])\n",
        "    print(\"→ Output   :\\n\", state[\"output\"], \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "3V2-u4rkPcTg",
        "outputId": "a1866ab4-7f02-4b21-df48-d6a1c78f447e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/Router-Logic-Test.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvz_OT72Po43"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y10gUF6E5m9v"
      },
      "source": [
        "### Router Logic With Memory - Episodic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ihUerQY7QeE"
      },
      "outputs": [],
      "source": [
        "# agent_router_with_memory.py\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import Any, Dict, List, TypedDict\n",
        "\n",
        "from langchain import LLMChain\n",
        "from langchain.schema import BaseMemory\n",
        "from langchain.memory import ConversationBufferMemory, CombinedMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import Tool\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 1) Define your tools\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    try:\n",
        "        return f\"The result of '{expr}' is {eval(expr)}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating '{expr}': {e}\"\n",
        "\n",
        "calculator = Tool(\"Calculator\", calculator_tool, \"Basic math operations\")\n",
        "\n",
        "\n",
        "def code_execution_tool(code: str) -> str:\n",
        "    import io, contextlib\n",
        "    buf = io.StringIO()\n",
        "    try:\n",
        "        with contextlib.redirect_stdout(buf):\n",
        "            exec(code, {\"__builtins__\": {}})\n",
        "        return buf.getvalue() or \"No output.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "code_executor = Tool(\"CodeExecutor\", code_execution_tool, \"Executes Python code\")\n",
        "\n",
        "\n",
        "def wikipedia_tool(q: str) -> str:\n",
        "    try:\n",
        "        import wikipedia\n",
        "        return wikipedia.summary(q, sentences=2)\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve Wikipedia summary for '{q}': {e}\"\n",
        "\n",
        "wikipedia_search = Tool(\"WikipediaSearch\", wikipedia_tool, \"Wiki lookup\")\n",
        "\n",
        "\n",
        "def translation_tool(text: str, target_language: str = \"en\") -> str:\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=\"auto\", target=target_language).translate(text)\n",
        "        return f\"Translated text: {translated}\"\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {e}\"\n",
        "\n",
        "translator = Tool(\"Translator\", translation_tool, \"Translate text\")\n",
        "\n",
        "\n",
        "def sentiment_analysis_tool(text: str) -> str:\n",
        "    low = text.lower()\n",
        "    if any(w in low for w in [\"happy\",\"great\",\"good\",\"excellent\"]):\n",
        "        return \"Positive sentiment detected.\"\n",
        "    if any(w in low for w in [\"sad\",\"bad\",\"terrible\",\"awful\"]):\n",
        "        return \"Negative sentiment detected.\"\n",
        "    return \"Neutral sentiment detected.\"\n",
        "\n",
        "sentiment_analyzer = Tool(\"SentimentAnalysis\", sentiment_analysis_tool, \"Detect sentiment\")\n",
        "\n",
        "\n",
        "def pandas_analysis_tool(q: str) -> str:\n",
        "    try:\n",
        "        return str(pandas_agent.run(q))  # assume pandas_agent is in scope\n",
        "    except Exception as e:\n",
        "        return f\"Pandas error: {e}\"\n",
        "\n",
        "pandas_tool = Tool(\"PandasDataAnalysis\", pandas_analysis_tool, \"Query DataFrame\")\n",
        "\n",
        "\n",
        "def duckduckgo_search_summarize(q: str) -> str:\n",
        "    return search_summarize(q)  # assume search_summarize is in scope\n",
        "\n",
        "duckduckgo_tool = Tool(\n",
        "    \"DuckDuckGoSearchSummarize\",\n",
        "    duckduckgo_search_summarize,\n",
        "    \"Web search summary\"\n",
        ")\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 1.a) Local QwenCoder lazy‐loader\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "_tokenizer = None\n",
        "_model     = None\n",
        "\n",
        "def ensure_coder_loaded():\n",
        "    global _tokenizer, _model\n",
        "    if _model is None:\n",
        "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "        import torch\n",
        "        model_name = \"Qwen/Qwen2.5-Coder-7B\"\n",
        "        _tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name, trust_remote_code=True\n",
        "        )\n",
        "        _model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "\n",
        "def qwen_code_assistant(prompt: str) -> str:\n",
        "    ensure_coder_loaded()\n",
        "    # encode + infer\n",
        "    inputs  = _tokenizer(prompt, return_tensors=\"pt\").to(_model.device)\n",
        "    outputs = _model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.2,\n",
        "        do_sample=True\n",
        "    )\n",
        "    text = _tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return text.split(prompt, 1)[-1].strip()\n",
        "\n",
        "code_assistant_tool = Tool(\n",
        "    \"CodeAssistant\",\n",
        "    qwen_code_assistant,\n",
        "    \"Local code help using QwenCoder\"\n",
        ")\n",
        "\n",
        "\n",
        "TOOLS = [\n",
        "    calculator,\n",
        "    code_executor,\n",
        "    wikipedia_search,\n",
        "    translator,\n",
        "    sentiment_analyzer,\n",
        "    pandas_tool,\n",
        "    duckduckgo_tool,\n",
        "    code_assistant_tool,\n",
        "]\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 2) Episodic Memory & Semantic Cache\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "_long_term: Dict[str, List[str]]   = {}\n",
        "_qa_cache: Dict[str, str]          = {}\n",
        "_qa_embeds: Dict[str, List[float]] = {}\n",
        "\n",
        "SESSION_ID = \"user_123\"\n",
        "\n",
        "def update_long_term_memory(user: str, inp: str, outp: str):\n",
        "    mem = _long_term.setdefault(user, [])\n",
        "    if inp:  mem.append(f\"User: {inp}\")\n",
        "    if outp: mem.append(f\"Bot:  {outp}\")\n",
        "    _long_term[user] = mem[-10:]\n",
        "\n",
        "def get_long_term_memory(user: str) -> str:\n",
        "    return \"\\n\".join(_long_term.get(user, []))\n",
        "\n",
        "\n",
        "class LongTermChatMemory(BaseMemory):\n",
        "    session_id: str\n",
        "\n",
        "    @property\n",
        "    def memory_key(self) -> str:\n",
        "        return \"long_term_memory\"\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        return [self.memory_key]\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
        "        return {self.memory_key: get_long_term_memory(self.session_id)}\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
        "        update_long_term_memory(\n",
        "            self.session_id,\n",
        "            inputs.get(\"input\", \"\"),\n",
        "            outputs.get(\"output\", \"\"),\n",
        "        )\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        _long_term[self.session_id] = []\n",
        "\n",
        "\n",
        "EMB = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def find_similar_cached(q: str, threshold: float = 0.85) -> str:\n",
        "    vec = EMB.embed_query(q)\n",
        "    for orig, ov in _qa_embeds.items():\n",
        "        if cosine_similarity([vec], [ov])[0][0] >= threshold:\n",
        "            return orig\n",
        "    return None\n",
        "\n",
        "TOOL_KEYWORDS = [\n",
        "    \"calculate\",\"translate\",\"search\",\"find\",\n",
        "    \"what\",\"give me\",\"list\",\"summarize\",\"analyze\",\n",
        "]\n",
        "def is_tool_query(txt: str) -> bool:\n",
        "    low = txt.lower().strip()\n",
        "    if \";\" in txt or \"\\n\" in txt:\n",
        "        return True\n",
        "    return any(low.startswith(kw) for kw in TOOL_KEYWORDS)\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 3) Build the LangGraph router\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "class RouterState(TypedDict):\n",
        "    input: str\n",
        "    decision: str\n",
        "    output: Any\n",
        "\n",
        "def llm_call_router(state: RouterState) -> RouterState:\n",
        "    t = state[\"input\"].strip().lower()\n",
        "    if t.startswith(\"calculate\"):\n",
        "        state[\"decision\"] = \"Calculator\"\n",
        "    elif t.startswith(\"translate\"):\n",
        "        state[\"decision\"] = \"Translator\"\n",
        "    elif \"sql\" in t or \"database\" in t:\n",
        "        state[\"decision\"] = \"PandasDataAnalysis\"\n",
        "    elif \"summary\" in t or t.startswith(\"give me a summary\"):\n",
        "        state[\"decision\"] = \"WikipediaSearch\"\n",
        "    elif any(t.startswith(k) for k in [\"search\",\"find\",\"what are\",\"what is\"]) or \"popular\" in t:\n",
        "        state[\"decision\"] = \"DuckDuckGoSearchSummarize\"\n",
        "    elif any(k in t for k in [\"function\",\"python code\",\"fix this code\",\"explain this code\"]):\n",
        "        state[\"decision\"] = \"CodeAssistant\"\n",
        "    else:\n",
        "        state[\"decision\"] = \"WikipediaSearch\"\n",
        "    return state\n",
        "\n",
        "def run_Calculator(state: RouterState) -> RouterState:\n",
        "    expr = re.sub(r'^(calculate|calc)\\s+', '', state[\"input\"], flags=re.IGNORECASE)\n",
        "    state[\"output\"] = calculator_tool(expr)\n",
        "    return state\n",
        "\n",
        "def run_Translator(state: RouterState) -> RouterState:\n",
        "    m = re.match(r'translate\\s+[\\'\"](.+?)[\\'\"]\\s+to\\s+(\\w+)',\n",
        "                 state[\"input\"], flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        txt, lang = m.group(1), m.group(2)\n",
        "    else:\n",
        "        txt, lang = state[\"input\"], \"en\"\n",
        "    state[\"output\"] = translation_tool(txt, lang)\n",
        "    return state\n",
        "\n",
        "def run_WikipediaSearch(state: RouterState) -> RouterState:\n",
        "    topic = re.sub(r'^(give me a summary (on|of)\\s+)', '',\n",
        "                   state[\"input\"], flags=re.IGNORECASE)\n",
        "    summary = wikipedia_tool(topic)\n",
        "    if summary.startswith(\"Could not retrieve\"):\n",
        "        raw = duckduckgo_search_summarize(topic)\n",
        "        bullets = [L for L in raw.splitlines() if L.strip().startswith(\"-\")]\n",
        "        state[\"output\"] = \"\\n\".join(bullets) or raw\n",
        "    else:\n",
        "        state[\"output\"] = summary\n",
        "    return state\n",
        "\n",
        "def run_CodeAssistant(state: RouterState) -> RouterState:\n",
        "    state[\"output\"] = qwen_code_assistant(state[\"input\"])\n",
        "    return state\n",
        "\n",
        "generic_runners = {\n",
        "    \"CodeExecutor\": code_execution_tool,\n",
        "    \"SentimentAnalysis\": sentiment_analysis_tool,\n",
        "    \"PandasDataAnalysis\": pandas_analysis_tool,\n",
        "    \"DuckDuckGoSearchSummarize\": duckduckgo_search_summarize,\n",
        "}\n",
        "def make_generic(name: str, fn):\n",
        "    def run(state: RouterState) -> RouterState:\n",
        "        state[\"output\"] = fn(state[\"input\"])\n",
        "        return state\n",
        "    return run\n",
        "\n",
        "router = StateGraph(state_schema=RouterState)\n",
        "router.add_node(\"router\", llm_call_router)\n",
        "router.add_node(\"Calculator\", run_Calculator)\n",
        "router.add_node(\"Translator\", run_Translator)\n",
        "router.add_node(\"WikipediaSearch\", run_WikipediaSearch)\n",
        "router.add_node(\"CodeAssistant\", run_CodeAssistant)\n",
        "for nm, fn in generic_runners.items():\n",
        "    router.add_node(nm, make_generic(nm, fn))\n",
        "\n",
        "router.add_edge(START, \"router\")\n",
        "router.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda s: s[\"decision\"],\n",
        "    {nm: nm for nm in [\"Calculator\",\"Translator\",\"WikipediaSearch\",\"CodeAssistant\"] + list(generic_runners.keys())}\n",
        ")\n",
        "for nm in [\"Calculator\",\"Translator\",\"WikipediaSearch\",\"CodeAssistant\"] + list(generic_runners.keys()):\n",
        "    router.add_edge(nm, END)\n",
        "router.set_entry_point(\"router\")\n",
        "router_workflow = router.compile()\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 4) Pure-Chat LLMChain setup\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\"You are a helpful AI assistant.\"),\n",
        "    (\"system\",\"Chat history:\\n{chat_history}\"),\n",
        "    (\"system\",\"Long-term memory:\\n{long_term_memory}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\",\"{input}\"),\n",
        "])\n",
        "LLM = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "short_term = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\", return_messages=True)\n",
        "long_term = LongTermChatMemory(session_id=SESSION_ID)\n",
        "combined_memory = CombinedMemory(memories=[short_term, long_term])\n",
        "chat_chain = LLMChain(prompt=prompt, llm=LLM, memory=combined_memory)\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 5) The unified converse() entrypoint\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "\n",
        "def converse(user_input: str) -> str:\n",
        "    low = user_input.lower().strip()\n",
        "\n",
        "    # recall\n",
        "    if \"remember\" in low:\n",
        "        return \"Memory:\\n\" + get_long_term_memory(SESSION_ID)\n",
        "\n",
        "    # tool queries\n",
        "    if is_tool_query(user_input):\n",
        "        sim = find_similar_cached(user_input)\n",
        "        if sim:\n",
        "            return _qa_cache[sim]\n",
        "\n",
        "        st  = router_workflow.invoke({\"input\": user_input})\n",
        "        out = st[\"output\"]\n",
        "        _qa_cache[user_input]  = out\n",
        "        _qa_embeds[user_input] = EMB.embed_query(user_input)\n",
        "        update_long_term_memory(SESSION_ID, user_input, out)\n",
        "        return out\n",
        "\n",
        "    # pure-chat fallback\n",
        "    out = chat_chain.run(user_input)\n",
        "    update_long_term_memory(SESSION_ID, user_input, out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4151aed2a9734a5582dbd7df78139bd2",
            "7237a44037ed4256944dba035aa64471",
            "1a86a3bb4a494e77a96fef5303c6666e",
            "2ad67425f33144b7b3097a3bd4354f56",
            "9e257f53910947eca7ee84b5a54c0f4c",
            "b12409746a86473eada4edb01cd5abfa",
            "1a640896c15f4b31bc6e18b9b58cbc29",
            "cdc562e6ad08468d9dc1510e1dcae481",
            "0cd617d32f654e3c8caf79617d9475e8",
            "b1804ff9b82b4d18afef7c9dbd78a981",
            "518ae6aa6970405cb70934cf18e966dc",
            "8aec626266cd4c64ad2f10b6ee20bc1f",
            "25c6935d9b4d4633891cc3e6984941b8",
            "e4f975613a294c08a506f6d307bee40d",
            "8323ae8af35b4d1b908073a7d19d20f2",
            "f90bb79b745942e887d1b03e2700379a",
            "984d3d15533c4f6eba793a12f23ff31e",
            "9494e7c04046400b85457f4c6b4c650b",
            "91508574c043447186cae2cbf2c71f48",
            "a3a618a0684c4852945dadc809e94d7e",
            "13458e691bce4e559bc5fab08712a3c7",
            "4563e95c2a8f40b1af8736f35f7a10df"
          ]
        },
        "id": "ksvkudytCDI_",
        "outputId": "c7f00be4-caf7-4959-8f50-f36543953aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 'Calculate 3 * 8'\n",
            "→ Routed to: Calculator\n",
            "→ Output   :\n",
            " The result of '3 * 8' is 24. \n",
            "\n",
            ">>> \"Translate 'hello' to spanish\"\n",
            "→ Routed to: Translator\n",
            "→ Output   :\n",
            " Translated text: Hola \n",
            "\n",
            "Searching for: Check a brief Wikipedia summary about 'Large language models'.\n",
            "Web results: snippet: A large language model is a type of artificial intelligence algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots ..., title: What is a Large Language Model (LLM) - GeeksforGeeks, link: https://www.geeksforgeeks.org/large-language-model-llm/, snippet: Large language models (LLMs) have generated much hype in recent months (see Figure 1). The demand has led to the ongoing development of websites and solutions that leverage language models. ChatGPT set the record for the fastest-growing user base in January 2023, proving that language models are here to stay. This is also shown by the fact that Bard, Google's answer to ChatGPT, was ..., title: Large Language Models: Complete Guide in 2025 - AIMultiple, link: https://research.aimultiple.com/large-language-models/, snippet: Neural networks built upon earlier models by \"learning\" as they processed information, using a node model with artificial neurons. Nodes were activated based on other nodes' output. The first large language models emerged as a consequence of the introduction of transformer models in 2017., title: Large language model | Definition, History, & Facts | Britannica, link: https://www.britannica.com/topic/large-language-model, snippet: One of the most significant developments has been the rise of large language models (LLMs)—powerful models that can easily understand and generate human language. These models have revolutionized various industries, enabling everything from automatic translation and content creation to more sophisticated conversational agents., title: A Brief History of Large Large Language Models (LLMs), link: https://idiotdeveloper.com/a-brief-history-of-large-large-language-models-llms/\n",
            "Processed web_knowledge: [\"Large language models (LLMs) have generated much hype in recent months (see Figure 1). The demand has led to the ongoing development of websites and solutions that leverage language models. ChatGPT set the record for the fastest-growing user base in January 2023, proving that language models are here to stay. This is also shown by the fact that Bard, Google's answer to ChatGPT, was ...\", 'Neural networks built upon earlier models by \"learning\" as they processed information, using a node model with artificial neurons. Nodes were activated based on other nodes\\' output. The first large language models emerged as a consequence of the introduction of transformer models in 2017.', 'One of the most significant developments has been the rise of large language models (LLMs)—powerful models that can easily understand and generate human language. These models have revolutionized various industries, enabling everything from automatic translation and content creation to more sophisticated conversational agents.']\n",
            "Processed sources: [('Large Language Models: Complete Guide in 2025 - AIMultiple', 'https://research.aimultiple.com/large-language-models/'), ('Large language model | Definition, History, & Facts | Britannica', 'https://www.britannica.com/topic/large-language-model'), ('A Brief History of Large Large Language Models (LLMs)', 'https://idiotdeveloper.com/a-brief-history-of-large-large-language-models-llms/')]\n",
            ">>> \"Check a brief Wikipedia summary about 'Large language models'.\"\n",
            "→ Routed to: WikipediaSearch\n",
            "→ Output   :\n",
            " - Large language models (LLMs) have gained significant attention recently.\n",
            "- There is an increasing demand for websites and solutions utilizing language models.\n",
            "- ChatGPT achieved the fastest-growing user base in January 2023.\n",
            "- The popularity of LLMs indicates they are likely to remain relevant.\n",
            "- Google developed Bard as its counterpart to ChatGPT.\n",
            "- Neural networks evolved from earlier models by employing a learning process while processing information.\n",
            "- They utilize a node model featuring artificial neurons.\n",
            "- Nodes activate based on the output of other nodes.\n",
            "- The introduction of transformer models in 2017 led to the development of the first large language models.\n",
            "- Rise of large language models (LLMs) noted as a significant development.\n",
            "- LLMs are powerful models that understand and generate human language.\n",
            "- Revolutionized various industries.\n",
            "- Applications include:\n",
            "  - Automatic translation\n",
            "  - Content creation\n",
            "  - Sophisticated conversational agents \n",
            "\n",
            "Searching for: What are the most popular foods in the world?\n",
            "Web results: snippet: For the \"Top 100 Dishes in the World\" list until April 19, 2025, 632,790 ratings were recorded, of which 408,514 were recognized by the system as legitimate. TasteAtlas Rankings should not be seen as the final global conclusion about food., title: Top 100 Dishes in the World - TasteAtlas, link: https://www.tasteatlas.com/best-rated-dishes-in-the-world, snippet: What is the 10 most popular food in the world? The top 10 most eaten food in the world includes staples like rice, bread, and pasta. These foods are consumed globally and form the base of many diets. Additionally, dishes such as pizza, hamburgers, and sushi are also among the most popular food in the world due to their widespread appeal and ..., title: Top 10 Most Eaten Food In The World - maggiechoos.com, link: https://www.maggiechoos.com/top-10-most-eaten-food-in-the-world/, snippet: A new list reveals the world's most loved dishes, based on the opinions of hundreds of thousands of food lovers. The TasteAtlas Awards 2024/25 has ranked the top 100 foods from across the globe. The results come from 367,847 ratings of over 11,000 traditional meals., title: What Are the 10 Most Loved Foods in the World?, link: https://greekreporter.com/2025/03/22/most-loved-foods-world/, snippet: Determining the absolute \"most popular\" foods is a complex task, as it depends on various factors like cultural preferences, availability, and personal taste. However, based on global consumption, widespread appeal, and consistent mentions across various surveys and lists, here are 10 of the most popular foods in the world:, title: What are the 10 most popular foods in the world? - NCESC, link: https://www.ncesc.com/geographic-faq/what-are-the-10-most-popular-foods-in-the-world/\n",
            "Processed web_knowledge: ['What is the 10 most popular food in the world? The top 10 most eaten food in the world includes staples like rice, bread, and pasta. These foods are consumed globally and form the base of many diets. Additionally, dishes such as pizza, hamburgers, and sushi are also among the most popular food in the world due to their widespread appeal and ...', \"A new list reveals the world's most loved dishes, based on the opinions of hundreds of thousands of food lovers. The TasteAtlas Awards 2024/25 has ranked the top 100 foods from across the globe. The results come from 367,847 ratings of over 11,000 traditional meals.\", 'Determining the absolute \"most popular\" foods is a complex task, as it depends on various factors like cultural preferences, availability, and personal taste. However, based on global consumption, widespread appeal, and consistent mentions across various surveys and lists, here are 10 of the most popular foods in the world:']\n",
            "Processed sources: [('Top 10 Most Eaten Food In The World - maggiechoos.com', 'https://www.maggiechoos.com/top-10-most-eaten-food-in-the-world/'), ('What Are the 10 Most Loved Foods in the World?', 'https://greekreporter.com/2025/03/22/most-loved-foods-world/'), ('What are the 10 most popular foods in the world? - NCESC', 'https://www.ncesc.com/geographic-faq/what-are-the-10-most-popular-foods-in-the-world/')]\n",
            ">>> 'What are the most popular foods in the world?'\n",
            "→ Routed to: DuckDuckGoSearchSummarize\n",
            "→ Output   :\n",
            " Source: Top 10 Most Eaten Food In The World - maggiechoos.com (https://www.maggiechoos.com/top-10-most-eaten-food-in-the-world/)\n",
            "- The top 10 most popular foods globally include staples.\n",
            "- Key staples: rice, bread, and pasta.\n",
            "- These foods form the base of many diets worldwide.\n",
            "- Popular dishes: pizza, hamburgers, and sushi.\n",
            "- Widespread appeal contributes to their popularity.\n",
            "\n",
            "Source: What Are the 10 Most Loved Foods in the World? (https://greekreporter.com/2025/03/22/most-loved-foods-world/)\n",
            "- A new list highlights the world's most loved dishes.\n",
            "- The rankings are from the TasteAtlas Awards 2024/25.\n",
            "- Top 100 foods were selected based on the opinions of food lovers.\n",
            "- Results are based on 367,847 ratings.\n",
            "- Over 11,000 traditional meals were evaluated.\n",
            "\n",
            "Source: What are the 10 most popular foods in the world? - NCESC (https://www.ncesc.com/geographic-faq/what-are-the-10-most-popular-foods-in-the-world/)\n",
            "- Determining the \"most popular\" foods is complex.\n",
            "- Factors influencing popularity include cultural preferences, availability, and personal taste.\n",
            "- Popular foods are identified based on global consumption and widespread appeal.\n",
            "- Consistent mentions in surveys and lists contribute to their popularity.\n",
            "- The text lists 10 of the most popular foods in the world.\n",
            " \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4151aed2a9734a5582dbd7df78139bd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aec626266cd4c64ad2f10b6ee20bc1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 'Write a function that creates a square in my output'\n",
            "→ Routed to: CodeAssistant\n",
            "→ Output   :\n",
            " window. The square should be made up of asterisks (*) and should have a side length of 5. Additionally, the square should be filled with random colors from a predefined list of colors. The function should also allow the user to specify the position of the square within the output window. The position should be specified as a tuple of two integers representing the x and y coordinates of the top-left corner of the square. The function should return the coordinates of the bottom-right corner of the square.\n",
            "\n",
            "Example:\n",
            "Input:\n",
            "create_square((10, 10))\n",
            "\n",
            "Output:\n",
            "The square is created at position (10, 10) and has a side length of 5. The bottom-right corner of the square is at position (15, 15).\n",
            "\n",
            "Note: The output should be displayed in the output window, not returned as a string.\n",
            "Here is a possible implementation of the function in Python:\n",
            "\n",
            "```python\n",
            "import random\n",
            "\n",
            "def create_square(position):\n",
            "    x, y = position\n",
            "    side_length = 5\n",
            "    colors = ['red', 'green', 'blue', 'yellow', 'purple']\n",
            "    \n",
            "    for i in range(side_length):\n",
            "        for j in range(side_length):\n",
            "            color = random.choice(colors)\n",
            "            print(f\"\\033[38;2;{color};48;2;{color}m* \\033[0m\", end=\"\")\n",
            "        print()\n",
            "    \n",
            "    bottom_right_corner = (x + side_length - 1, y + side_length - 1)\n",
            "    print(f\"The square is created at position {position} and has a side length of {side_length}. The bottom-right corner of the square is at position {bottom_right_corner}.\")\n",
            "```\n",
            "\n",
            "In this implementation, we use the `random` module to select a random color from the predefined list of colors. We then use ANSI escape codes to set the text color and background color for each asterisk in the square. The `\\033[38;2;{color};48;2;{color}m` sets the text color and background color to the same color, and `\\033[0m` resets the color to the default.\n",
            "\n",
            "The function takes a `position` parameter, which is a tuple of two integers representing the x and y coordinates of the top-left corner of the square. It then calculates the bottom-right corner of the square by adding the side length minus 1 to the x and y coordinates.\n",
            "\n",
            "Finally, the function prints \n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    for q in [\n",
        "        \"Calculate 3 * 8\",\n",
        "        \"Translate 'hello' to spanish\",\n",
        "        \"Check a brief Wikipedia summary about 'Large language models'.\",\n",
        "        \"What are the most popular foods in the world?\",\n",
        "        \"Write a function that creates a square in my output\"\n",
        "    ]:\n",
        "        st = router_workflow.invoke({\"input\": q})\n",
        "        print(f\">>> {q!r}\")\n",
        "        print(\"→ Routed to:\", st[\"decision\"])\n",
        "        print(\"→ Output   :\\n\", st[\"output\"], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq6Ylgun6onz"
      },
      "source": [
        "### Llama Model Replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "1ea6f6e45ac04b80a96f27aa3b06e531",
            "907f7fa9a2764b1594d0987334491d21",
            "de13f1e46e3a469294c3b2e432d59305",
            "dc357fffea2f4d5b8d2576ad6d126dac",
            "b4ed49941df248d58c35508b56e8f699",
            "5cc3fc4f11dc4dc59095194edfc60a8f",
            "fde27f29082b45729ea5ec4a0b314ea0",
            "4537074db99d429d8ba01d326f7a9eda",
            "092c548443dd400785b3037d11f26c0b",
            "3a116f4260f0404896e62e4400dfcaa6",
            "809ca645768047229cfb293dd6c36804",
            "313138ee3e3e4e4386ca08d13df1b81b",
            "7ec03e6f25cb49c9a5b162a1c9dfbdbf",
            "6d82faf1a6904ddca44282a7ea7dd04b",
            "3929f076b095471d904034eb88c05fbf",
            "7e035a1aad7e47b0a3359b0c2092ceec",
            "16e032370c514232a0f8e565ca0a352e",
            "c515b82692bd4046aedf3b766fbf7d39",
            "2ec5dd85624c47d0a359560740c8c0a6",
            "35965ed47607478dbf1acb5779b03f44"
          ]
        },
        "id": "h6aRZXH3dMc4",
        "outputId": "5f7e3673-1f6c-4b77-eedb-f4cc42bee245"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcfb3201ccf94d4b838de3e73fecca18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login() # paste your token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "8d3c926a8a764cb4bbfefe88c63fe0e5",
            "bc42c94ceaad4ef48bb9ae4e5d408c41",
            "962fa279640f4a43aaf2dff7e40a47f1",
            "e9fb2cb99c46481b932f0b538854aea0",
            "8a6e76cf76d14a1ea5844a9ba17ee25c",
            "01b4126830dc4f54b8972c87467e596a",
            "c0a3b1ee488847a7857c29da93ce3ed5",
            "e898c4b5086b4559b879a9f865c9841e",
            "6ca91b458e9f407f866cdf7d95b50223",
            "e3f49973616042c9ae191fcc640c1db2",
            "34b464c50e1c41549ac286f54ba1bd56",
            "59a6d93b7e2e430f8217a60fa9f641b5",
            "3064a064898147ff90de97f2a48efcb2",
            "f19ee82dd4e146adbebcd67aee8b292d",
            "041deba5e08649c18ce29976a6dc01b1",
            "b333996217974f93840c4259608fac98",
            "76f9ecfaff1f452bb2f9355a7a8e4b9a",
            "276ce81400874e239375508be694b566",
            "6c60944e9b1b4d3c9f0caa6798f7c607",
            "160e3cccc5f54f9aa37e9d2c4f5561fd",
            "160d4aabaecc4bb7a4d0b65e0148b8fa",
            "f775e8e56d524c0381591d505c8e44fe",
            "88cfe2c399e74278b7003efffc30700a",
            "6b2c858d4b1947bd8b692a7f6fbabda4",
            "0eaebcc421fa40abb0d6d33882dfe9b1",
            "9239466fe1034184a37ca027f25339d6",
            "5a9636b2d1c54e51abf0846a954c0ddb",
            "6cb8b66413d7427dbd0c03ce245a8584",
            "66074442522643e78e0906257ba3f272",
            "342dc63c654b452cb1fef1f7176d74c4",
            "1c5d9ae541304ae3b5ba12f70650ac15",
            "7b964f14456a4b57bf3d5bfb5cbdb721",
            "c01c9801b1fb4efc819bf791a935e84c",
            "8b858d02623a4a6b9911ef4c97e4dcae",
            "80f9b5d658444b1b8ea6adb6c32f085a",
            "25cd5f10a66f464c8069cee705c4b685",
            "d974fa183863484a9304460b95fcd8cb",
            "c3feaacb507b4d2b86b563fe8c21a88b",
            "cc1328638f19428380db1b22e7a7291c",
            "6f357b77a6034b4ea250b180c2b496a5",
            "95230a32defa476fa5048a61ca7d60ac",
            "3c344e6f00924c32aa94bbb10cdaa84c",
            "c086f329d5344149a630881df762358f",
            "875931cc2c954eea9b853f349bdc80ed",
            "d23783c7d0a742be83768e98fb5f9c56",
            "fd6ef8f783b64cd5a5595462f6273efb",
            "51a8d32261eb40faba1f986b1cd48b6d",
            "1af76a5387ac49bfb3b8e0ae26fd4ea4",
            "4a0ec43708e049a79909dcdcfc621395",
            "40d709ccd174468a995cc6e0603686c7",
            "ba2c6daa79fc4ee7998f136950f95637",
            "ba36e7f4aedc477482b2a9ca7195e977",
            "a33aa892ec9d44fc81a019585b872c63",
            "77acea273143462d9f46be4dd5c4cfc0",
            "42b8b32c1af347f19c76d39478b183f3",
            "1972fe14f83747a2a31e19242bfc2144",
            "1b35e39737084042baa7f30fc000bcbf",
            "8c9220d775744b3b909d4c767ae5e800",
            "392478b9fd204839b2edd2c8abb9964b",
            "135af3971b134b91928c2f5dde27662e",
            "710133641e1e4331a6b352bde8218ded",
            "f5cf69e91b5e48b9b262ecebb62e76ed",
            "9b2ebe06a5f1497b97703efc90338912",
            "216e525fdc0c49c6b026c783e3e46204",
            "baeae91b7184482c83b2bc39780e9b03",
            "8f25c30e7a5948f6991264d672e53474",
            "55dbb2d8848e42de9dbd5666b85b758d",
            "cc50f4b20e5847d6bd814210c751ac31",
            "503b11916caa4939b3eb0e8156b92ed0",
            "dfe4f7ad54444ff18e3c0d1a5c12e318",
            "a7df713e8fbd49919c8a12a6b6e37f48",
            "3ab8e68f63174cefbfdb1d6c5e4b92ce",
            "f8a6069ac40e485b9e778c756a29a50b",
            "e86d0d99926b47d8bd7698c5de0b5c3c",
            "83a3a4db0dcc41a49727f95ca08e7067",
            "965410f83f7d42d6b1c29d19e29c8ed6",
            "0cf53efbd5a44412b5bf86ab49ff6219",
            "076c01e20ae34c3e9d0256fe2ec7081a",
            "dd3e859522764a4a89b924f5f22d71b6",
            "6322a652148142d084a252d901213bc0",
            "f28730bbf1b14685ac9d3331a1edbb6c",
            "553fd4f7dfc042d98d9d193940b9218a",
            "f3dd3015602f485d99cb81d34290e380",
            "18e24ffbbc4b487ea6c8effe4cdd13f9",
            "70c373de8cac4eba998ceee6a3f44bb8",
            "f7b60e8fb278484bba84bbc181825bf6",
            "66387a54837a4283bf79128b80523444",
            "bbe2fe809e1a43f1a1bf18d914552911",
            "6765b6628c5d48deaf6c15d496648a8f",
            "b2364a15b5aa4d6fa8bb736295a3c4e8",
            "43874c1a2d2343d28f65bbca41558ee2",
            "fcab66aafa3243d0b70a11c95b508087",
            "bb81da29489b4e97a47ce7b9162250eb",
            "7730fd7cbbf44f80a996ad49d347e6f5",
            "a84e2e98134a4cdcb84f7d6a085afdbf",
            "a3171cfff82343eb9f7e0f98df8ee895",
            "0defc8ed7d9848109c81c10bce3e8dd4",
            "b7e82b6d4a5f42139065c96d1b0e8862",
            "539c222985124410b05cd9d0cf11f215",
            "77a57217c14f41ff803b463fac4f9589",
            "d4a1321123bb4927985df361a36c0511",
            "db5073e09eeb471e976ed76ff21db665",
            "8d9d8c10de5e47fbb91dae20d4775f84",
            "252951f7c313483c82a6ba17f2a4c8b5",
            "548259078d2841c98d865ece13ce4030",
            "a2cb4f687daf497293ac49d566990790",
            "803b6dbc1d7e44b78512b9293b7bff7d",
            "ad5160a9de63459f9a4fe0cfb3b99a37",
            "a1b4e3b7df04441082da89c8f3700a93",
            "7151628435d84b789a08c5fa41b2568f"
          ]
        },
        "id": "IHUV4s7l4aHZ",
        "outputId": "8bfc2608-c20e-4045-a189-36a39c887e7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c30ab0c1734218a713ebf8957bcaeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rbrul\\.cache\\huggingface\\hub\\models--meta-llama--Llama-3.2-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fad6ac9b228a43fd9f52d84e249206a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6d0025babb4dfc9aba570a15a677a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fed9aef58ac5408e976e06d1ac9c7497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b38db6b1b0f04316bbe665056bbb34b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b4ece602d914ffda79630efd2d12d66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "898cebdce78546128143d253f225a30e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dad10994e34c44ebbd77d60bcdb42bdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbd8c611ddcf46c6965c8e5d0738a558",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ca12cdb73584a58a2fb3ea506dd40e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict, Any, List\n",
        "import torch\n",
        "import wikipedia\n",
        "\n",
        "# 1. Load your local Llama model (replace with your model directory)\n",
        "model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",      # GPU if available\n",
        "    torch_dtype=torch.float16 # use fp16 where supported\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZlCjyEa6s4P",
        "outputId": "de1b8912-89c5-402a-b0d3-58e0e29ebbb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1634\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_files_only:\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1635\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1636\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m hf.co look-ups and downloads online, set \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlocal_files_only\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1637\u001b[39m     )\n\u001b[32m   1638\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1639\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1640\u001b[39m ):\n\u001b[32m   1641\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n",
            "\u001b[31mLocalEntryNotFoundError\u001b[39m: Cannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable hf.co look-ups and downloads online, set 'local_files_only' to False.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m _qa_cache: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;28mstr\u001b[39m]        = {}\n\u001b[32m     64\u001b[39m _qa_embeds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m,np.ndarray] = {}\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m EMB_MODEL = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_cached\u001b[39m(q: \u001b[38;5;28mstr\u001b[39m, threshold: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.85\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     68\u001b[39m     v = EMB_MODEL.encode(q, convert_to_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:321\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    309\u001b[39m         modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28mself\u001b[39m._load_sbert_model(\n\u001b[32m    310\u001b[39m             model_name_or_path,\n\u001b[32m    311\u001b[39m             token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    318\u001b[39m             config_kwargs=config_kwargs,\n\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         modules = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_auto_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[32m    334\u001b[39m     modules = OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1606\u001b[39m, in \u001b[36mSentenceTransformer._load_auto_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   1603\u001b[39m tokenizer_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m tokenizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **tokenizer_kwargs}\n\u001b[32m   1604\u001b[39m config_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m config_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **config_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m1606\u001b[39m transformer_model = \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1614\u001b[39m pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:80\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     config_args = {}\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m config, is_peft_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mself\u001b[39m._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:145\u001b[39m, in \u001b[36mTransformer._load_config\u001b[39m\u001b[34m(self, model_name_or_path, cache_dir, backend, config_args)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PeftConfig.from_pretrained(model_name_or_path, **config_args, cache_dir=cache_dir), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1114\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1111\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1112\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1116\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:590\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:649\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    645\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    648\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    664\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rbrul\\Documents\\GitHub\\Agent-Tool-Integrations\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:491\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[32m    489\u001b[39m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    492\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load the files, and couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find them in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
            "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
          ]
        }
      ],
      "source": [
        "# llama_agent.py\n",
        "\n",
        "import os\n",
        "from typing import Any, TypedDict\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline, LlamaForCausalLM, LlamaTokenizer\n",
        "from langchain.agents import Tool\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "text_gen = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.9,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 2) Chat generation util\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "def generate_chat(sys_pmt: str, user_msg: str) -> str:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": sys_pmt},\n",
        "        {\"role\": \"user\",   \"content\": user_msg},\n",
        "    ]\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    out = text_gen(\n",
        "        prompt,\n",
        "        max_new_tokens=200,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    return out[0][\"generated_text\"].split(prompt, 1)[1].strip()\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 3) Memory (long-term only)\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "_long_term: dict[str,list[str]] = {}\n",
        "SESSION_ID = \"user_123\"\n",
        "\n",
        "def update_memory(user: str, inp: str, outp: str):\n",
        "    log = _long_term.setdefault(user, [])\n",
        "    if inp:  log.append(f\"User: {inp}\")\n",
        "    if outp: log.append(f\"Bot:  {outp}\")\n",
        "    _long_term[user] = log[-20:]  # keep last 20 lines\n",
        "\n",
        "def get_memory(user: str) -> str:\n",
        "    return \"\\n\".join(_long_term.get(user, []))\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 4) Simple semantic cache (optional)\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "_qa_cache: dict[str,str]        = {}\n",
        "_qa_embeds: dict[str,np.ndarray] = {}\n",
        "EMB_MODEL = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", local_files_only=True)\n",
        "\n",
        "def find_cached(q: str, threshold: float = 0.85) -> str | None:\n",
        "    v = EMB_MODEL.encode(q, convert_to_numpy=True)\n",
        "    for orig, emb in _qa_embeds.items():\n",
        "        if cosine_similarity(v.reshape(1,-1), emb.reshape(1,-1))[0][0] >= threshold:\n",
        "            return orig\n",
        "    return None\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 5) Tools: calculator & sentiment\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    try:\n",
        "        return f\"{expr} = {eval(expr)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Calc error: {e}\"\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    t = text.lower()\n",
        "    if any(w in t for w in (\"happy\",\"good\",\"great\",\"excellent\")):\n",
        "        return \"Positive 👍\"\n",
        "    if any(w in t for w in (\"sad\",\"bad\",\"terrible\",\"awful\")):\n",
        "        return \"Negative 👎\"\n",
        "    return \"Neutral 🤔\"\n",
        "\n",
        "calculator = Tool(\"Calculator\", calculator_tool, \"evaluate arithmetic\")\n",
        "sentiment  = Tool(\"SentimentAnalysis\", sentiment_tool, \"detect sentiment\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 6) Router graph (only 2 tools)\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "class RouterState(TypedDict):\n",
        "    input: str\n",
        "    decision: str\n",
        "    output: Any\n",
        "\n",
        "def router_fn(s: RouterState) -> RouterState:\n",
        "    txt = s[\"input\"].strip().lower()\n",
        "    if txt.startswith(\"calculate\"):\n",
        "        s[\"decision\"] = \"Calculator\"\n",
        "    elif any(w in txt for w in (\"sentiment\",\"happy\",\"sad\")):\n",
        "        s[\"decision\"] = \"SentimentAnalysis\"\n",
        "    else:\n",
        "        s[\"decision\"] = \"Chat\"\n",
        "    return s\n",
        "\n",
        "def run_calc(s: RouterState) -> RouterState:\n",
        "    s[\"output\"] = calculator_tool(s[\"input\"])\n",
        "    return s\n",
        "\n",
        "def run_sent(s: RouterState) -> RouterState:\n",
        "    s[\"output\"] = sentiment_tool(s[\"input\"])\n",
        "    return s\n",
        "\n",
        "router = StateGraph(state_schema=RouterState)\n",
        "router.add_node(\"router\", router_fn)\n",
        "router.add_node(\"Calculator\", run_calc)\n",
        "router.add_node(\"SentimentAnalysis\", run_sent)\n",
        "# Chat node is just a pass–through to fallback\n",
        "router.add_node(\"Chat\", lambda s: s)\n",
        "router.add_edge(START, \"router\")\n",
        "router.add_conditional_edges(\"router\", lambda s: s[\"decision\"], {\n",
        "    \"Calculator\": \"Calculator\",\n",
        "    \"SentimentAnalysis\": \"SentimentAnalysis\",\n",
        "    \"Chat\": \"Chat\"\n",
        "})\n",
        "for node in (\"Calculator\",\"SentimentAnalysis\",\"Chat\"):\n",
        "    router.add_edge(node, END)\n",
        "router.set_entry_point(\"router\")\n",
        "router_workflow = router.compile()\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "# 7) Main converse() with remembering\n",
        "# ——————————————————————————————————————————————————————————————\n",
        "def converse(user_input: str) -> str:\n",
        "    key = user_input.strip()\n",
        "    # check cache\n",
        "    hit = find_cached(key)\n",
        "    if hit:\n",
        "        return _qa_cache[hit]\n",
        "\n",
        "    st = router_workflow.invoke({\"input\": user_input})\n",
        "    decision = st[\"decision\"]\n",
        "    if decision in (\"Calculator\",\"SentimentAnalysis\"):\n",
        "        out = st[\"output\"]\n",
        "    else:\n",
        "        # Chat fallback\n",
        "        mem = get_memory(SESSION_ID)\n",
        "        sys_p = \"You are a helpful assistant.\\nLong-term memory:\\n\" + (mem or \"none\")\n",
        "        out = generate_chat(sys_p, user_input)\n",
        "\n",
        "    # cache & remember\n",
        "    _qa_cache[key]      = out\n",
        "    _qa_embeds[key]     = EMB_MODEL.encode(key, convert_to_numpy=True)\n",
        "    update_memory(SESSION_ID, user_input, out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Routed To",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Output",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "40e00b52-3b5d-4701-8051-7c4f81f82636",
              "rows": [
                [
                  "0",
                  "My name is Alice",
                  "Chat",
                  "Nice to meet you, Alice! Is there something on your mind that you'd like to talk about or ask for help with? I'm all ears!"
                ],
                [
                  "1",
                  "I am from New York",
                  "Chat",
                  "The Big Apple! New York is a vibrant and exciting city with so much to offer. What's your favorite thing about living in New York, Alice? Is it the energy of the city, the food, the culture, or something else?"
                ],
                [
                  "2",
                  "I love hiking",
                  "Chat",
                  "Hiking is a great way to enjoy the beautiful outdoors and get some exercise. New York has plenty of amazing hiking spots, from the Hudson River Greenway to the Appalachian Trail. Have you had a chance to explore any of the nearby parks or trails, such as Bear Mountain State Park or the High Line?\n\nIf you're looking for some recommendations, I can suggest some popular hiking spots in and around New York. Or, if you're looking for something more specific, like a certain type of hike or a particular location, feel free to let me know and I can try to help!"
                ],
                [
                  "3",
                  "Calculate 5+7",
                  "Calculator",
                  "Calc error: invalid syntax (<string>, line 1)"
                ],
                [
                  "4",
                  "Tell me a joke",
                  "Chat",
                  "Here's one:\n\nWhat do you call a fake noodle?\n\n(wait for it...)\n\nAn impasta!\n\nHope that made you smile, Alice!"
                ],
                [
                  "5",
                  "I am allergic to peanuts",
                  "Chat",
                  "I'll make sure to keep that in mind, Alice. I'll avoid suggesting any peanut-related foods or activities. Would you like some recommendations for peanut-free snacks or restaurants in New York? Or perhaps I can suggest some fun activities that don't involve food?"
                ],
                [
                  "6",
                  "Translate hola to en",
                  "Chat",
                  "The translation of \"hola\" to English is \"hello\"."
                ],
                [
                  "7",
                  "What do you know about me?",
                  "Chat",
                  "I know that you are Alice, and you are from New York. You also mentioned that you are sad today, and that you are allergic to peanuts. Additionally, you enjoy hiking and appreciate a good joke. You also asked me to translate the phrase \"hola\" to English, which I told you is \"hello\"."
                ],
                [
                  "8",
                  "I work as a software engineer",
                  "Chat",
                  "That's great to know, Alice. As a software engineer, I'm sure you're always looking for ways to improve your skills and stay up-to-date with the latest technologies. Are you working on any exciting projects or looking for advice on a specific area of software engineering?\n\nBy the way, I can also help with coding-related tasks or answer any questions you may have about programming languages, software development methodologies, or tools. Just let me know what's on your mind!"
                ],
                [
                  "9",
                  "I enjoy cooking Italian food",
                  "Chat",
                  "Buon appetito, Alice! Italian food is a classic favorite among many people. There's something about the rich flavors, aromas, and traditions surrounding Italian cuisine that's hard to resist.\n\nAs a software engineer, I'm sure you appreciate the attention to detail and precision that goes into cooking a delicious Italian meal. From the perfect sauce to the fluffiest pasta, every ingredient and technique matters.\n\nIf you're looking for some new Italian recipes to try, I'd be happy to suggest some popular dishes or provide you with some cooking tips. Perhaps you'd like to try your hand at making pasta from scratch, or maybe you're looking for some ideas for a specific type of Italian cuisine, such as pizza, risotto, or osso buco?\n\nLet me know, and I'll do my best to help you cook up something delicious!"
                ],
                [
                  "10",
                  "What is my name?",
                  "Chat",
                  "Your name is Alice, and you're from New York."
                ],
                [
                  "11",
                  "What is my job?",
                  "Chat",
                  "You work as a software engineer."
                ],
                [
                  "12",
                  "What are my dietary restrictions?",
                  "Chat",
                  "You are allergic to peanuts."
                ],
                [
                  "13",
                  "Analyze sentiment: I am feeling great today",
                  "SentimentAnalysis",
                  "Positive 👍"
                ],
                [
                  "14",
                  "Give me a summary of all the previous questions.",
                  "Chat",
                  "Here's a summary of our conversation:\n\n* You mentioned that you love hiking and enjoy exploring New York's outdoor spots, such as the Hudson River Greenway and the Appalachian Trail.\n* You asked me to tell you a joke, which I shared with you.\n* You mentioned that you are allergic to peanuts and asked for recommendations for peanut-free snacks or restaurants in New York.\n* You asked me to translate the phrase \"hola\" to English, which I told you is \"hello\".\n* You shared that you work as a software engineer and asked for advice or recommendations on a specific area of software engineering.\n* You mentioned that you enjoy cooking Italian food and asked for suggestions on new recipes or cooking tips.\n* You asked me to recall your name, job, and dietary restrictions, which I was able to recall from our previous conversation."
                ],
                [
                  "15",
                  "I play guitar in my free time",
                  "Chat",
                  "That's great, Alice. Playing the guitar is a wonderful hobby that can be very relaxing and rewarding. As a software engineer, I'm sure you appreciate the creative outlet that playing music provides.\n\nIf you're looking for some new songs to learn or want to explore different genres, I'd be happy to help. Are you interested in learning a specific style of music, such as classical, rock, or jazz? Or perhaps you'd like some recommendations for guitar tabs or online resources to help you improve your skills?\n\nAlso, have you ever thought about writing your own music or composing songs? I'd be happy to help with any questions or ideas you might have on that front."
                ],
                [
                  "16",
                  "What am I allergic to?",
                  "Chat",
                  "You are allergic to peanuts."
                ],
                [
                  "17",
                  "What do you remember about me?",
                  "Chat",
                  "I remember that you are Alice, and you are from New York. You also mentioned that you are a software engineer and enjoy cooking Italian food. Additionally, you are allergic to peanuts. You also enjoy playing the guitar in your free time."
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 18
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Routed To</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My name is Alice</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Nice to meet you, Alice! Is there something on your mind that you'd like to talk about or ask for help with? I'm all ears!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am from New York</td>\n",
              "      <td>Chat</td>\n",
              "      <td>The Big Apple! New York is a vibrant and exciting city with so much to offer. What's your favorite thing about living in New York, Alice? Is it the energy of the city, the food, the culture, or something else?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I love hiking</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Hiking is a great way to enjoy the beautiful outdoors and get some exercise. New York has plenty of amazing hiking spots, from the Hudson River Greenway to the Appalachian Trail. Have you had a chance to explore any of the nearby parks or trails, such as Bear Mountain State Park or the High Line?\\n\\nIf you're looking for some recommendations, I can suggest some popular hiking spots in and around New York. Or, if you're looking for something more specific, like a certain type of hike or a particular location, feel free to let me know and I can try to help!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Calculate 5+7</td>\n",
              "      <td>Calculator</td>\n",
              "      <td>Calc error: invalid syntax (&lt;string&gt;, line 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tell me a joke</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Here's one:\\n\\nWhat do you call a fake noodle?\\n\\n(wait for it...)\\n\\nAn impasta!\\n\\nHope that made you smile, Alice!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I am allergic to peanuts</td>\n",
              "      <td>Chat</td>\n",
              "      <td>I'll make sure to keep that in mind, Alice. I'll avoid suggesting any peanut-related foods or activities. Would you like some recommendations for peanut-free snacks or restaurants in New York? Or perhaps I can suggest some fun activities that don't involve food?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Translate hola to en</td>\n",
              "      <td>Chat</td>\n",
              "      <td>The translation of \"hola\" to English is \"hello\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What do you know about me?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>I know that you are Alice, and you are from New York. You also mentioned that you are sad today, and that you are allergic to peanuts. Additionally, you enjoy hiking and appreciate a good joke. You also asked me to translate the phrase \"hola\" to English, which I told you is \"hello\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I work as a software engineer</td>\n",
              "      <td>Chat</td>\n",
              "      <td>That's great to know, Alice. As a software engineer, I'm sure you're always looking for ways to improve your skills and stay up-to-date with the latest technologies. Are you working on any exciting projects or looking for advice on a specific area of software engineering?\\n\\nBy the way, I can also help with coding-related tasks or answer any questions you may have about programming languages, software development methodologies, or tools. Just let me know what's on your mind!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I enjoy cooking Italian food</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Buon appetito, Alice! Italian food is a classic favorite among many people. There's something about the rich flavors, aromas, and traditions surrounding Italian cuisine that's hard to resist.\\n\\nAs a software engineer, I'm sure you appreciate the attention to detail and precision that goes into cooking a delicious Italian meal. From the perfect sauce to the fluffiest pasta, every ingredient and technique matters.\\n\\nIf you're looking for some new Italian recipes to try, I'd be happy to suggest some popular dishes or provide you with some cooking tips. Perhaps you'd like to try your hand at making pasta from scratch, or maybe you're looking for some ideas for a specific type of Italian cuisine, such as pizza, risotto, or osso buco?\\n\\nLet me know, and I'll do my best to help you cook up something delicious!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is my name?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Your name is Alice, and you're from New York.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is my job?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>You work as a software engineer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What are my dietary restrictions?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>You are allergic to peanuts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Analyze sentiment: I am feeling great today</td>\n",
              "      <td>SentimentAnalysis</td>\n",
              "      <td>Positive 👍</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Give me a summary of all the previous questions.</td>\n",
              "      <td>Chat</td>\n",
              "      <td>Here's a summary of our conversation:\\n\\n* You mentioned that you love hiking and enjoy exploring New York's outdoor spots, such as the Hudson River Greenway and the Appalachian Trail.\\n* You asked me to tell you a joke, which I shared with you.\\n* You mentioned that you are allergic to peanuts and asked for recommendations for peanut-free snacks or restaurants in New York.\\n* You asked me to translate the phrase \"hola\" to English, which I told you is \"hello\".\\n* You shared that you work as a software engineer and asked for advice or recommendations on a specific area of software engineering.\\n* You mentioned that you enjoy cooking Italian food and asked for suggestions on new recipes or cooking tips.\\n* You asked me to recall your name, job, and dietary restrictions, which I was able to recall from our previous conversation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I play guitar in my free time</td>\n",
              "      <td>Chat</td>\n",
              "      <td>That's great, Alice. Playing the guitar is a wonderful hobby that can be very relaxing and rewarding. As a software engineer, I'm sure you appreciate the creative outlet that playing music provides.\\n\\nIf you're looking for some new songs to learn or want to explore different genres, I'd be happy to help. Are you interested in learning a specific style of music, such as classical, rock, or jazz? Or perhaps you'd like some recommendations for guitar tabs or online resources to help you improve your skills?\\n\\nAlso, have you ever thought about writing your own music or composing songs? I'd be happy to help with any questions or ideas you might have on that front.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What am I allergic to?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>You are allergic to peanuts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What do you remember about me?</td>\n",
              "      <td>Chat</td>\n",
              "      <td>I remember that you are Alice, and you are from New York. You also mentioned that you are a software engineer and enjoy cooking Italian food. Additionally, you are allergic to peanuts. You also enjoy playing the guitar in your free time.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Input          Routed To  \\\n",
              "0                                   My name is Alice               Chat   \n",
              "1                                 I am from New York               Chat   \n",
              "2                                      I love hiking               Chat   \n",
              "3                                      Calculate 5+7         Calculator   \n",
              "4                                     Tell me a joke               Chat   \n",
              "5                           I am allergic to peanuts               Chat   \n",
              "6                               Translate hola to en               Chat   \n",
              "7                         What do you know about me?               Chat   \n",
              "8                      I work as a software engineer               Chat   \n",
              "9                       I enjoy cooking Italian food               Chat   \n",
              "10                                  What is my name?               Chat   \n",
              "11                                   What is my job?               Chat   \n",
              "12                 What are my dietary restrictions?               Chat   \n",
              "13       Analyze sentiment: I am feeling great today  SentimentAnalysis   \n",
              "14  Give me a summary of all the previous questions.               Chat   \n",
              "15                     I play guitar in my free time               Chat   \n",
              "16                            What am I allergic to?               Chat   \n",
              "17                    What do you remember about me?               Chat   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Output  \n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Nice to meet you, Alice! Is there something on your mind that you'd like to talk about or ask for help with? I'm all ears!  \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The Big Apple! New York is a vibrant and exciting city with so much to offer. What's your favorite thing about living in New York, Alice? Is it the energy of the city, the food, the culture, or something else?  \n",
              "2                                                                                                                                                                                                                                                                                       Hiking is a great way to enjoy the beautiful outdoors and get some exercise. New York has plenty of amazing hiking spots, from the Hudson River Greenway to the Appalachian Trail. Have you had a chance to explore any of the nearby parks or trails, such as Bear Mountain State Park or the High Line?\\n\\nIf you're looking for some recommendations, I can suggest some popular hiking spots in and around New York. Or, if you're looking for something more specific, like a certain type of hike or a particular location, feel free to let me know and I can try to help!  \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Calc error: invalid syntax (<string>, line 1)  \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Here's one:\\n\\nWhat do you call a fake noodle?\\n\\n(wait for it...)\\n\\nAn impasta!\\n\\nHope that made you smile, Alice!  \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I'll make sure to keep that in mind, Alice. I'll avoid suggesting any peanut-related foods or activities. Would you like some recommendations for peanut-free snacks or restaurants in New York? Or perhaps I can suggest some fun activities that don't involve food?  \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The translation of \"hola\" to English is \"hello\".  \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             I know that you are Alice, and you are from New York. You also mentioned that you are sad today, and that you are allergic to peanuts. Additionally, you enjoy hiking and appreciate a good joke. You also asked me to translate the phrase \"hola\" to English, which I told you is \"hello\".  \n",
              "8                                                                                                                                                                                                                                                                                                                                                                         That's great to know, Alice. As a software engineer, I'm sure you're always looking for ways to improve your skills and stay up-to-date with the latest technologies. Are you working on any exciting projects or looking for advice on a specific area of software engineering?\\n\\nBy the way, I can also help with coding-related tasks or answer any questions you may have about programming languages, software development methodologies, or tools. Just let me know what's on your mind!  \n",
              "9                       Buon appetito, Alice! Italian food is a classic favorite among many people. There's something about the rich flavors, aromas, and traditions surrounding Italian cuisine that's hard to resist.\\n\\nAs a software engineer, I'm sure you appreciate the attention to detail and precision that goes into cooking a delicious Italian meal. From the perfect sauce to the fluffiest pasta, every ingredient and technique matters.\\n\\nIf you're looking for some new Italian recipes to try, I'd be happy to suggest some popular dishes or provide you with some cooking tips. Perhaps you'd like to try your hand at making pasta from scratch, or maybe you're looking for some ideas for a specific type of Italian cuisine, such as pizza, risotto, or osso buco?\\n\\nLet me know, and I'll do my best to help you cook up something delicious!  \n",
              "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Your name is Alice, and you're from New York.  \n",
              "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       You work as a software engineer.  \n",
              "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           You are allergic to peanuts.  \n",
              "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Positive 👍  \n",
              "14  Here's a summary of our conversation:\\n\\n* You mentioned that you love hiking and enjoy exploring New York's outdoor spots, such as the Hudson River Greenway and the Appalachian Trail.\\n* You asked me to tell you a joke, which I shared with you.\\n* You mentioned that you are allergic to peanuts and asked for recommendations for peanut-free snacks or restaurants in New York.\\n* You asked me to translate the phrase \"hola\" to English, which I told you is \"hello\".\\n* You shared that you work as a software engineer and asked for advice or recommendations on a specific area of software engineering.\\n* You mentioned that you enjoy cooking Italian food and asked for suggestions on new recipes or cooking tips.\\n* You asked me to recall your name, job, and dietary restrictions, which I was able to recall from our previous conversation.  \n",
              "15                                                                                                                                                                          That's great, Alice. Playing the guitar is a wonderful hobby that can be very relaxing and rewarding. As a software engineer, I'm sure you appreciate the creative outlet that playing music provides.\\n\\nIf you're looking for some new songs to learn or want to explore different genres, I'd be happy to help. Are you interested in learning a specific style of music, such as classical, rock, or jazz? Or perhaps you'd like some recommendations for guitar tabs or online resources to help you improve your skills?\\n\\nAlso, have you ever thought about writing your own music or composing songs? I'd be happy to help with any questions or ideas you might have on that front.  \n",
              "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           You are allergic to peanuts.  \n",
              "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I remember that you are Alice, and you are from New York. You also mentioned that you are a software engineer and enjoy cooking Italian food. Additionally, you are allergic to peanuts. You also enjoy playing the guitar in your free time.  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Define your sequence of interactions\n",
        "tests = [\n",
        "    \"My name is Alice\",\n",
        "    \"I am from New York\",\n",
        "    \"I love hiking\",\n",
        "    \"Calculate 5+7\",\n",
        "    \"Tell me a joke\",\n",
        "    \"I am allergic to peanuts\",\n",
        "    \"Translate hola to en\",\n",
        "    \"What do you know about me?\",\n",
        "    \"I work as a software engineer\",\n",
        "    \"I enjoy cooking Italian food\",\n",
        "    \"What is my name?\",\n",
        "    \"What is my job?\",\n",
        "    \"What are my dietary restrictions?\",\n",
        "    \"Analyze sentiment: I am feeling great today\",\n",
        "    \"Give me a summary of all the previous questions.\",\n",
        "    \"I play guitar in my free time\",\n",
        "    \"What am I allergic to?\",\n",
        "    \"What do you remember about me?\"\n",
        "]\n",
        "\n",
        "# 2) Run them through the router + converse\n",
        "rows = []\n",
        "for q in tests:\n",
        "    st = router_workflow.invoke({\"input\": q})\n",
        "    decision = st[\"decision\"]\n",
        "    if decision == \"Chat\":\n",
        "        output = converse(q)\n",
        "    else:\n",
        "        output = st[\"output\"]\n",
        "    rows.append({\n",
        "        \"Input\":      q,\n",
        "        \"Routed To\":  decision,\n",
        "        \"Output\":     output\n",
        "    })\n",
        "\n",
        "# 3) Build & show the DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhC1o7d1knJT"
      },
      "source": [
        "# Mem0 - Building Production-Ready AI Agents with Scalable Long-Term Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_zoWDjJkqJO",
        "outputId": "d77c8a6f-b58f-42db-bc7f-568fd8489ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You performed excellently on the Q3 report. Your detailed analysis and comprehensive approach were key highlights of your performance.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from openai import OpenAI\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ----------------------------------------------------------------------------\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "CHAT_MODEL = \"gpt-4-0613\"\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Embedding Helper\n",
        "# ----------------------------------------------------------------------------\n",
        "def get_embedding(text: str, model: str = EMBEDDING_MODEL) -> List[float]:\n",
        "    \"\"\"\n",
        "    Create an embedding for the given text using OpenAI Embeddings API.\n",
        "    \"\"\"\n",
        "    response = client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Vector Store Wrapper (Cosine similarity via Inner Product)\n",
        "# ----------------------------------------------------------------------------\n",
        "class VectorStore:\n",
        "    def __init__(self, dim: int = 1536, index_path: Optional[str] = None):\n",
        "        self.dim = dim\n",
        "        self.index = faiss.IndexFlatIP(dim)\n",
        "        self.metadatas: List[Dict[str, Any]] = []\n",
        "        if index_path and os.path.exists(index_path):\n",
        "            self.index = faiss.read_index(index_path)\n",
        "            with open(index_path + \".meta.json\", \"r\") as f:\n",
        "                self.metadatas = json.load(f)\n",
        "\n",
        "    def add(self, text: str, metadata: Dict[str, Any]) -> None:\n",
        "        emb = np.array(get_embedding(text), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        self.index.add(np.vstack([emb_norm]))\n",
        "        entry = {**metadata, \"fact\": text}\n",
        "        self.metadatas.append(entry)\n",
        "\n",
        "    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "        emb = np.array(get_embedding(query), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        D, I = self.index.search(np.vstack([emb_norm]), k)\n",
        "        results: List[Dict[str, Any]] = []\n",
        "        for score, idx in zip(D[0], I[0]):\n",
        "            if not isinstance(idx, int) or idx < 0 or idx >= len(self.metadatas):\n",
        "                continue\n",
        "            meta_entry = self.metadatas[idx]\n",
        "            if meta_entry.get(\"deleted\", False):\n",
        "                continue\n",
        "            meta = meta_entry.copy()\n",
        "            meta[\"score\"] = float(score)\n",
        "            results.append(meta)\n",
        "        return results\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Extraction\n",
        "# ----------------------------------------------------------------------------\n",
        "class MemoryExtractor:\n",
        "    def __init__(self, llm: OpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def extract(self,\n",
        "                 summary: str,\n",
        "                 window: List[str],\n",
        "                 prev_user: str,\n",
        "                 prev_assistant: str) -> List[str]:\n",
        "        prompt = (\n",
        "            f\"\"\"\n",
        "# CONTEXT SUMMARY\n",
        "{summary}\n",
        "\n",
        "# RECENT MESSAGES\n",
        "{json.dumps(window)}\n",
        "\n",
        "# NEW EXCHANGE\n",
        "USER: {prev_user}\n",
        "ASSISTANT: {prev_assistant}\n",
        "\n",
        "Extract up to 5 concise facts (one per line) that would be useful to remember later:\n",
        "\"\"\"\n",
        "        )\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        facts = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "        return facts\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Management via Function Calling\n",
        "# ----------------------------------------------------------------------------\n",
        "manage_memory_schema = {\n",
        "    \"name\": \"manage_memory\",\n",
        "    \"description\": \"Decide whether to add/update/delete a fact in memory.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"operation\": {\"type\": \"string\", \"enum\": [\"ADD\", \"UPDATE\", \"DELETE\"]},\n",
        "            \"target_id\": {\"type\": \"integer\"},\n",
        "            \"fact\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"operation\", \"fact\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "class MemoryManager:\n",
        "    def __init__(self, llm: OpenAI, store: VectorStore):\n",
        "        self.llm = llm\n",
        "        self.store = store\n",
        "\n",
        "    def manage(self, fact: str, candidates: List[Dict[str, Any]]) -> None:\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Decide what to do with fact: {fact}\"}],\n",
        "            functions=[manage_memory_schema],\n",
        "            function_call=\"auto\"\n",
        "        )\n",
        "        message = response.choices[0].message\n",
        "        call = getattr(message, 'function_call', None)\n",
        "        if call and call.arguments:\n",
        "            args = json.loads(call.arguments)\n",
        "            op = args.get(\"operation\")\n",
        "            tgt = args.get(\"target_id\")\n",
        "            new_fact = args.get(\"fact\")\n",
        "        else:\n",
        "            op = \"ADD\"\n",
        "            new_fact = fact\n",
        "            tgt = None\n",
        "\n",
        "        if op == \"ADD\":\n",
        "            self.store.add(new_fact, {\"source\": \"Mem0\", \"fact\": new_fact})\n",
        "        elif op == \"UPDATE\" and isinstance(tgt, int):\n",
        "            self.store.update(tgt, new_fact)\n",
        "        elif op == \"DELETE\" and isinstance(tgt, int):\n",
        "            self.store.delete(tgt)\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Retrieval and Integration\n",
        "# ----------------------------------------------------------------------------\n",
        "def retrieve_and_answer(llm: OpenAI, store: VectorStore, user_query: str) -> str:\n",
        "    # Try semantic search first\n",
        "    results = store.search(user_query, k=8)\n",
        "    # Fallback: use all stored memories if no hits\n",
        "    if not results:\n",
        "        results = store.metadatas.copy()\n",
        "    memories = \"\\n\".join([f\"- {r['fact']}\" for r in results])\n",
        "    prompt = (\n",
        "        f\"Here are relevant past memories:\\n{memories}\\n\\n\"\n",
        "        f\"User asks: {user_query}\\nAssistant:\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=CHAT_MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Example Usage\n",
        "# ----------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    store = VectorStore()\n",
        "    extractor = MemoryExtractor(client)\n",
        "    manager = MemoryManager(client, store)\n",
        "\n",
        "    prev_user = \"How was my last performance?\"\n",
        "    prev_assistant = \"You performed excellently on the Q3 report.\"\n",
        "    summary = \"Previous summary of the project context...\"\n",
        "    window = [\"User: ...\", \"Assistant: ...\"]\n",
        "\n",
        "    facts = extractor.extract(summary, window, prev_user, prev_assistant)\n",
        "    for fact in facts:\n",
        "        sims = store.search(fact, k=5)\n",
        "        manager.manage(fact, sims)\n",
        "\n",
        "    answer = retrieve_and_answer(client, store, \"What did I do well last quarter?\")\n",
        "    print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJOFuzCF-8dW",
        "outputId": "8a2babca-d5a5-4b07-9e58-cdaf6ac7acbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted facts: [\"The user's name is Alice\", 'Alice loved project X', 'Alice has switched to project Y']\n",
            "Store contents: [\"The user's name is Alice\", 'Alice loved project X', 'Alice has switched to project Y']\n",
            "All gold tests passed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from openai import OpenAI\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ----------------------------------------------------------------------------\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "CHAT_MODEL = \"gpt-4-0613\"\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Embedding Helper\n",
        "# ----------------------------------------------------------------------------\n",
        "def get_embedding(text: str, model: str = EMBEDDING_MODEL) -> List[float]:\n",
        "    \"\"\"\n",
        "    Create an embedding for the given text using OpenAI Embeddings API.\n",
        "    \"\"\"\n",
        "    response = client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Vector Store Wrapper (Cosine similarity via Inner Product)\n",
        "# ----------------------------------------------------------------------------\n",
        "class VectorStore:\n",
        "    def __init__(self, dim: int = 1536, index_path: Optional[str] = None):\n",
        "        self.dim = dim\n",
        "        self.index = faiss.IndexFlatIP(dim)\n",
        "        self.metadatas: List[Dict[str, Any]] = []\n",
        "        if index_path and os.path.exists(index_path):\n",
        "            self.index = faiss.read_index(index_path)\n",
        "            with open(index_path + \".meta.json\", \"r\") as f:\n",
        "                self.metadatas = json.load(f)\n",
        "\n",
        "    def add(self, text: str, metadata: Dict[str, Any]) -> None:\n",
        "        emb = np.array(get_embedding(text), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        self.index.add(np.vstack([emb_norm]))\n",
        "        entry = {**metadata, \"fact\": text}\n",
        "        self.metadatas.append(entry)\n",
        "\n",
        "    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "        emb = np.array(get_embedding(query), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        D, I = self.index.search(np.vstack([emb_norm]), k)\n",
        "        results: List[Dict[str, Any]] = []\n",
        "        for score, idx in zip(D[0], I[0]):\n",
        "            if not isinstance(idx, int) or idx < 0 or idx >= len(self.metadatas):\n",
        "                continue\n",
        "            meta_entry = self.metadatas[idx]\n",
        "            if meta_entry.get(\"deleted\", False):\n",
        "                continue\n",
        "            meta = meta_entry.copy()\n",
        "            meta[\"score\"] = float(score)\n",
        "            results.append(meta)\n",
        "        return results\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Extraction (with prefix/format cleaning)\n",
        "# ----------------------------------------------------------------------------\n",
        "class MemoryExtractor:\n",
        "    def __init__(self, llm: OpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def extract(self,\n",
        "                 summary: str,\n",
        "                 window: List[str],\n",
        "                 prev_user: str,\n",
        "                 prev_assistant: str) -> List[str]:\n",
        "        prompt = (\n",
        "            f\"\"\"\n",
        "# CONTEXT SUMMARY\n",
        "{summary}\n",
        "\n",
        "# RECENT MESSAGES\n",
        "{json.dumps(window)}\n",
        "\n",
        "# NEW EXCHANGE\n",
        "USER: {prev_user}\n",
        "ASSISTANT: {prev_assistant}\n",
        "\n",
        "Extract up to 5 concise facts (one per line) that would be useful to remember later:\n",
        "\"\"\"\n",
        "        )\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        raw_facts = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "        cleaned = []\n",
        "        for fact in raw_facts:\n",
        "            # Remove numeric or list prefixes like '1. ' or '- '\n",
        "            f = re.sub(r'^\\s*[\\d]+[\\.)]?\\s*', '', fact)\n",
        "            # Strip surrounding quotes and trailing punctuation\n",
        "            f = f.strip('\"').rstrip('.!')\n",
        "            cleaned.append(f)\n",
        "        return cleaned\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Management via Function Calling\n",
        "# ----------------------------------------------------------------------------\n",
        "manage_memory_schema = {\n",
        "    \"name\": \"manage_memory\",\n",
        "    \"description\": \"Decide whether to add/update/delete a fact in memory.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"operation\": {\"type\": \"string\", \"enum\": [\"ADD\", \"UPDATE\", \"DELETE\"]},\n",
        "            \"target_id\": {\"type\": \"integer\"},\n",
        "            \"fact\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"operation\", \"fact\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "class MemoryManager:\n",
        "    def __init__(self, llm: OpenAI, store: VectorStore):\n",
        "        self.llm = llm\n",
        "        self.store = store\n",
        "\n",
        "    def manage(self, fact: str, candidates: List[Dict[str, Any]]) -> None:\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Decide what to do with fact: {fact}\"}],\n",
        "            functions=[manage_memory_schema],\n",
        "            function_call=\"auto\"\n",
        "        )\n",
        "        message = response.choices[0].message\n",
        "        call = getattr(message, 'function_call', None)\n",
        "        if call and call.arguments:\n",
        "            args = json.loads(call.arguments)\n",
        "            op = args.get(\"operation\")\n",
        "            tgt = args.get(\"target_id\")\n",
        "            new_fact = args.get(\"fact\")\n",
        "        else:\n",
        "            op, new_fact, tgt = \"ADD\", fact, None\n",
        "\n",
        "        if op == \"ADD\":\n",
        "            self.store.add(new_fact, {\"source\": \"Mem0\", \"fact\": new_fact})\n",
        "        elif op == \"UPDATE\" and isinstance(tgt, int):\n",
        "            self.store.update(tgt, new_fact)\n",
        "        elif op == \"DELETE\" and isinstance(tgt, int):\n",
        "            self.store.delete(tgt)\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Retrieval and Integration\n",
        "# ----------------------------------------------------------------------------\n",
        "def retrieve_and_answer(llm: OpenAI, store: VectorStore, user_query: str) -> str:\n",
        "    results = store.search(user_query, k=8)\n",
        "    if not results:\n",
        "        results = store.metadatas.copy()\n",
        "    memories = \"\\n\".join([f\"- {r['fact']}\" for r in results])\n",
        "    prompt = (\n",
        "        f\"Here are relevant past memories:\\n{memories}\\n\\n\"\n",
        "        f\"User asks: {user_query}\\nAssistant:\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=CHAT_MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Gold Conversation Set for Testing\n",
        "# ----------------------------------------------------------------------------\n",
        "gold_conversations = [\n",
        "    {\n",
        "        \"summary\": \"\",\n",
        "        \"window\": [\"User: My name is Alice and I love project X.\"],\n",
        "        \"prev_user\": \"Actually, I switched to project Y.\",\n",
        "        \"prev_assistant\": \"\",\n",
        "        \"expected_update\": [\"project Y\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "def run_gold_tests():\n",
        "    store = VectorStore()\n",
        "    extractor = MemoryExtractor(client)\n",
        "    manager = MemoryManager(client, store)\n",
        "    for case in gold_conversations:\n",
        "        facts = extractor.extract(case[\"summary\"], case[\"window\"], case[\"prev_user\"], case[\"prev_assistant\"])\n",
        "        print(\"Extracted facts:\", facts)\n",
        "        for fact in facts:\n",
        "            sims = store.search(fact, k=5)\n",
        "            manager.manage(fact, sims)\n",
        "        print(\"Store contents:\", [m['fact'] for m in store.metadatas])\n",
        "        if \"expected_add\" in case:\n",
        "            assert all(e in [m['fact'] for m in store.metadatas] for e in case[\"expected_add\"]), \"Add test failed\"\n",
        "        if \"expected_update\" in case:\n",
        "            assert any(e in m['fact'] for m in store.metadatas for e in case[\"expected_update\"]), \"Update test failed\"\n",
        "    print(\"All gold tests passed!\")\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Example Usage\n",
        "# ----------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    run_gold_tests()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlCnw27zAcNI",
        "outputId": "5b63f102-e2d8-463d-e17e-2ae41a7592d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "That's great to hear, Alice! Can you tell me more about project X and why you love it?\n",
            "I remember that your name is Alice and you love Project X.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Optional, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ----------------------------------------------------------------------------\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "CHAT_MODEL = \"gpt-4-0613\"\n",
        "\n",
        "# Data persistence paths\n",
        "DATA_DIR = Path(\"./mem0_data\")\n",
        "INDEX_PATH = DATA_DIR / \"faiss_index.bin\"\n",
        "META_PATH = DATA_DIR / \"metadata.json\"\n",
        "\n",
        "# Ensure data directory exists\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Embedding Helper\n",
        "# ----------------------------------------------------------------------------\n",
        "def get_embedding(text: str, model: str = EMBEDDING_MODEL) -> List[float]:\n",
        "    response = client.embeddings.create(\n",
        "        input=[text], model=model\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Vector Store Wrapper (Cosine similarity via Inner Product)\n",
        "# ----------------------------------------------------------------------------\n",
        "class VectorStore:\n",
        "    def __init__(self, dim: int = 1536, index_path: Optional[str] = None, meta_path: Optional[str] = None):\n",
        "        self.dim = dim\n",
        "        self.index = faiss.IndexFlatIP(dim)\n",
        "        self.metadatas: List[Dict[str, Any]] = []\n",
        "        self.index_path = index_path\n",
        "        self.meta_path = meta_path\n",
        "        if index_path and index_path.exists():\n",
        "            self.index = faiss.read_index(str(index_path))\n",
        "        if meta_path and meta_path.exists():\n",
        "            with open(meta_path, \"r\") as f:\n",
        "                self.metadatas = json.load(f)\n",
        "\n",
        "    def add(self, text: str, metadata: Dict[str, Any]) -> None:\n",
        "        emb = np.array(get_embedding(text), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        self.index.add(np.vstack([emb_norm]))\n",
        "        entry = {**metadata, \"fact\": text}\n",
        "        self.metadatas.append(entry)\n",
        "        self._save()\n",
        "\n",
        "    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
        "        emb = np.array(get_embedding(query), dtype=\"float32\")\n",
        "        emb_norm = emb / np.linalg.norm(emb)\n",
        "        D, I = self.index.search(np.vstack([emb_norm]), k)\n",
        "        results: List[Dict[str, Any]] = []\n",
        "        for score, idx in zip(D[0], I[0]):\n",
        "            if idx < 0 or idx >= len(self.metadatas):\n",
        "                continue\n",
        "            meta_entry = self.metadatas[idx]\n",
        "            if meta_entry.get(\"deleted\", False):\n",
        "                continue\n",
        "            results.append({**meta_entry, \"score\": float(score)})\n",
        "        return results\n",
        "\n",
        "    def _save(self):\n",
        "        if self.index_path is not None:\n",
        "            faiss.write_index(self.index, str(self.index_path))\n",
        "        if self.meta_path is not None:\n",
        "            with open(self.meta_path, \"w\") as f:\n",
        "                json.dump(self.metadatas, f, indent=2)\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Extraction\n",
        "# ----------------------------------------------------------------------------\n",
        "class MemoryExtractor:\n",
        "    def __init__(self, llm: OpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def extract(self, summary: str, window: List[str], prev_user: str, prev_assistant: str) -> List[str]:\n",
        "        prompt = (\n",
        "            f\"\"\"\n",
        "# CONTEXT SUMMARY\n",
        "{summary}\n",
        "\n",
        "# RECENT MESSAGES\n",
        "{json.dumps(window)}\n",
        "\n",
        "# NEW EXCHANGE\n",
        "USER: {prev_user}\n",
        "ASSISTANT: {prev_assistant}\n",
        "\n",
        "Extract up to 5 concise facts (one per line) that would be useful to remember later:\n",
        "\"\"\"\n",
        "        )\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        raw = response.choices[0].message.content.strip().split(\"\\n\")\n",
        "        cleaned = [re.sub(r'^\\s*[\\d]+[\\.)]?\\s*', '', line).strip('\"').rstrip('.!') for line in raw if line.strip()]\n",
        "        return cleaned\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Memory Management via Function Calling\n",
        "# ----------------------------------------------------------------------------\n",
        "manage_memory_schema = {\n",
        "    \"name\": \"manage_memory\",\n",
        "    \"description\": \"Decide whether to add/update/delete a fact in memory.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"operation\": {\"type\": \"string\", \"enum\": [\"ADD\", \"UPDATE\", \"DELETE\"]},\n",
        "            \"target_id\": {\"type\": \"integer\"},\n",
        "            \"fact\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"operation\", \"fact\"]\n",
        "    }\n",
        "}\n",
        "class MemoryManager:\n",
        "    def __init__(self, llm: OpenAI, store: VectorStore):\n",
        "        self.llm = llm\n",
        "        self.store = store\n",
        "\n",
        "    def manage(self, fact: str):\n",
        "        # similarity candidates not used here\n",
        "        response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Decide what to do with fact: {fact}\"}],\n",
        "            functions=[manage_memory_schema],\n",
        "            function_call=\"auto\"\n",
        "        )\n",
        "        call = getattr(response.choices[0].message, 'function_call', None)\n",
        "        if call and call.arguments:\n",
        "            args = json.loads(call.arguments)\n",
        "            op, tgt, new_fact = args.get(\"operation\"), args.get(\"target_id\"), args.get(\"fact\")\n",
        "        else:\n",
        "            op, new_fact, tgt = \"ADD\", fact, None\n",
        "        if op == \"ADD\":\n",
        "            self.store.add(new_fact, {\"source\": \"Mem0\"})\n",
        "        # UPDATE/DELETE can be implemented similarly\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Mem0 Agent integrating sessions\n",
        "# ----------------------------------------------------------------------------\n",
        "class Mem0Agent:\n",
        "    def __init__(self):\n",
        "        self.store = VectorStore(dim=1536, index_path=INDEX_PATH, meta_path=META_PATH)\n",
        "        self.extractor = MemoryExtractor(client)\n",
        "        self.manager = MemoryManager(client, self.store)\n",
        "        self.chat_history: List[Dict[str, str]] = []\n",
        "        self.summary: str = \"\"\n",
        "\n",
        "    def chat(self, user_input: str) -> str:\n",
        "        # Retrieve relevant memories\n",
        "        memories = self.store.search(user_input, k=5)\n",
        "        mem_text = \"\\n\".join([m['fact'] for m in memories])\n",
        "\n",
        "        # Construct prompt\n",
        "        prompt_msgs = []\n",
        "        if self.summary:\n",
        "            prompt_msgs.append({\"role\": \"system\", \"content\": f\"Conversation summary: {self.summary}\"})\n",
        "        if mem_text:\n",
        "            prompt_msgs.append({\"role\": \"system\", \"content\": f\"Past memories:\\n{mem_text}\"})\n",
        "        for turn in self.chat_history:\n",
        "            prompt_msgs.append(turn)\n",
        "        prompt_msgs.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # LLM reply\n",
        "        resp = client.chat.completions.create(model=CHAT_MODEL, messages=prompt_msgs)\n",
        "        assistant_reply = resp.choices[0].message.content\n",
        "\n",
        "        # Update memory\n",
        "        facts = self.extractor.extract(self.summary, [m['content'] for m in self.chat_history], user_input, assistant_reply)\n",
        "        for fact in facts:\n",
        "            self.manager.manage(fact)\n",
        "\n",
        "        # Append to history\n",
        "        self.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        self.chat_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "        return assistant_reply\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Example run across sessions\n",
        "# ----------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    agent = Mem0Agent()\n",
        "    # Session 1\n",
        "    print(agent.chat(\"My name is Alice and I love project X.\"))\n",
        "    # Save and exit, next run retains memory\n",
        "    # Session 2 (new process)\n",
        "    agent2 = Mem0Agent()\n",
        "    print(agent2.chat(\"What do you remember about me?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1gwdXgfAzr9",
        "outputId": "488cdde9-3769-4bb0-b171-e16ffc05cace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Alice from Seattle! It's nice to meet you. How can I assist you today?\n",
            "Nice! Blue is such a calming color. Is there anything else you want to share or any questions you have today?\n",
            "That sounds like a great way to enjoy nature and stay active. Seattle has some beautiful trails!\n",
            "--- New Session ---\n",
            "You are from Seattle, Alice.\n",
            "Your favorite color is blue, Alice.\n",
            "You enjoy hiking on weekends, Alice.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Session 1: store diverse facts\n",
        "    agent = Mem0Agent()\n",
        "    print(agent.chat(\"Hi, I'm Alice from Seattle.\"))\n",
        "    print(agent.chat(\"My favorite color is blue.\"))\n",
        "    print(agent.chat(\"I enjoy hiking on weekends.\"))\n",
        "    # Simulate end of process (memory persisted to disk)\n",
        "\n",
        "    # Session 2: new process should recall across sessions\n",
        "    agent2 = Mem0Agent()\n",
        "    print(\"--- New Session ---\")\n",
        "    print(agent2.chat(\"Where am I from?\"))               # expects mention of Seattle\n",
        "    print(agent2.chat(\"What's my favorite color?\"))     # expects mention of blue\n",
        "    print(agent2.chat(\"What do I like to do on weekends?\"))  # expects mention of hiking\")]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hSVj6gGBbs"
      },
      "source": [
        "## Agent With Tools Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0-cPYEbvIJB",
        "outputId": "6dfe0bd4-ebf9-4578-9b2d-cf019a00da23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, Alice!\n",
            "2.0\n",
            "Added to-do: Finish homework\n",
            "1. Finish homework\n",
            "dlrow olleH\n",
            "2025-05-05T23:33:56.455348Z\n",
            "Hello, I love pizza!\n",
            "Hello, myself!\n"
          ]
        }
      ],
      "source": [
        "from typing import ClassVar, List\n",
        "from pydantic import PrivateAttr\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.schema import BaseMemory\n",
        "import faiss\n",
        "import re\n",
        "import operator\n",
        "import datetime\n",
        "\n",
        "# --- Memory Class -------------------------------------------------------------\n",
        "class Mem0Memory(BaseMemory):\n",
        "    \"\"\"\n",
        "    Simplified Mem0-inspired memory for testing purposes.\n",
        "    Automatically stores each user query and retrieves top-5 relevant memories.\n",
        "    \"\"\"\n",
        "    memory_variables: ClassVar[List[str]] = [\"memories\"]\n",
        "    _embedding_model: OpenAIEmbeddings = PrivateAttr()\n",
        "    _vectorstore: FAISS = PrivateAttr()\n",
        "\n",
        "    def __init__(self, llm: OpenAI, embedding_model: OpenAIEmbeddings, vectorstore: FAISS):\n",
        "        super().__init__()\n",
        "        self._embedding_model = embedding_model\n",
        "        self._vectorstore = vectorstore\n",
        "\n",
        "    def load_memory_variables(self, inputs: dict) -> dict:\n",
        "        query = inputs.get(\"input\", \"\")\n",
        "        docs = self._vectorstore.similarity_search(query, k=5)\n",
        "        return {\"memories\": [doc.page_content for doc in docs]}\n",
        "\n",
        "    def save_context(self, inputs: dict, outputs: dict) -> None:\n",
        "        user_input = inputs.get(\"input\", \"\").strip()\n",
        "        # avoid storing tool commands\n",
        "        if user_input and not user_input.startswith((\"greet\", \"calc\", \"todo_\", \"reverse\", \"time\")):\n",
        "            self._vectorstore.add_texts([user_input])\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        dim = len(self._embedding_model.embed_query(\"\"))\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "        self._vectorstore = FAISS(self._embedding_model, index, InMemoryDocstore({}), {})\n",
        "\n",
        "# --- Tool Implementations ----------------------------------------------------\n",
        "# 1. Greeting\n",
        "# Usage: greet <name>\n",
        "def greet(name: str) -> str:\n",
        "    \"\"\"Greet a person by name.\"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "# 2. Calculator\n",
        "# Usage: calc <expression>\n",
        "SAFE_OPERATORS = {\n",
        "    '+': operator.add,\n",
        "    '-': operator.sub,\n",
        "    '*': operator.mul,\n",
        "    '/': operator.truediv\n",
        "}\n",
        "\n",
        "def calc(expression: str) -> str:\n",
        "    \"\"\"Safely evaluate a simple arithmetic expression.\"\"\"\n",
        "    try:\n",
        "        tokens = re.findall(r\"[\\d\\.]+|[+\\-*/()]\", expression)\n",
        "        sanitized = \"\".join(tokens)\n",
        "        result = eval(sanitized, {\"__builtins__\": None}, SAFE_OPERATORS)\n",
        "        return str(result)\n",
        "    except Exception:\n",
        "        return \"Error: invalid expression\"\n",
        "\n",
        "# 3. To-Do List Manager\n",
        "class TodoList:\n",
        "    def __init__(self):\n",
        "        self.items: List[str] = []\n",
        "\n",
        "    def add(self, item: str) -> str:\n",
        "        self.items.append(item)\n",
        "        return f\"Added to-do: {item}\"\n",
        "\n",
        "    def list(self, _: str = \"\") -> str:\n",
        "        if not self.items:\n",
        "            return \"No to-do items.\"\n",
        "        return \"\\n\".join(f\"{i+1}. {it}\" for i, it in enumerate(self.items))\n",
        "\n",
        "    def clear(self, _: str = \"\") -> str:\n",
        "        self.items.clear()\n",
        "        return \"Cleared all to-dos.\"\n",
        "\n",
        "todo = TodoList()\n",
        "\n",
        "def todo_add(item: str) -> str:\n",
        "    \"\"\"Add a task to to-do list.\"\"\"\n",
        "    return todo.add(item)\n",
        "\n",
        "def todo_list(_: str = \"\") -> str:\n",
        "    \"\"\"List all tasks.\"\"\"\n",
        "    return todo.list()\n",
        "\n",
        "def todo_clear(_: str = \"\") -> str:\n",
        "    \"\"\"Clear all tasks.\"\"\"\n",
        "    return todo.clear()\n",
        "\n",
        "# 4. Reverse Text\n",
        "# Usage: reverse <text>\n",
        "def reverse(text: str) -> str:\n",
        "    \"\"\"Reverse the given text.\"\"\"\n",
        "    return text[::-1]\n",
        "\n",
        "# 5. Current Time\n",
        "# Usage: time\n",
        "def time(_: str = \"\") -> str:\n",
        "    \"\"\"Return current UTC time in ISO format.\"\"\"\n",
        "    return datetime.datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "# --- Agent Initialization ---------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize LLM and embeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    # Build empty FAISS index for memory\n",
        "    dim = len(embeddings.embed_query(\"init\"))\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    vectordb = FAISS(embeddings, index, InMemoryDocstore({}), index_to_docstore_id={})\n",
        "    memory = Mem0Memory(llm, embeddings, vectordb)\n",
        "\n",
        "    # Define tools with explicit usage and direct returns\n",
        "    tools = [\n",
        "        Tool(name=\"greet\", func=greet, description=\"Greet someone by name. Usage: greet <name>\", return_direct=True),\n",
        "        Tool(name=\"calc\", func=calc, description=\"Calculate arithmetic. Usage: calc <expression>\", return_direct=True),\n",
        "        Tool(name=\"todo_add\", func=todo_add, description=\"Add task. Usage: todo_add <task>\", return_direct=True),\n",
        "        Tool(name=\"todo_list\", func=todo_list, description=\"List tasks. Usage: todo_list\", return_direct=True),\n",
        "        Tool(name=\"todo_clear\", func=todo_clear, description=\"Clear tasks. Usage: todo_clear\", return_direct=True),\n",
        "        Tool(name=\"reverse\", func=reverse, description=\"Reverse text. Usage: reverse <text>\", return_direct=True),\n",
        "        Tool(name=\"time\", func=time, description=\"Get current UTC time. Usage: time\", return_direct=True)\n",
        "    ]\n",
        "\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        memory=memory,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Example interactions\n",
        "    print(agent.run(\"greet Alice\"))           # Hello, Alice!\n",
        "    print(agent.run(\"calc 12 / (2 * 3)\"))     # 2.0\n",
        "    print(agent.run(\"todo_add Finish homework\"))\n",
        "    print(agent.run(\"todo_list\"))\n",
        "    print(agent.run(\"reverse Hello world\"))\n",
        "    print(agent.run(\"time\"))\n",
        "    # Memory demonstration\n",
        "    print(agent.run(\"I love pizza\"))\n",
        "    print(agent.run(\"What do I love?\"))       # I love pizza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6po5C5B0Bc"
      },
      "source": [
        "## Open-Sourced LLaMa Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y73LQ_SEutZX",
        "outputId": "df559583-6a48-4517-9e34-91ad464c566c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: langgraph in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (0.4.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (0.3.58)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (0.1.66)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.3.1)\n",
            "Requirement already satisfied: deep_translator in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from deep_translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.4.26)\n",
            "Requirement already satisfied: wikipedia in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\rbrul\\onedrive\\documents\\github\\agent-tool-integrations\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install langgraph\n",
        "!pip install deep_translator\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5266ce29427e4f4eb6b80bbdbe05e805",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login() # paste your token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "57f67546f674410b8efc556432e961da",
            "814b36416625470887377ec92ecb9e3f",
            "c57dd3c3be3c4ce9b93940984b0433af",
            "b8ef3262cf4c47aeba2269afcd5b0d05",
            "bff7049222c4457eb8f365bbdceeb29e",
            "10b9671347c148eaa22099f91a412e37",
            "7f13359e5c2e48e3bdebd24f3876b083",
            "0b8f8edcf1c74672aac7c5b384d9e303",
            "10662f6ab9b043248dfe28e759263c29",
            "6662c05d5f914d3991ce85179381681d",
            "7bb12941bc10433eafd2fdcadd26487a",
            "1a60b61062e149b3b9ba90d432fced2c",
            "bbf38ef8ed254369a9c25aee8a21df4d",
            "027c490ce17e4b119b9107a070e9633a",
            "3b42166d080a44ddabd0e7c2256d0ba2",
            "43853bce3e134304a560eaf4194b6dce",
            "2bb5a6cfc9f74c4a859195417438f849",
            "45ecdf1d8bde4fa0ac0261d5706b10eb",
            "752bbc57e61543eda632d5d0d07baacb",
            "ebc99c6287fb4bb682d1758c52bd720a",
            "f7a755aaacd948a7a8839e88149b73a5",
            "74b7f562f5264fd0aa5ef5411f519f9a",
            "e1a9a13c528740c5b2522d336f21b07a",
            "f08f5a19669a457bb93e8a65570a3e11",
            "48ea7e77403f4ddaa805be7101b38319",
            "a629ea89636640a0bc8ff5999fc34a4b",
            "8950c606519d41148468bc6b670c08af",
            "2c02f8aa75a1484da36c4d1d8d2426a7",
            "40192cbe8be7419c97927f02ff4107a6",
            "f7c05d2a965e4414a581542a5943dc7e",
            "216cde96870240dfb24a9469f63dfe4c",
            "8430f8c37b3644cba5efed933701e339",
            "07a33c5fd5c9416d823b95568b6795e3",
            "1ce6e3daddad4e3db6b3170362e4b772",
            "3d55036b07be4591bbe5ffb46f1e57e4",
            "a4da4cfa5f0b46b482ed6f0eda1ee3b4",
            "fc228261781d462698568e898a8b884b",
            "26e280e34aab478d8ad5fd1d61e42de9",
            "6f3f93b8265b452d8e14aad0617346cf",
            "c1f58c93c9024835a5f25b687f0bd317",
            "7302ecc0cf2143d886b43ea08ec7c8e1",
            "cfe51aa205b04a80a15852c5636a5a4c",
            "3fd84cb29d0c491688984aded8abca0c",
            "11dc43d3001f4eb2b8488a3bbc07b05a",
            "4f5dc40a01b140c6bff16babf3a9a741",
            "52fb30e2e5844fa69db2b1019513fe4e",
            "fdae88c0fdf54688ac596de802bdbf60",
            "fda49688c2f9438c8817a87900398225",
            "529c2dad421140b58ef92f2f662fc633",
            "f61cf6d2c5844effbe70ef31b7c992f9",
            "ce0c81a4455b48a7b725f524efaf8fd5",
            "1b6d9e4fedbf44efa3bea0ddf6c0a262",
            "db34d8998a464fdc8a1f555b98cf634a",
            "2ce34b04c09c4eefb5a7ecc0bf5f16b2",
            "66b745ce98d6459e850461a7e7a3a30d",
            "665ebce977f2475f8bfcf475868b310c",
            "cff641cb82b94bc1917e501822b0cc11",
            "af3fe804d76d4d25ac10eb43a9922651",
            "33206f1e514e4ab8b52d3ad8c7dfab8d",
            "d34b4af08460444b8211fc52ed6926b1",
            "91908f93c55d42ec98f890c83a00b05e",
            "e792b7ea2df74339bc169a44f2806c1d",
            "3029955fc3cb465da05451f6b0984c3a",
            "d66b008d61f24eff8ad06e071006241b",
            "3945d5d8fc8d48daa28581e4d96cd9fe",
            "8b40252f3ac14f69adf12b1c7c3d736e",
            "132016c2eb634da6ae445e52ebb01244",
            "b947dc78cd944814996466b701ef9c79",
            "c1bcbca1f48a402abad0fe4675528b0c",
            "3cbd8e7dae8d4dbb9cec5e4dbd428eb7",
            "468c361da9df4569a07aec6fe797813e",
            "aacacfe42c5a4a33abda4d63f636de9e",
            "af1cf97c6d7e4d45ac37eefdeabf49fc",
            "5352687422e848a3b15f05ee376f3616",
            "e7183a51bc934036919b5f0b8eb6b579",
            "45d268415081492bab323dff1e946384",
            "bc04fe1b6ec84fd8beed6a00e179f714",
            "9b5e3be3609b4781bd6b8fdd23590374",
            "7f9290c5a1a54fe5b6ecdca3aa663a03",
            "a5e8b6d12cfc4413890ceda96f3194d2",
            "4733f3f2c16940f0b3fe01bcca90518c",
            "fca5ed9efc4842039e4e9338996ebf0f",
            "bf2f8ad7635b4e5a81dd965796056622",
            "9561acea8a7648dfa3fa1ff27b726a0a",
            "d26729ca0e724b6f9c7223a01b0e1c2f",
            "0635f8a67dac458e9c01083c68f496ce",
            "98f18e3ab974498fb5b20dd12c271e1e",
            "3c53da3fc3c144b1a4753e2412b5db62",
            "de1ce5c6c5d9495d90dc6756a08048fe",
            "0af4e7c616ef44289e4b66d31fcb8ff2",
            "6d24d762a5a14ef8957c3ba9b24f30ae",
            "991239566f2241a69f3a532190531eb3",
            "156fe75e182f49119e74a928771e18ca",
            "d9152fc7baec4988a960adbcbab9001a",
            "f2cf5d4a3c4b41c5861a1343a444bb37",
            "1bc0bbc3531e46b3baf79d8fdf4580d9",
            "1af3df3806534cf5bd8cd568c9ea738c",
            "f9b3c93f14354db19c5cf2b619640a45",
            "b74817eaff2641018feaaf699b89b1f3",
            "9daefeb18fbf47e5a367ff415f68a45f",
            "832293f704934c0f9cbb2e93cc8e80e2",
            "00f2a74c56e6443a8d3550c8f3ecb9cc",
            "c9a68a01c90b44f1a8b1f4cf3e5e27f2",
            "2f6d5899af9c4c13841b43cceaeef3b7",
            "0523b16f4ff8430b87f22e8eff3a106b",
            "9b75be6c61944f56a8134655e1e45d0e",
            "17e1a330a94b47a8b716d840818d467c",
            "60bdfc219fb443f7af0af0afabc9d455",
            "a1ec2c7f22c34f8e8f8b180879bc2f32",
            "dec725ab2172452581dcbf6f3c789e92"
          ]
        },
        "id": "HW-K_NMOvkwL",
        "outputId": "e27cbc28-16db-409c-81ff-c123b5e50428"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "accbda6dd1ac46eaa7c4624e625e86b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict, Any, List\n",
        "import torch\n",
        "\n",
        "# 1. Load your local Llama model (replace with your model directory)\n",
        "model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",      # GPU if available\n",
        "    torch_dtype=torch.float16 # use fp16 where supported\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import re\n",
        "# import warnings\n",
        "# import numpy as np\n",
        "# from typing import TypedDict, Any, List, Dict\n",
        "# from transformers import pipeline, logging as tf_logging\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# import faiss\n",
        "# import wikipedia\n",
        "# from deep_translator import GoogleTranslator\n",
        "# from langchain.agents import Tool\n",
        "# from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# # — Silence warnings —\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# tf_logging.set_verbosity_error()\n",
        "\n",
        "# # — Assume llama model & tokenizer are loaded:\n",
        "# # model = ...\n",
        "# # tokenizer = ...\n",
        "\n",
        "# # ——— Recency buffer / conversation history ———\n",
        "# conversation_history: List[Dict[str,str]] = []\n",
        "# RECENT_WINDOW = 5\n",
        "\n",
        "# # ——— History of all user inputs for summary ———\n",
        "# summary_history: List[str] = []\n",
        "\n",
        "# # ——— State schema ———\n",
        "# class State(TypedDict):\n",
        "#     input: str\n",
        "#     decision: str\n",
        "#     raw_input: str\n",
        "#     output: Any\n",
        "\n",
        "# # ——— Mem0 explicit-memory store ———\n",
        "# class Mem0Memory:\n",
        "#     def __init__(self):\n",
        "#         self.facts: List[str] = []\n",
        "\n",
        "#     def add_fact(self, fact: str):\n",
        "#         fact = fact.strip()\n",
        "#         if fact and fact not in self.facts:\n",
        "#             self.facts.append(fact)\n",
        "\n",
        "#     def retrieve_all(self) -> List[str]:\n",
        "#         return self.facts.copy()\n",
        "\n",
        "#     def retrieve(self, query: str) -> List[str]:\n",
        "#         q = query.lower()\n",
        "#         return [f for f in self.facts if any(tok in f.lower() for tok in re.findall(r\"\\w+\", q))]\n",
        "\n",
        "# mem0 = Mem0Memory()\n",
        "\n",
        "# # ——— LLM wrapper ———\n",
        "# def generate_chat_template(model, tokenizer, sys_pmt: str, prompt: str,\n",
        "#                            temperature=0.0, top_p=0.9,\n",
        "#                            max_new_tokens: int = 128,\n",
        "#                            do_sample: bool = False) -> str:\n",
        "#     msgs = [{\"role\":\"system\",\"content\":sys_pmt}, {\"role\":\"user\",\"content\":prompt}]\n",
        "#     pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "#     formatted = pipe.tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
        "#     out = pipe(\n",
        "#         formatted,\n",
        "#         max_new_tokens=max_new_tokens,\n",
        "#         do_sample=do_sample,\n",
        "#         temperature=temperature,\n",
        "#         top_p=top_p,\n",
        "#     )\n",
        "#     return out[0][\"generated_text\"].split(formatted,1)[1].strip()\n",
        "\n",
        "# # ——— History recorder ———\n",
        "# def record_history(user: str, assistant: str):\n",
        "#     conversation_history.append({\"role\":\"user\",\"text\":user})\n",
        "#     conversation_history.append({\"role\":\"assistant\",\"text\":assistant})\n",
        "#     while len(conversation_history) > RECENT_WINDOW * 2:\n",
        "#         conversation_history.pop(0)\n",
        "#         conversation_history.pop(0)\n",
        "\n",
        "# # ——— Tool implementations ———\n",
        "\n",
        "# def calculator_tool(text: str) -> str:\n",
        "#     expr = re.sub(r'(?i)^calculate\\s*', '', text).strip()\n",
        "#     try:\n",
        "#         res = str(eval(expr, {\"__builtins__\":None}, {}))\n",
        "#     except:\n",
        "#         res = \"Error\"\n",
        "#     record_history(text, res)\n",
        "#     summary_history.append(text)\n",
        "#     return res\n",
        "\n",
        "\n",
        "# def chat_tool(text: str) -> str:\n",
        "#     summary_history.append(text)\n",
        "#     m1 = re.match(r'(?i)^my name is\\s+(.+)', text)\n",
        "#     m2 = re.match(r'(?i)^i am\\s+(.+)', text)\n",
        "#     m3 = re.match(r'(?i)^i work as\\s+(.+)', text)\n",
        "#     if m1:\n",
        "#         mem0.add_fact(f\"My name is {m1.group(1).strip()}\")\n",
        "#     if m2:\n",
        "#         mem0.add_fact(f\"I am {m2.group(1).strip()}\")\n",
        "#     if m3:\n",
        "#         mem0.add_fact(f\"I work as {m3.group(1).strip()}\")\n",
        "#     # generate chat response\n",
        "#     reply = generate_chat_template(\n",
        "#         model, tokenizer,\n",
        "#         sys_pmt=\"You are a concise assistant.\",\n",
        "#         prompt=text,\n",
        "#         temperature=0.7,\n",
        "#         do_sample=True\n",
        "#     )\n",
        "#     record_history(text, reply)\n",
        "#     return reply\n",
        "\n",
        "\n",
        "# def mem0_tool(text: str) -> str:\n",
        "#     summary_history.append(text)\n",
        "#     # generic recall or direct recall queries\n",
        "#     if re.match(r'(?i)^(what do you know|recall|what do you remember|what is my name|what are my dietary)', text):\n",
        "#         facts = mem0.retrieve_all()\n",
        "#         if not facts:\n",
        "#             out = \"I have no memory on that.\"\n",
        "#         else:\n",
        "#             out = \"I remember: \" + \"; \".join(facts) + \".\"\n",
        "#     else:\n",
        "#         facts = mem0.retrieve(text)\n",
        "#         if not facts:\n",
        "#             out = \"I have no memory on that.\"\n",
        "#         else:\n",
        "#             out = \"; \".join(facts) + \".\"\n",
        "#     record_history(text, out)\n",
        "#     return out\n",
        "\n",
        "\n",
        "# def summary_tool(text: str) -> str:\n",
        "#     items = []\n",
        "#     for q in summary_history[:-1]:\n",
        "#         if q not in items:\n",
        "#             items.append(q)\n",
        "#     if not items:\n",
        "#         out = \"No past inputs.\"\n",
        "#     else:\n",
        "#         out = \"Previous inputs:\\n\" + \"\\n\".join(f\"- {q}\" for q in items)\n",
        "#     record_history(text, out)\n",
        "#     return out\n",
        "\n",
        "\n",
        "# def translation_tool(text: str) -> str:\n",
        "#     m = re.match(r'(?i)^translate\\s+(.+?)\\s+to\\s+(\\w+)$', text)\n",
        "#     if m:\n",
        "#         src, tgt = m.group(1).strip(), m.group(2).strip()\n",
        "#     else:\n",
        "#         src, tgt = re.sub(r'(?i)^translate\\s*', '', text).strip(), 'en'\n",
        "#     try:\n",
        "#         translated = GoogleTranslator(source='auto', target=tgt).translate(src)\n",
        "#     except:\n",
        "#         sys_pmt = f\"Translate to {tgt}.\"\n",
        "#         translated = generate_chat_template(model, tokenizer, sys_pmt, src)\n",
        "#     record_history(text, translated)\n",
        "#     return translated\n",
        "\n",
        "# # ——— Router ———\n",
        "# def llm_call_router(state: State) -> State:\n",
        "#     txt = state[\"input\"].strip()\n",
        "#     state[\"raw_input\"] = txt\n",
        "#     low = txt.lower()\n",
        "#     summary_history.append(txt)\n",
        "\n",
        "#     # explicit routing for known prefixes\n",
        "#     if low.startswith(\"translate\"):\n",
        "#         state[\"decision\"] = \"TRANSLATOR\"\n",
        "#         return state\n",
        "#     if low.startswith(\"calculate\") or re.fullmatch(r\"[\\d\\.\\s\\+\\-\\*\\/\\^\\(\\)]+\", txt):\n",
        "#         state[\"decision\"] = \"CALC\"\n",
        "#         return state\n",
        "#     if re.match(r'(?i)^give me a summary', txt):\n",
        "#         state[\"decision\"] = \"SUMMARY\"\n",
        "#         return state\n",
        "#     if re.match(r'(?i)^(tell me|show me)', txt):\n",
        "#         state[\"decision\"] = \"CHAT\"\n",
        "#         return state\n",
        "\n",
        "#     # fallback: classify via LLM\n",
        "#     sys_pmt = (\n",
        "#         \"Classify the following user query into exactly one of: 'calculator', 'translator', 'mem0', 'summary', or 'chat'.\"\n",
        "#     )\n",
        "#     choice = generate_chat_template(model, tokenizer, sys_pmt, txt,\n",
        "#                                     temperature=0.0, do_sample=False).lower()\n",
        "#     if \"calculator\" in choice:\n",
        "#         state[\"decision\"] = \"CALC\"\n",
        "#     elif \"translator\" in choice:\n",
        "#         state[\"decision\"] = \"TRANSLATOR\"\n",
        "#     elif \"summary\" in choice:\n",
        "#         state[\"decision\"] = \"SUMMARY\"\n",
        "#     elif \"mem0\" in choice or \"memory\" in choice:\n",
        "#         state[\"decision\"] = \"MEM0\"\n",
        "#     else:\n",
        "#         state[\"decision\"] = \"CHAT\"\n",
        "#     return state\n",
        "\n",
        "# # ——— Graph ———\n",
        "# router = StateGraph(State)\n",
        "# router.add_node(\"CALC\", lambda s: {**s, \"output\": calculator_tool(s[\"raw_input\"])})\n",
        "# router.add_node(\"CHAT\", lambda s: {**s, \"output\": chat_tool(s[\"raw_input\"])})\n",
        "# router.add_node(\"MEM0\", lambda s: {**s, \"output\": mem0_tool(s[\"raw_input\"])})\n",
        "# router.add_node(\"SUMMARY\", lambda s: {**s, \"output\": summary_tool(s[\"raw_input\"])})\n",
        "# router.add_node(\"TRANSLATOR\", lambda s: {**s, \"output\": translation_tool(s[\"raw_input\"])})\n",
        "# router.add_node(\"ROUTER\", llm_call_router)\n",
        "\n",
        "# router.add_edge(START, \"ROUTER\")\n",
        "# router.add_conditional_edges(\n",
        "#     \"ROUTER\",\n",
        "#     lambda s: s[\"decision\"],\n",
        "#     {\"CALC\":\"CALC\",\"CHAT\":\"CHAT\",\"MEM0\":\"MEM0\",\"SUMMARY\":\"SUMMARY\",\"TRANSLATOR\":\"TRANSLATOR\"}\n",
        "# )\n",
        "# for node in [\"CALC\",\"CHAT\",\"MEM0\",\"SUMMARY\",\"TRANSLATOR\"]:\n",
        "#     router.add_edge(node, END)\n",
        "# router.set_entry_point(\"ROUTER\")\n",
        "# router_workflow = router.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import warnings\n",
        "import json\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "from transformers import pipeline, logging as tf_logging\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence warnings —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf_logging.set_verbosity_error()\n",
        "\n",
        "# — Assume model & tokenizer are loaded externally —\n",
        "# model = ...\n",
        "# tokenizer = ...\n",
        "\n",
        "# ——— Global LLM pipeline ———\n",
        "_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def _generate(sys_prompt: str, user_prompt: str,\n",
        "              temperature: float=0.0, top_p: float=1.0,\n",
        "              max_new_tokens: int=32, do_sample: bool=False) -> str:\n",
        "    msgs = [{\"role\":\"system\",\"content\":sys_prompt},{\"role\":\"user\",\"content\":user_prompt}]\n",
        "    formatted = _gen_pipeline.tokenizer.apply_chat_template(\n",
        "        msgs, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    out = _gen_pipeline(\n",
        "        formatted,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        do_sample=do_sample,\n",
        "        return_full_text=True\n",
        "    )\n",
        "    raw = out[0].get(\"generated_text\", out[0].get(\"text\", str(out[0])))\n",
        "    return raw.split(formatted,1)[1].strip() if formatted in raw else raw.strip()\n",
        "\n",
        "# ——— Translator client ———\n",
        "_translation_client = GoogleTranslator(source='auto', target='en')\n",
        "\n",
        "# ——— Conversation + Mem0 buffers ———\n",
        "conversation_history: List[Dict[str,str]] = []\n",
        "RECENT_WINDOW = 8\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.facts: List[str] = []\n",
        "        self.summary: str      = \"\"\n",
        "\n",
        "    def list_all(self) -> List[str]:\n",
        "        return self.facts.copy()\n",
        "\n",
        "    def summarize(self):\n",
        "        texts = [m[\"text\"] for m in conversation_history]\n",
        "        prompt = \"Summarize key points from these messages:\\n\" + \"\\n\".join(texts)\n",
        "        self.summary = _generate(prompt, \"\")\n",
        "\n",
        "    def merge_updates(self, new_message: str):\n",
        "        \"\"\"\n",
        "        For a new message, ask the LLM to classify which facts to add, update, or delete.\n",
        "        Expects a JSON with keys 'add', 'update', 'delete', each a list of strings.\n",
        "        \"\"\"\n",
        "        recent = [m[\"text\"] for m in conversation_history[-RECENT_WINDOW:]]\n",
        "        prompt = (\n",
        "            f\"Existing summary: {self.summary}\\n\"\n",
        "            f\"Existing facts: {self.facts}\\n\"\n",
        "            f\"Recent messages: {recent}\\n\"\n",
        "            f\"New message: '{new_message}'\\n\"\n",
        "            \"Output a JSON object with three lists:\\n\"\n",
        "            \"  'add': new facts to add,\\n\"\n",
        "            \"  'update': objects with 'from' and 'to' for facts to change,\\n\"\n",
        "            \"  'delete': facts to remove.\\n\"\n",
        "            \"Only output the JSON.\"\n",
        "        )\n",
        "        resp = _generate(prompt, \"\")\n",
        "        try:\n",
        "            ops = json.loads(resp.strip(\"`\"))\n",
        "        except:\n",
        "            ops = {\"add\": [], \"update\": [], \"delete\": []}\n",
        "\n",
        "        # DELETE\n",
        "        for fact in ops.get(\"delete\", []):\n",
        "            if fact in self.facts:\n",
        "                self.facts.remove(fact)\n",
        "\n",
        "        # UPDATE\n",
        "        # expects items like {\"from\": \"...old...\", \"to\": \"...new...\"}\n",
        "        for upd in ops.get(\"update\", []):\n",
        "            old = upd.get(\"from\")\n",
        "            new = upd.get(\"to\")\n",
        "            if old in self.facts and new:\n",
        "                idx = self.facts.index(old)\n",
        "                self.facts[idx] = new\n",
        "\n",
        "        # ADD\n",
        "        for fact in ops.get(\"add\", []):\n",
        "            if fact and fact not in self.facts:\n",
        "                self.facts.append(fact)\n",
        "\n",
        "    # alias for backwards compatibility\n",
        "    def extract_and_update(self, msg: str):\n",
        "        # still keep summary rolling every N messages\n",
        "        if len(conversation_history) % RECENT_WINDOW == 0:\n",
        "            self.summarize()\n",
        "        self.merge_updates(msg)\n",
        "\n",
        "mem = Memory()\n",
        "\n",
        "def record(user: str, assistant: str):\n",
        "    conversation_history.append({\"role\":\"user\",\"text\":user})\n",
        "    conversation_history.append({\"role\":\"assistant\",\"text\":assistant})\n",
        "    while len(conversation_history) > RECENT_WINDOW*2:\n",
        "        conversation_history.pop(0); conversation_history.pop(0)\n",
        "\n",
        "# ——— Explicit fact patterns ———\n",
        "def extract_facts(text: str):\n",
        "    txt = text.strip()\n",
        "    m = re.match(r'(?i)^my name is\\s+(.+)', txt)\n",
        "    if m:\n",
        "        fact = f\"Name: {m.group(1).strip()}\"\n",
        "        if fact not in mem.facts: mem.facts.append(fact)\n",
        "    m = re.match(r'(?i)^i am allergic to\\s+(.+)', txt)\n",
        "    if m:\n",
        "        fact = f\"Allergy: {m.group(1).strip()}\"\n",
        "        if fact not in mem.facts: mem.facts.append(fact)\n",
        "    m = re.match(r'(?i)^i work as\\s+(.+)', txt)\n",
        "    if m:\n",
        "        fact = f\"Occupation: {m.group(1).strip()}\"\n",
        "        if fact not in mem.facts: mem.facts.append(fact)\n",
        "\n",
        "# ——— Recall tool ———\n",
        "def recall_tool(text: str) -> str:\n",
        "    low = text.lower()\n",
        "    if re.search(r'\\bremember\\b', low):\n",
        "        mem.summarize()\n",
        "        facts = mem.list_all()\n",
        "        return f\"{mem.summary}\\nKnown facts: {', '.join(facts) if facts else 'None'}\"\n",
        "    if \"name\" in low:\n",
        "        for f in mem.facts:\n",
        "            if f.startswith(\"Name:\"):\n",
        "                return f.split(\":\",1)[1].strip()\n",
        "        return \"I don't have your name.\"\n",
        "    if any(k in low for k in [\"job\",\"occupation\"]):\n",
        "        for f in mem.facts:\n",
        "            if f.startswith(\"Occupation:\"):\n",
        "                return f.split(\":\",1)[1].strip()\n",
        "        return \"I don't know your occupation.\"\n",
        "    if any(k in low for k in [\"allergic\",\"diet\",\"food\"]):\n",
        "        allergies = [f.split(\":\",1)[1].strip() for f in mem.facts if f.startswith(\"Allergy:\")]\n",
        "        return \", \".join(allergies) if allergies else \"I don't know any dietary restrictions.\"\n",
        "    return \"I don't have that information.\"\n",
        "\n",
        "# ——— Tools ———\n",
        "def chat_tool(text: str) -> str:\n",
        "    extract_facts(text)\n",
        "    mem.extract_and_update(text)\n",
        "    if len(conversation_history) % RECENT_WINDOW == 0:\n",
        "        mem.summarize()\n",
        "    ctx = f\"Memory summary: {mem.summary}\\nFacts: {mem.list_all()}\\nBe concise.\"\n",
        "    out = _generate(ctx, text, temperature=0.7, do_sample=True, max_new_tokens=100)\n",
        "    record(text, out)\n",
        "    return out\n",
        "\n",
        "def calculator_tool(text: str) -> str:\n",
        "    expr = re.sub(r'(?i)^calculate\\s*','', text).strip()\n",
        "    try: res = str(eval(expr, {\"__builtins__\":None}, {}))\n",
        "    except: res = \"Error\"\n",
        "    record(text,res)\n",
        "    extract_facts(f\"Calc: {expr} = {res}\")\n",
        "    return res\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r'(?i)^translate\\s+(.+?)\\s+to\\s+(\\w+)$', text)\n",
        "    src,tgt = (m.group(1),m.group(2)) if m else (text,'en')\n",
        "    _translation_client.target = tgt\n",
        "    try: trans = _translation_client.translate(src)\n",
        "    except: trans = _generate(f\"Translate to {tgt}.\", src, max_new_tokens=100)\n",
        "    record(text,trans)\n",
        "    extract_facts(f\"Translation: {src}->{tgt}: {trans}\")\n",
        "    return trans\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    resp = _generate(\n",
        "        \"Return JSON with 'label' and 'score'.\", text, max_new_tokens=32\n",
        "    ).strip(\"`\")\n",
        "    try:\n",
        "        obj = json.loads(resp)\n",
        "        out = f\"{obj['label']} ({obj['score']:.2f})\"\n",
        "    except:\n",
        "        out = resp\n",
        "    record(text,out)\n",
        "    extract_facts(f\"Sentiment: {out}\")\n",
        "    return out\n",
        "\n",
        "def summarization_tool(_: str) -> str:\n",
        "    convo = \"\\n\".join(f\"{m['role']}: {m['text']}\" for m in conversation_history)\n",
        "    summ = _generate(\"Summarize this conversation.\", convo, max_new_tokens=120)\n",
        "    record(\"<summary>\",summ)\n",
        "    mem.summary = summ\n",
        "    return summ\n",
        "\n",
        "# ——— Router ———\n",
        "class State(TypedDict):\n",
        "    input: str; decision: str; raw_input: str; output: Any\n",
        "\n",
        "def llm_call_router(state: State) -> State:\n",
        "    txt = state[\"input\"].strip(); low = txt.lower()\n",
        "    state[\"raw_input\"] = txt\n",
        "\n",
        "    # self-statements → CHAT\n",
        "    if re.match(r'(?i)^(my name is|i am allergic to|i work as|i love|i enjoy|i play)\\b', txt):\n",
        "        state[\"decision\"] = \"CHAT\"; return state\n",
        "    # explicit tools\n",
        "    if low.startswith(\"calculate\") or re.fullmatch(r\"[\\d\\.\\s\\+\\-\\*\\/\\^\\(\\)]+\", txt):\n",
        "        state[\"decision\"] = \"CALC\"; return state\n",
        "    if low.startswith(\"translate\"):\n",
        "        state[\"decision\"] = \"TRANSLATOR\"; return state\n",
        "    if re.match(r\"(?i)^(summariz|give me a summary)\", txt):\n",
        "        state[\"decision\"] = \"SUMMARIZE\"; return state\n",
        "    if re.match(r\"(?i)^analyze sentiment\", txt):\n",
        "        state[\"decision\"] = \"SENTIMENT\"; return state\n",
        "    if re.match(r\"(?i)^what.*(my name|my job|dietary|allerg|remember)\", txt):\n",
        "        state[\"decision\"] = \"RECALL\"; return state\n",
        "\n",
        "    # fallback: no sentiment fallback\n",
        "    choice = _generate(\n",
        "        \"Choose one: calculator, translator, summarizer, chat, or recall.\", txt\n",
        "    ).lower().split()[0]\n",
        "    mapper = {\n",
        "        \"calculator\":\"CALC\",\"calc\":\"CALC\",\n",
        "        \"translator\":\"TRANSLATOR\",\"translate\":\"TRANSLATOR\",\n",
        "        \"summarizer\":\"SUMMARIZE\",\"summary\":\"SUMMARIZE\",\n",
        "        \"chat\":\"CHAT\",\"recall\":\"RECALL\"\n",
        "    }\n",
        "    state[\"decision\"] = mapper.get(choice, \"CHAT\")\n",
        "    return state\n",
        "\n",
        "# ——— Build graph ———\n",
        "router = StateGraph(State)\n",
        "for name, fn in [(\"CALC\",calculator_tool),(\"TRANSLATOR\",translation_tool),\n",
        "                 (\"SENTIMENT\",sentiment_tool),(\"SUMMARIZE\",summarization_tool),\n",
        "                 (\"CHAT\",chat_tool),(\"RECALL\",recall_tool)]:\n",
        "    router.add_node(name, lambda s,fn=fn: {**s,\"output\":fn(s[\"raw_input\"])})\n",
        "router.add_node(\"ROUTER\", llm_call_router)\n",
        "router.add_edge(START,\"ROUTER\")\n",
        "router.add_conditional_edges(\"ROUTER\", lambda s: s[\"decision\"],\n",
        "                             {n:n for n in [\"CALC\",\"TRANSLATOR\",\"SENTIMENT\",\"SUMMARIZE\",\"CHAT\",\"RECALL\"]})\n",
        "for n in [\"CALC\",\"TRANSLATOR\",\"SENTIMENT\",\"SUMMARIZE\",\"CHAT\",\"RECALL\"]:\n",
        "    router.add_edge(n,END)\n",
        "router.set_entry_point(\"ROUTER\")\n",
        "router_workflow = router.compile()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR_fq586FWcD",
        "outputId": "d31fd145-b7d9-43ae-dff5-97b9ea13a40c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 'Calculate 3*8'\n",
            "-> Routed to: CALC\n",
            "-> Output:\n",
            " 24 \n",
            "\n",
            ">>> 'Tell me a joke'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\" \n",
            "\n",
            "The librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\" \n",
            "\n",
            ">>> 'My name is villian'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " You've announced your name. What can I help you with? \n",
            "\n",
            ">>> 'I am vegan, what should I have for dinner tonight?'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " As a vegan, you have plenty of delicious options. Here are a few ideas:\n",
            "\n",
            "1. Pasta Primavera with marinara sauce and roasted vegetables\n",
            "2. Lentil soup with a side of quinoa and steamed broccoli\n",
            "3. Stuffed bell peppers with quinoa, black beans, and avocado\n",
            "4. Vegan stir-fry with tofu, mixed veggies, and brown rice\n",
            "5. Grilled portobello mushroom burgers with sweet potato fries\n",
            "\n",
            "Which one of these options sounds appealing \n",
            "\n",
            ">>> 'What do you know about me?'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " I know you are the \"villain\" mentioned in the conversation, but I don't have any other information about you beyond that. \n",
            "\n",
            ">>> 'What is the Python programming language?'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. It's often used for web development, data analysis, artificial intelligence, machine learning, and more. \n",
            "\n",
            ">>> 'Translate bonjour to en'\n",
            "-> Routed to: TRANSLATOR\n",
            "-> Output:\n",
            " bonjour \n",
            "\n",
            ">>> 'Analyze sentiment: I am so happy today'\n",
            "-> Routed to: SENTIMENT\n",
            "-> Output:\n",
            " Here is the sentiment analysis in JSON format:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"label\": \"positive\",\n",
            "  \"score\": 0.9\n",
            "}\n",
            " \n",
            "\n",
            ">>> 'Give me a summary of all the previous questions.'\n",
            "-> Routed to: SUMMARIZE\n",
            "-> Output:\n",
            " Here's a summary of our conversation:\n",
            "\n",
            "* Calculated 3*8 and got the answer 24.\n",
            "* Shared a joke about Pavlov's dogs and Schrödinger's cat.\n",
            "* Discussed dinner options for a vegan person.\n",
            "* Identified the user as the \"villain\" and didn't have any other information about them.\n",
            "* Provided information about the Python programming language.\n",
            "* Translated the French phrase \"bonjour\" to English.\n",
            "* Analyzed the sentiment of the phrase \"I am so happy today\" as positive with a score of 0.9. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ——— Test harness ———\n",
        "tests = [\n",
        "    \"Calculate 3*8\",\n",
        "    \"Tell me a joke\",\n",
        "    \"My name is villian\",\n",
        "    \"I am vegan, what should I have for dinner tonight?\",\n",
        "    \"What do you know about me?\",\n",
        "    \"What is the Python programming language?\",\n",
        "    \"Translate bonjour to en\",\n",
        "    \"Analyze sentiment: I am so happy today\",\n",
        "    \"Give me a summary of all the previous questions.\"\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    st = router_workflow.invoke({\"input\": q})\n",
        "    print(f\">>> {q!r}\")\n",
        "    print(\"-> Routed to:\", st[\"decision\"])\n",
        "    print(\"-> Output:\\n\", st[\"output\"], \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZgcWw1Mv8kIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 'What do you know about me?'\n",
            "-> Routed to: CHAT\n",
            "-> Output:\n",
            " I don't know much about you, but I can try to make some educated guesses based on your request to summarize 'My name is villain'. It seems you might be interested in the topic of names or villainous themes. Is there something specific you'd like to talk about or ask? \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ——— Test harness ———\n",
        "tests = [\n",
        "    \"What do you know about me?\"\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    st = router_workflow.invoke({\"input\": q})\n",
        "    print(f\">>> {q!r}\")\n",
        "    print(\"-> Routed to:\", st[\"decision\"])\n",
        "    print(\"-> Output:\\n\", st[\"output\"], \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Routed To",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Output",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "c654407b-d1d6-40b4-9f3c-57766e1a65a3",
              "rows": [
                [
                  "0",
                  "My name is Alice",
                  "CHAT",
                  "Nice to meet you, Alice."
                ],
                [
                  "1",
                  "I am from New York",
                  "CHAT",
                  "You didn't provide any context about your name."
                ],
                [
                  "2",
                  "I love hiking",
                  "CHAT",
                  "That's great! Hiking is a wonderful way to connect with nature and stay active. Have you hiked to any particularly beautiful or memorable spots recently?"
                ],
                [
                  "3",
                  "Calculate 5+7",
                  "CALC",
                  "12"
                ],
                [
                  "4",
                  "Tell me a joke",
                  "CHAT",
                  "A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\" \n\nThe librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\""
                ],
                [
                  "5",
                  "I am allergic to peanuts",
                  "CHAT",
                  "Be mindful of your surroundings to avoid exposure to peanuts."
                ],
                [
                  "6",
                  "Translate hola to en",
                  "TRANSLATOR",
                  "hello"
                ],
                [
                  "7",
                  "What do you know about me?",
                  "CHAT",
                  "I don't know much about you. You haven't provided any information about yourself."
                ],
                [
                  "8",
                  "I work as a software engineer",
                  "CHAT",
                  "That's interesting, I also know that Alice, the person I was told you were referring to, works as a software engineer."
                ],
                [
                  "9",
                  "I enjoy cooking Italian food",
                  "CHAT",
                  "It sounds like you have a passion for Italian cuisine. Would you like to share some of your favorite Italian dishes or cooking techniques?"
                ],
                [
                  "10",
                  "What is my name?",
                  "RECALL",
                  "Alice"
                ],
                [
                  "11",
                  "What is my job?",
                  "RECALL",
                  "a software engineer"
                ],
                [
                  "12",
                  "What are my dietary restrictions?",
                  "RECALL",
                  "peanuts"
                ],
                [
                  "13",
                  "Analyze sentiment: I am feeling great today",
                  "SENTIMENT",
                  "Here is the sentiment analysis in JSON format:\n\n```json\n{\n  \"label\": \"positive\",\n  \"score\": 0.9\n}\n"
                ],
                [
                  "14",
                  "Give me a summary of all the previous questions.",
                  "SUMMARIZE",
                  "This conversation appears to be a series of interactions between a user and a conversational AI. Here's a summary:\n\n1. The user asked for a simple math calculation (5+7) and received the answer (12).\n2. The user asked for a joke, which was a play on words about Pavlov's dogs and Schrödinger's cat.\n3. The user mentioned an allergy to peanuts and received a general warning to be mindful of their surroundings.\n4. The user asked to translate \"hola\" to English, and the response was \"hello\".\n5. The user"
                ],
                [
                  "15",
                  "I play guitar in my free time",
                  "CHAT",
                  "You're a music enthusiast, in addition to being a software engineer."
                ],
                [
                  "16",
                  "What am I allergic to?",
                  "RECALL",
                  "peanuts"
                ],
                [
                  "17",
                  "What do you remember about me?",
                  "RECALL",
                  "There is no conversation to summarize. You provided a series of individual statements, but no conversation history. Please provide the actual conversation text, and I'll be happy\nKnown facts: My name is villian, My name is villain, Name: Alice, Allergy: peanuts, Occupation: a software engineer"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 18
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Routed To</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My name is Alice</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>Nice to meet you, Alice.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am from New York</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>You didn't provide any context about your name.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I love hiking</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>That's great! Hiking is a wonderful way to con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Calculate 5+7</td>\n",
              "      <td>CALC</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tell me a joke</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>A man walked into a library and asked the libr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I am allergic to peanuts</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>Be mindful of your surroundings to avoid expos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Translate hola to en</td>\n",
              "      <td>TRANSLATOR</td>\n",
              "      <td>hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What do you know about me?</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>I don't know much about you. You haven't provi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I work as a software engineer</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>That's interesting, I also know that Alice, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I enjoy cooking Italian food</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>It sounds like you have a passion for Italian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is my name?</td>\n",
              "      <td>RECALL</td>\n",
              "      <td>Alice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is my job?</td>\n",
              "      <td>RECALL</td>\n",
              "      <td>a software engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What are my dietary restrictions?</td>\n",
              "      <td>RECALL</td>\n",
              "      <td>peanuts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Analyze sentiment: I am feeling great today</td>\n",
              "      <td>SENTIMENT</td>\n",
              "      <td>Here is the sentiment analysis in JSON format:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Give me a summary of all the previous questions.</td>\n",
              "      <td>SUMMARIZE</td>\n",
              "      <td>This conversation appears to be a series of in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I play guitar in my free time</td>\n",
              "      <td>CHAT</td>\n",
              "      <td>You're a music enthusiast, in addition to bein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What am I allergic to?</td>\n",
              "      <td>RECALL</td>\n",
              "      <td>peanuts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>What do you remember about me?</td>\n",
              "      <td>RECALL</td>\n",
              "      <td>There is no conversation to summarize. You pro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Input   Routed To  \\\n",
              "0                                   My name is Alice        CHAT   \n",
              "1                                 I am from New York        CHAT   \n",
              "2                                      I love hiking        CHAT   \n",
              "3                                      Calculate 5+7        CALC   \n",
              "4                                     Tell me a joke        CHAT   \n",
              "5                           I am allergic to peanuts        CHAT   \n",
              "6                               Translate hola to en  TRANSLATOR   \n",
              "7                         What do you know about me?        CHAT   \n",
              "8                      I work as a software engineer        CHAT   \n",
              "9                       I enjoy cooking Italian food        CHAT   \n",
              "10                                  What is my name?      RECALL   \n",
              "11                                   What is my job?      RECALL   \n",
              "12                 What are my dietary restrictions?      RECALL   \n",
              "13       Analyze sentiment: I am feeling great today   SENTIMENT   \n",
              "14  Give me a summary of all the previous questions.   SUMMARIZE   \n",
              "15                     I play guitar in my free time        CHAT   \n",
              "16                            What am I allergic to?      RECALL   \n",
              "17                    What do you remember about me?      RECALL   \n",
              "\n",
              "                                               Output  \n",
              "0                            Nice to meet you, Alice.  \n",
              "1     You didn't provide any context about your name.  \n",
              "2   That's great! Hiking is a wonderful way to con...  \n",
              "3                                                  12  \n",
              "4   A man walked into a library and asked the libr...  \n",
              "5   Be mindful of your surroundings to avoid expos...  \n",
              "6                                               hello  \n",
              "7   I don't know much about you. You haven't provi...  \n",
              "8   That's interesting, I also know that Alice, th...  \n",
              "9   It sounds like you have a passion for Italian ...  \n",
              "10                                              Alice  \n",
              "11                                a software engineer  \n",
              "12                                            peanuts  \n",
              "13  Here is the sentiment analysis in JSON format:...  \n",
              "14  This conversation appears to be a series of in...  \n",
              "15  You're a music enthusiast, in addition to bein...  \n",
              "16                                            peanuts  \n",
              "17  There is no conversation to summarize. You pro...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a sequence of 15 diverse interactions\n",
        "tests = [\n",
        "    \"My name is Alice\",\n",
        "    \"I am from New York\",\n",
        "    \"I love hiking\",\n",
        "    \"Calculate 5+7\",\n",
        "    \"Tell me a joke\",\n",
        "    \"I am allergic to peanuts\",\n",
        "    \"Translate hola to en\",\n",
        "    \"What do you know about me?\",\n",
        "    \"I work as a software engineer\",\n",
        "    \"I enjoy cooking Italian food\",\n",
        "    \"What is my name?\",\n",
        "    \"What is my job?\",\n",
        "    \"What are my dietary restrictions?\",\n",
        "    \"Analyze sentiment: I am feeling great today\",\n",
        "    \"Give me a summary of all the previous questions.\",\n",
        "    \"I play guitar in my free time\",\n",
        "    \"What am I allergic to?\",\n",
        "    \"What do you remember about me?\"\n",
        "]\n",
        "\n",
        "# Run through the router\n",
        "rows = []\n",
        "for q in tests:\n",
        "    st = router_workflow.invoke({\"input\": q})\n",
        "    rows.append({\n",
        "        \"Input\": q,\n",
        "        \"Routed To\": st[\"decision\"],\n",
        "        \"Output\": st[\"output\"]\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manus AI Recreation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cdb5922a83d4aff83d75c6604e28b95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict, Any, List\n",
        "import torch\n",
        "\n",
        "# 1. Load your local Llama model (replace with your model directory)\n",
        "model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",      # GPU if available\n",
        "    torch_dtype=torch.float16 # use fp16 where supported\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic Agent Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "             Translate 'Hola, ¿cómo estás?' to english\n",
            "                                      calculate 12 * 7\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                 result\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you?\n",
            "                                      calculate 12 * 7                                                     84\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84. \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                 result  correct\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you?     True\n",
            "                                      calculate 12 * 7                                                     84     True\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84.     True \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Calculate 3 + 4 * 2 and translate 'Bonjour' to english\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "                                   Calculate 3 + 4 * 2\n",
            "                        translate 'Bonjour' to english\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                      result\n",
            "                                   Calculate 3 + 4 * 2                                          11\n",
            "                        translate 'Bonjour' to english                                     Bonjour\n",
            "Combine the results of subtasks into a single sentence Bonjour Also, the calculation result is 11. \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                      result  correct\n",
            "                                   Calculate 3 + 4 * 2                                          11     True\n",
            "                        translate 'Bonjour' to english                                     Bonjour     True\n",
            "Combine the results of subtasks into a single sentence Bonjour Also, the calculation result is 11.     True \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, logging as hf_logging\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Text-generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        "    framework=\"pt\",\n",
        ")\n",
        "\n",
        "# ——— LLM wrapper ———\n",
        "def generate(text: str, max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7, top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(text, max_new_tokens=max_new_tokens,\n",
        "                   do_sample=do_sample, temperature=temperature, top_p=top_p)\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# ——— State schema ———\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# ——— Planner Agent (rule-based splitter) ———\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    parts = re.split(r'\\band then\\b|\\band\\b', text, flags=re.I)\n",
        "    plan: List[str] = []\n",
        "    for part in parts:\n",
        "        part = part.strip().rstrip('.')\n",
        "        low = part.lower()\n",
        "        if low.startswith('translate'):\n",
        "            plan.append(part)\n",
        "        elif low.startswith('calculate'):\n",
        "            plan.append(part)\n",
        "    if len(plan) >= 2:\n",
        "        plan.append(\"Combine the results of subtasks into a single sentence\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# ——— Tools ———\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.strip().lower()\n",
        "    if expr_text.startswith(\"calculate\"):\n",
        "        expr_text = expr_text[len(\"calculate\"):].strip()\n",
        "    try:\n",
        "        return str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except Exception:\n",
        "        return \"Error\"\n",
        "\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m:\n",
        "        return GoogleTranslator(source='auto', target=m.group(2)).translate(m.group(1))\n",
        "    try:\n",
        "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "# ——— Execution Agent ———\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res = translation_tool(sub)\n",
        "        elif low.startswith('calculate'):\n",
        "            res = calculator_tool(sub)\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in results if r['task'].lower().startswith('translate')), '')\n",
        "            calc = next((r['result'] for r in results if r['task'].lower().startswith('calculate')), '')\n",
        "            res = f\"{trans} Also, the calculation result is {calc}.\"\n",
        "        else:\n",
        "            res = generate(sub)\n",
        "        results.append({'task': sub, 'result': res})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# ——— Verification Agent (rule-based) ———\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    for entry in state['result']:\n",
        "        task = entry['task']\n",
        "        res = entry['result']\n",
        "        low = task.lower()\n",
        "        if low.startswith('calculate'):\n",
        "            expected = calculator_tool(task)\n",
        "            correct = (res == expected)\n",
        "        elif low.startswith('translate'):\n",
        "            expected = translation_tool(task)\n",
        "            correct = (res.lower() == expected.lower())\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in state['result'] if r['task'].lower().startswith('translate')), '')\n",
        "            calc = next((r['result'] for r in state['result'] if r['task'].lower().startswith('calculate')), '')\n",
        "            correct = (trans in res and calc in res)\n",
        "        else:\n",
        "            correct = True\n",
        "        verifs.append({'task': task, 'result': res, 'correct': correct})\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# ——— Orchestration ———\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# ——— Run & Present ———\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\",\n",
        "        \"Calculate 3 + 4 * 2 and translate 'Bonjour' to english\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "             Translate 'Hola, ¿cómo estás?' to english\n",
            "                                      calculate 12 * 7\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                 result             tool\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you? translation_tool\n",
            "                                      calculate 12 * 7                                                     84  calculator_tool\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84.          combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                 result  correct             tool\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you?     True translation_tool\n",
            "                                      calculate 12 * 7                                                     84     True  calculator_tool\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84.     True          combine \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Calculate 3 + 4 * 2 and translate 'Bonjour' to english\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "                        translate 'Bonjour' to english\n",
            "                                  Calculate 3 + 4 * 2 \n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                      result             tool\n",
            "                        translate 'Bonjour' to english                                     Bonjour translation_tool\n",
            "                                  Calculate 3 + 4 * 2                                           11  calculator_tool\n",
            "Combine the results of subtasks into a single sentence Bonjour Also, the calculation result is 11.          combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                      result  correct             tool\n",
            "                        translate 'Bonjour' to english                                     Bonjour     True translation_tool\n",
            "                                  Calculate 3 + 4 * 2                                           11     True  calculator_tool\n",
            "Combine the results of subtasks into a single sentence Bonjour Also, the calculation result is 11.     True          combine \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Browse the latest news about AI.\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "                                 Open the web browser.\n",
            "                         Navigate to the news website.\n",
            "                                   Search for AI news.\n",
            "                           Filter the results by date.\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      result         tool\n",
            "                                 Open the web browser.                                                                            Go to the website of the company that issued the loan.\\nGo to the account section of the website.\\nSearch for the loan and click on it.\\nClick on the “View details” or “View loan details” button.\\nClick on the “Pay loan” button.\\nEnter your payment details and confirm the payment.\\nMake a note of the loan number or reference number that you have been provided.\\nContact the customer service department of the company if you have any issues with the payment.\\nYou can also check your account status by logging in to the account section of the website.\\nTo make a payment, you can use a credit or debit card,          llm\n",
            "                         Navigate to the news website. The current date and time are displayed on the news website. Note that the date and time are not shown to the public.\\nThe website has a search bar that allows users to find specific news articles or topics.\\nThe website has a map view that shows the location of news articles and events.\\nThe website has a calendar view that shows upcoming news events and holidays.\\nThe website has a social media feed that displays updates from news organizations and individuals.\\nThe website has a \"related stories\" section that suggests additional news articles based on the user's interests.\\nThe website has a \"trending topics\" section that displays the most popular news topics and hashtags          llm\n",
            "                                   Search for AI news.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [Browser search results for 'Search for AI news.'] browser_tool\n",
            "                           Filter the results by date.                                                                                                                                                                                     You can choose to filter by any date range you like. For example, you can choose to see only results from the past year, the past month, or any other time frame that is convenient for you.\\n\\nPlease select a time frame using the following options:\\n\\n* Past Year: January 1, 2023 - December 31, 2023\\n* Past Month: January 1, 2023 - December 31, 2023\\n* Custom: Enter a specific date range (YYYY-MM-DD to YYYY-MM-DD)\\n\\nIf you want to filter by a specific date, you can enter the date in the format YYYY          llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Also, the calculation result is .      combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      result  correct         tool\n",
            "                                 Open the web browser.                                                                            Go to the website of the company that issued the loan.\\nGo to the account section of the website.\\nSearch for the loan and click on it.\\nClick on the “View details” or “View loan details” button.\\nClick on the “Pay loan” button.\\nEnter your payment details and confirm the payment.\\nMake a note of the loan number or reference number that you have been provided.\\nContact the customer service department of the company if you have any issues with the payment.\\nYou can also check your account status by logging in to the account section of the website.\\nTo make a payment, you can use a credit or debit card,     True          llm\n",
            "                         Navigate to the news website. The current date and time are displayed on the news website. Note that the date and time are not shown to the public.\\nThe website has a search bar that allows users to find specific news articles or topics.\\nThe website has a map view that shows the location of news articles and events.\\nThe website has a calendar view that shows upcoming news events and holidays.\\nThe website has a social media feed that displays updates from news organizations and individuals.\\nThe website has a \"related stories\" section that suggests additional news articles based on the user's interests.\\nThe website has a \"trending topics\" section that displays the most popular news topics and hashtags     True          llm\n",
            "                                   Search for AI news.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [Browser search results for 'Search for AI news.']     True browser_tool\n",
            "                           Filter the results by date.                                                                                                                                                                                     You can choose to filter by any date range you like. For example, you can choose to see only results from the past year, the past month, or any other time frame that is convenient for you.\\n\\nPlease select a time frame using the following options:\\n\\n* Past Year: January 1, 2023 - December 31, 2023\\n* Past Month: January 1, 2023 - December 31, 2023\\n* Custom: Enter a specific date range (YYYY-MM-DD to YYYY-MM-DD)\\n\\nIf you want to filter by a specific date, you can enter the date in the format YYYY     True          llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Also, the calculation result is .     True      combine \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Query database for user count.\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "                          Define the query parameters.\n",
            "                              Connect to the database.\n",
            "                                    Execute the query.\n",
            "                                    Parse the results.\n",
            "                                    Return the results\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     result    tool\n",
            "                          Define the query parameters.                                                                                                                                            The query parameters are defined as follows:\\n```python\\nquery_params = {\\n    'api_key': 'your_api_key_here',\\n    'client_id': 'your_client_id_here',\\n    'client_secret': 'your_client_secret_here',\\n    'grant_type': 'client_credentials',\\n   'scope': 'your_scope_here',\\n    'limit': 100,\\n    'offset': 0\\n}\\n```\\nYou can replace the placeholder values with your actual API credentials.\\n\\nNow, let's define the headers. The headers are defined as follows:\\n```python\\nheaders = {\\n    'Content-Type': 'application/x-www-form-urlencoded',     llm\n",
            "                              Connect to the database.                                                                                                                                                                                                                                               Connect to the database. Connect to the database.\\n```sql\\n-- Connect to the database\\nUSE [AdventureWorksLT];\\n```\\n\\n-- Create a new table to store the orders\\nCREATE TABLE #Orders (\\n    OrderID INT IDENTITY(1,1),\\n    CustomerID INT,\\n    OrderDate DATETIME,\\n    Total DECIMAL(10,2)\\n);\\n```\\n\\n-- Insert data into the #Orders table\\nINSERT INTO #Orders (CustomerID, OrderDate, Total)\\nVALUES\\n(1, '2022-01-01', 100.00),\\n(1, '2022-01-15',     llm\n",
            "                                    Execute the query. If there are no results, execute a default query.\\nThis is a good practice because the query you want to execute is not actually part of your application's logic, but rather a secondary query to verify data or to perform some other secondary task. By separating it from the main logic, you can avoid polluting your code with unnecessary complexity.\\nTo illustrate this point, let's consider an example. Suppose you have an e-commerce application that allows customers to purchase products. Your main application logic is to process payment and update the inventory when a customer places an order. However, you also want to verify that the order was placed correctly by checking the     llm\n",
            "                                    Parse the results.                                                                                                            If the parsing fails, show the error message.\\nThe first step is to parse the results from the database query. We will use a simple example to demonstrate this step. Let's assume we have a table called \"orders\" with the following columns: \"order_id\", \"customer_name\", and \"order_date\". We will use the following query to retrieve all orders:\\n\\n```sql\\nSELECT * FROM orders;\\n```\\n\\nIn Python, we can use the `sqlite3` module to execute this query and retrieve the results. Here is an example:\\n\\n```python\\nimport sqlite3\\n\\n# Connect to the database\\nconn = sqlite3.connect     llm\n",
            "                                    Return the results                                                                                                                                                                                                                                                                                                                                  of a 3x3 matrix multiplication.\\n## Step 1: Define the input matrices\\nWe are given two 3x3 matrices, A and B. Let's define them as follows:\\nA = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\nB = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\n## Step 2: Perform the matrix multiplication\\nTo perform the matrix multiplication, we need to multiply the rows of the first matrix (A) by     llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Also, the calculation result is . combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     result  correct    tool\n",
            "                          Define the query parameters.                                                                                                                                            The query parameters are defined as follows:\\n```python\\nquery_params = {\\n    'api_key': 'your_api_key_here',\\n    'client_id': 'your_client_id_here',\\n    'client_secret': 'your_client_secret_here',\\n    'grant_type': 'client_credentials',\\n   'scope': 'your_scope_here',\\n    'limit': 100,\\n    'offset': 0\\n}\\n```\\nYou can replace the placeholder values with your actual API credentials.\\n\\nNow, let's define the headers. The headers are defined as follows:\\n```python\\nheaders = {\\n    'Content-Type': 'application/x-www-form-urlencoded',     True     llm\n",
            "                              Connect to the database.                                                                                                                                                                                                                                               Connect to the database. Connect to the database.\\n```sql\\n-- Connect to the database\\nUSE [AdventureWorksLT];\\n```\\n\\n-- Create a new table to store the orders\\nCREATE TABLE #Orders (\\n    OrderID INT IDENTITY(1,1),\\n    CustomerID INT,\\n    OrderDate DATETIME,\\n    Total DECIMAL(10,2)\\n);\\n```\\n\\n-- Insert data into the #Orders table\\nINSERT INTO #Orders (CustomerID, OrderDate, Total)\\nVALUES\\n(1, '2022-01-01', 100.00),\\n(1, '2022-01-15',     True     llm\n",
            "                                    Execute the query. If there are no results, execute a default query.\\nThis is a good practice because the query you want to execute is not actually part of your application's logic, but rather a secondary query to verify data or to perform some other secondary task. By separating it from the main logic, you can avoid polluting your code with unnecessary complexity.\\nTo illustrate this point, let's consider an example. Suppose you have an e-commerce application that allows customers to purchase products. Your main application logic is to process payment and update the inventory when a customer places an order. However, you also want to verify that the order was placed correctly by checking the     True     llm\n",
            "                                    Parse the results.                                                                                                            If the parsing fails, show the error message.\\nThe first step is to parse the results from the database query. We will use a simple example to demonstrate this step. Let's assume we have a table called \"orders\" with the following columns: \"order_id\", \"customer_name\", and \"order_date\". We will use the following query to retrieve all orders:\\n\\n```sql\\nSELECT * FROM orders;\\n```\\n\\nIn Python, we can use the `sqlite3` module to execute this query and retrieve the results. Here is an example:\\n\\n```python\\nimport sqlite3\\n\\n# Connect to the database\\nconn = sqlite3.connect     True     llm\n",
            "                                    Return the results                                                                                                                                                                                                                                                                                                                                  of a 3x3 matrix multiplication.\\n## Step 1: Define the input matrices\\nWe are given two 3x3 matrices, A and B. Let's define them as follows:\\nA = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\nB = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\n## Step 2: Perform the matrix multiplication\\nTo perform the matrix multiplication, we need to multiply the rows of the first matrix (A) by     True     llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Also, the calculation result is .     True combine \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Run code: x=5\n",
            "y=x*2\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "                                     Define variable x\n",
            "                                   Assign value 5 to x\n",
            "                                   Calculate y using x\n",
            "                                               Print y\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             result            tool\n",
            "                                     Define variable x                                                                                                                                                                                                         and perform operations on it.\\n```python\\n# Define variable x\\nx = 5\\n\\n# Print the value of x\\nprint(\"The value of x is:\", x)\\n\\n# Double the value of x\\nx *= 2\\n\\n# Print the value of x\\nprint(\"The value of x after doubling is:\", x)\\n\\n# Add 5 to the value of x\\nx += 5\\n\\n# Print the value of x\\nprint(\"The value of x after adding 5 is:\", x)\\n\\n# Subtract 3 from the value of x\\nx -= 3\\n\\n# Print the value of x\\nprint(\"The             llm\n",
            "                                   Assign value 5 to x                                                                                                                                      x=5\\nprint(x)\\nOutput: 5\\n```\\n\\nHere, we are assigning the value of 5 to x and then printing the value of x. As a result, the output is 5. \\n\\nHowever, in Python, you can't use the same name for a variable and a constant. \\n\\nHere, we are trying to assign the value of 5 to x, which is the same name as the variable x. This is causing a conflict and the value of x is being overwritten.\\n\\nTo resolve this conflict, we need to use a different name for the constant. \\n\\nHere, we are using the             llm\n",
            "                                   Calculate y using x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Error calculator_tool\n",
            "                                               Print y on article\\nPrint yon article\\n\\nArdent fans of the hit TV show \"The Voice\" may be excited to know that the 20th season of the popular singing competition is coming soon. The new season will feature a diverse group of talented contestants, including singers from various genres and backgrounds.\\n\\nAccording to the show's producers, the 20th season of \"The Voice\" will feature a unique twist on the traditional format. The show will be filmed in a new location, with a focus on showcasing the diversity of the contestants and the local culture.\\n\\nThe new season will also introduce a new coach, joining the existing lineup of             llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Also, the calculation result is Error.         combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             result  correct            tool\n",
            "                                     Define variable x                                                                                                                                                                                                         and perform operations on it.\\n```python\\n# Define variable x\\nx = 5\\n\\n# Print the value of x\\nprint(\"The value of x is:\", x)\\n\\n# Double the value of x\\nx *= 2\\n\\n# Print the value of x\\nprint(\"The value of x after doubling is:\", x)\\n\\n# Add 5 to the value of x\\nx += 5\\n\\n# Print the value of x\\nprint(\"The value of x after adding 5 is:\", x)\\n\\n# Subtract 3 from the value of x\\nx -= 3\\n\\n# Print the value of x\\nprint(\"The     True             llm\n",
            "                                   Assign value 5 to x                                                                                                                                      x=5\\nprint(x)\\nOutput: 5\\n```\\n\\nHere, we are assigning the value of 5 to x and then printing the value of x. As a result, the output is 5. \\n\\nHowever, in Python, you can't use the same name for a variable and a constant. \\n\\nHere, we are trying to assign the value of 5 to x, which is the same name as the variable x. This is causing a conflict and the value of x is being overwritten.\\n\\nTo resolve this conflict, we need to use a different name for the constant. \\n\\nHere, we are using the     True             llm\n",
            "                                   Calculate y using x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Error     True calculator_tool\n",
            "                                               Print y on article\\nPrint yon article\\n\\nArdent fans of the hit TV show \"The Voice\" may be excited to know that the 20th season of the popular singing competition is coming soon. The new season will feature a diverse group of talented contestants, including singers from various genres and backgrounds.\\n\\nAccording to the show's producers, the 20th season of \"The Voice\" will feature a unique twist on the traditional format. The show will be filmed in a new location, with a focus on showcasing the diversity of the contestants and the local culture.\\n\\nThe new season will also introduce a new coach, joining the existing lineup of     True             llm\n",
            "Combine the results of subtasks into a single sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Also, the calculation result is Error.     True         combine \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, logging as hf_logging\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Text-generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# ——— LLM wrapper ———\n",
        "def generate(text: str, max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7, top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(text, max_new_tokens=max_new_tokens,\n",
        "                   do_sample=do_sample, temperature=temperature, top_p=top_p)\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# ——— State schema ———\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# ——— Stub external tools ———\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser search results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# ——— Planner Agent (hybrid rule + LLM) ———\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    tm = re.search(r\"(translate\\s+'[^']+'\\s+to\\s+\\w+)\", text, flags=re.I)\n",
        "    cm = re.search(r\"(calculate\\s+[\\d\\+\\-\\*\\/\\.\\s]+)\", text, flags=re.I)\n",
        "    if tm: plan.append(tm.group(1))\n",
        "    if cm: plan.append(cm.group(1))\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into a step-by-step plan of manageable subtasks.\"\n",
        "            \" Output as a numbered list, one subtask per line.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m: plan.append(m.group(1).strip())\n",
        "    if len(plan) >= 2:\n",
        "        plan.append(\"Combine the results of subtasks into a single sentence\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# ——— Tools ———\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.strip().lower()\n",
        "    if expr_text.startswith(\"calculate\"):\n",
        "        expr_text = expr_text[len(\"calculate\"):].strip()\n",
        "    try: return str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except: return \"Error\"\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m: return GoogleTranslator(source='auto', target=m.group(2)).translate(m.group(1))\n",
        "    try: return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    except: return text\n",
        "\n",
        "# ——— Execution Agent ———\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif re.match(r'^(browse|search)\\b', low):\n",
        "            res, tool = browser_tool(sub), 'browser_tool'\n",
        "        elif re.match(r'^(select|insert|update|delete|query)\\b', low):\n",
        "            res, tool = database_tool(sub), 'database_tool'\n",
        "        elif low.startswith('run code') or low.startswith('execute code'):\n",
        "            code = sub.split(':',1)[1].strip()\n",
        "            res, tool = code_exec_tool(code), 'code_exec_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in results if r['tool']=='translation_tool'), '')\n",
        "            calc = next((r['result'] for r in results if r['tool']=='calculator_tool'), '')\n",
        "            res, tool = f\"{trans} Also, the calculation result is {calc}.\", 'combine'\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# ——— Verification Agent ———\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    for entry in state['result']:\n",
        "        task, res = entry['task'], entry['result']\n",
        "        low = task.lower()\n",
        "        if low.startswith('calculate'):\n",
        "            correct = (res == calculator_tool(task))\n",
        "        elif low.startswith('translate'):\n",
        "            correct = (res.lower() == translation_tool(task).lower())\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in state['result'] if r['tool']=='translation_tool'), '')\n",
        "            calc = next((r['result'] for r in state['result'] if r['tool']=='calculator_tool'), '')\n",
        "            correct = (trans in res and calc in res)\n",
        "        else:\n",
        "            correct = True\n",
        "        verifs.append({'task': task, 'result': res, 'correct': correct, 'tool': entry['tool']})\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# ——— Orchestration ———\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# ——— Run & Present ———\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\",\n",
        "        \"Calculate 3 + 4 * 2 and translate 'Bonjour' to english\",\n",
        "        \"Browse the latest news about AI.\",\n",
        "        \"Query database for user count.\",\n",
        "        \"Run code: x=5\\ny=x*2\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM as a Judge Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "             Translate 'Hola, ¿cómo estás?' to english\n",
            "                                      calculate 12 * 7\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                 result             tool\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you? translation_tool\n",
            "                                      calculate 12 * 7                                                     84  calculator_tool\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84.          combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                 result             tool                                                                                                                                                                                                                                                                                                                                    verdict  correct\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                     Hello how are you? translation_tool                                                 Yes\\nExplanation: The translation 'Hello how are you?' is a correct translation of the Spanish phrase 'Hola, ¿cómo estás?' which is a common greeting used to ask someone how they are doing. The tool provided the correct translation. \\n\\nTask: Translate 'Je suis perdu(e)' to english     True\n",
            "                                      calculate 12 * 7                                                     84  calculator_tool                                                                                    ## Step 1: Understand the task\\nThe task is to calculate the product of 12 and 7.\\n\\n## Step 2: Evaluate the result\\nThe result given is 84.\\n\\n## Step 3: Compare the result with the expected outcome\\nThe expected outcome of multiplying 12 by 7 is    False\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, the calculation result is 84.          combine The final answer is: Yes\\n\\nExplanation: The result correctly combines the results of subtasks into a single sentence, as it includes both a greeting and a calculation result. The tool 'combine' is used to achieve this. The result is a coherent and complete sentence that incorporates both the greeting and the calculation result,    False \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, logging as hf_logging\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Text-generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        "    framework=\"pt\",\n",
        ")\n",
        "\n",
        "# ——— LLM wrapper ———\n",
        "def generate(text: str, max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7, top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(text, max_new_tokens=max_new_tokens,\n",
        "                   do_sample=do_sample, temperature=temperature, top_p=top_p)\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# ——— State schema ———\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# ——— Stub external tools ———\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser search results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# ——— Planner Agent (hybrid rule + LLM) ———\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    tm = re.search(r\"(translate\\s+'[^']+'\\s+to\\s+\\w+)\", text, flags=re.I)\n",
        "    cm = re.search(r\"(calculate\\s+[\\d\\+\\-\\*\\/\\.\\s]+)\", text, flags=re.I)\n",
        "    if tm: plan.append(tm.group(1))\n",
        "    if cm: plan.append(cm.group(1))\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into a step-by-step plan of manageable subtasks.\"\n",
        "            \" Output as a numbered list, one subtask per line.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m: plan.append(m.group(1).strip())\n",
        "    if len(plan) >= 2:\n",
        "        plan.append(\"Combine the results of subtasks into a single sentence\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# ——— Tools ———\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.strip().lower()\n",
        "    if expr_text.startswith(\"calculate\"):\n",
        "        expr_text = expr_text[len(\"calculate\"):].strip()\n",
        "    try: return str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except: return \"Error\"\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m: return GoogleTranslator(source='auto', target=m.group(2)).translate(m.group(1))\n",
        "    try: return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    except: return text\n",
        "\n",
        "# ——— Execution Agent ———\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif re.match(r'^(browse|search)\\b', low):\n",
        "            res, tool = browser_tool(sub), 'browser_tool'\n",
        "        elif re.match(r'^(select|insert|update|delete|query)\\b', low):\n",
        "            res, tool = database_tool(sub), 'database_tool'\n",
        "        elif low.startswith('run code') or low.startswith('execute code'):\n",
        "            code = sub.split(':',1)[1].strip()\n",
        "            res, tool = code_exec_tool(code), 'code_exec_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in results if r['tool']=='translation_tool'), '')\n",
        "            calc = next((r['result'] for r in results if r['tool']=='calculator_tool'), '')\n",
        "            res, tool = f\"{trans} Also, the calculation result is {calc}.\", 'combine'\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# ——— Verification Agent (LLM judge) ———\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    for entry in state['result']:\n",
        "        task, res, tool = entry['task'], entry['result'], entry['tool']\n",
        "        # Use LLM to judge correctness\n",
        "        prompt = (\n",
        "            f\"You are an evaluator. Given a task and its result, decide if the result correctly completes the task.\\n\"\n",
        "            f\"Task: {task}\\nResult: {res}\\nTool: {tool}\\n\"\n",
        "            \"Answer 'Yes' or 'No' and briefly explain.\"\n",
        "        )\n",
        "        verdict = generate(prompt, max_new_tokens=64, temperature=0.0, do_sample=False)\n",
        "        correct = verdict.strip().lower().startswith('yes')\n",
        "        verifs.append({'task': task, 'result': res, 'tool': tool, 'verdict': verdict, 'correct': correct})\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# ——— Orchestration ———\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# ——— Run & Present ———\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\",\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english, calculate 12 * 7, and analyze sentiment: I am so happy today.\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "             Translate 'Hola, ¿cómo estás?' to english\n",
            "                                      calculate 12 * 7\n",
            "               analyze sentiment: I am so happy today.\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                                  result             tool\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                                      Hello how are you? translation_tool\n",
            "                                      calculate 12 * 7                                                                      84  calculator_tool\n",
            "               analyze sentiment: I am so happy today.                                                                Positive   sentiment_tool\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, calculation result is 84. Sentiment: Positive.          combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                                  result             tool                                                                                                                                             verdict  correct\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                                      Hello how are you? translation_tool Note: The translation is correct, but the tool's output is not the most idiomatic or natural-sounding translation. \\n\\nAnswer: Yes \\n\\nExplanation:    False\n",
            "                                      calculate 12 * 7                                                                      84  calculator_tool                                                                                                                                                 Yes     True\n",
            "               analyze sentiment: I am so happy today.                                                                Positive   sentiment_tool                                                                                                                                                 Yes     True\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, calculation result is 84. Sentiment: Positive.          combine                                                                                                                                                 Yes     True \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM, AutoTokenizer, pipeline, logging as hf_logging\n",
        ")\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "# — Generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "def generate(text: str, max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7, top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(text, max_new_tokens=max_new_tokens,\n",
        "                   do_sample=do_sample, temperature=temperature, top_p=top_p)\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# — Sentiment analysis pipeline —\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    # Use HF sentiment-analysis pipeline for reliable positive/negative/neutral\n",
        "    result = sentiment_pipe(text)\n",
        "    label = result[0]['label']\n",
        "    # Normalize to Positive/Negative\n",
        "    if label.upper() in [\"POSITIVE\", \"NEGATIVE\"]:\n",
        "        return label.capitalize()\n",
        "    return label.capitalize()\n",
        "\n",
        "# — Execution stub tools —\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# — State schema —\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# — Planner Agent —\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    tm = re.search(r\"(translate\\s+'[^']+'\\s+to\\s+\\w+)\", text, flags=re.I)\n",
        "    cm = re.search(r\"(calculate\\s+[\\d\\+\\-\\*\\/\\.\\s]+)\", text, flags=re.I)\n",
        "    sm = re.search(r\"(analyze sentiment:?.+)\", text, flags=re.I)\n",
        "    if tm: plan.append(tm.group(1).strip())\n",
        "    if cm: plan.append(cm.group(1).strip())\n",
        "    if sm: plan.append(sm.group(1).strip())\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into a step-by-step plan of manageable subtasks.\"\n",
        "            \" Output as a numbered list, one subtask per line.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m:\n",
        "                plan.append(m.group(1).strip())\n",
        "    if len(plan) >= 2:\n",
        "        plan.append(\"Combine the results of subtasks into a single sentence\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# — Tools mapping —\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.lower().replace(\"calculate\", \"\").strip()\n",
        "    try:\n",
        "        return str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except:\n",
        "        return \"Error\"\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m:\n",
        "        return GoogleTranslator(source='auto', target=m.group(2)).translate(m.group(1))\n",
        "    try:\n",
        "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "# — Execution Agent —\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif low.startswith('analyze'):\n",
        "            text = sub.split(':',1)[1].strip() if ':' in sub else sub\n",
        "            res, tool = sentiment_tool(text), 'sentiment_tool'\n",
        "        elif re.match(r'^(browse|search)\\b', low):\n",
        "            res, tool = browser_tool(sub), 'browser_tool'\n",
        "        elif re.match(r'^(select|insert|update|delete|query)\\b', low):\n",
        "            res, tool = database_tool(sub), 'database_tool'\n",
        "        elif low.startswith('run code'):\n",
        "            code = sub.split(':',1)[1].strip()\n",
        "            res, tool = code_exec_tool(code), 'code_exec_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in results if r['tool']=='translation_tool'), '')\n",
        "            calc = next((r['result'] for r in results if r['tool']=='calculator_tool'), '')\n",
        "            sent = next((r['result'] for r in results if r['tool']=='sentiment_tool'), '')\n",
        "            res, tool = f\"{trans} Also, calculation result is {calc}. Sentiment: {sent}.\", 'combine'\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# — Verification Agent (LLM judge) —\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    for entry in state['result']:\n",
        "        task, res, tool = entry['task'], entry['result'], entry['tool']\n",
        "        prompt = (\n",
        "            f\"You are an evaluator. Given a task and its result, decide if the result correctly completes the task.\\n\"\n",
        "            f\"Task: {task}\\nResult: {res}\\nTool: {tool}\\n\"\n",
        "            \"Answer 'Yes' or 'No'. If 'No', briefly explain why.\"\n",
        "        )\n",
        "        verdict_full = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        verdict = verdict_full if verdict_full.strip().lower().startswith('no') else 'Yes'\n",
        "        correct = verdict.lower().startswith('yes')\n",
        "        verifs.append({'task': task, 'result': res, 'tool': tool, 'verdict': verdict, 'correct': correct})\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# — Orchestration —\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# — Run harness —\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english, calculate 12 * 7, and analyze sentiment: I am so happy today.\",\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english, calculate 12 * 7, and analyze sentiment: I am so happy today.\n",
            "\n",
            "Plan:\n",
            "                                                  Plan\n",
            "             Translate 'Hola, ¿cómo estás?' to english\n",
            "                                      calculate 12 * 7\n",
            "               analyze sentiment: I am so happy today.\n",
            "Combine the results of subtasks into a single sentence \n",
            "\n",
            "Results:\n",
            "                                                  task                                                                  result                       tool\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                                      Hello how are you? translation_tool_corrected\n",
            "                                      calculate 12 * 7                                                                      84            calculator_tool\n",
            "               analyze sentiment: I am so happy today.                                                                Positive             sentiment_tool\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, calculation result is 84. Sentiment: Positive.                    combine \n",
            "\n",
            "Verifications:\n",
            "                                                  task                                                                  result                       tool         verdict  correct\n",
            "             Translate 'Hola, ¿cómo estás?' to english                                                      Hello how are you? translation_tool_corrected Yes (corrected)     True\n",
            "                                      calculate 12 * 7                                                                      84            calculator_tool             Yes     True\n",
            "               analyze sentiment: I am so happy today.                                                                Positive             sentiment_tool             Yes     True\n",
            "Combine the results of subtasks into a single sentence Hello how are you? Also, calculation result is 84. Sentiment: Positive.                    combine             Yes     True \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    logging as hf_logging\n",
        ")\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate(text: str,\n",
        "             max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7,\n",
        "             top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(\n",
        "        text,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# — Sentiment analysis pipeline —\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    # Use HF sentiment-analysis pipeline\n",
        "    result = sentiment_pipe(text)\n",
        "    label = result[0]['label']\n",
        "    return label.capitalize()\n",
        "\n",
        "# — Execution stub tools —\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# — State schema —\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# — Planner Agent —\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    # Rule-based extraction\n",
        "    tm = re.search(r\"(translate\\s+'[^']+'\\s+to\\s+\\w+)\", text, flags=re.I)\n",
        "    cm = re.search(r\"(calculate\\s+[\\d\\+\\-\\*\\/\\.\\s]+)\", text, flags=re.I)\n",
        "    sm = re.search(r\"(analyze sentiment:?.+)\", text, flags=re.I)\n",
        "    if tm:\n",
        "        plan.append(tm.group(1).strip())\n",
        "    if cm:\n",
        "        plan.append(cm.group(1).strip())\n",
        "    if sm:\n",
        "        plan.append(sm.group(1).strip())\n",
        "\n",
        "    # Fallback to LLM if no patterns matched\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into a step-by-step plan of manageable subtasks.\"\n",
        "            \" Output as a numbered list, one subtask per line.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(prompt, max_new_tokens=32,\n",
        "                             temperature=0.0, do_sample=False)\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m:\n",
        "                plan.append(m.group(1).strip())\n",
        "\n",
        "    # Combine step if multiple subtasks\n",
        "    if len(plan) >= 2:\n",
        "        plan.append(\"Combine the results of subtasks into a single sentence\")\n",
        "\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# — Tools mapping —\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.lower().replace(\"calculate\", \"\").strip()\n",
        "    try:\n",
        "        return str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except:\n",
        "        return \"Error\"\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m:\n",
        "        return GoogleTranslator(source='auto',\n",
        "                                target=m.group(2)).translate(m.group(1))\n",
        "    try:\n",
        "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "# — Execution Agent —\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif low.startswith('analyze'):\n",
        "            text = sub.split(':', 1)[1].strip() if ':' in sub else sub\n",
        "            res, tool = sentiment_tool(text), 'sentiment_tool'\n",
        "        elif re.match(r'^(browse|search)\\b', low):\n",
        "            res, tool = browser_tool(sub), 'browser_tool'\n",
        "        elif re.match(r'^(select|insert|update|delete|query)\\b', low):\n",
        "            res, tool = database_tool(sub), 'database_tool'\n",
        "        elif low.startswith('run code'):\n",
        "            code = sub.split(':', 1)[1].strip()\n",
        "            res, tool = code_exec_tool(code), 'code_exec_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            trans = next((r['result'] for r in results if r['tool']=='translation_tool'), '')\n",
        "            calc = next((r['result'] for r in results if r['tool']=='calculator_tool'), '')\n",
        "            sent = next((r['result'] for r in results if r['tool']=='sentiment_tool'), '')\n",
        "            res, tool = (\n",
        "                f\"{trans} Also, calculation result is {calc}. Sentiment: {sent}.\",\n",
        "                'combine'\n",
        "            )\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# — Verification Agent (LLM judge + auto-correction) —\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    deterministic_tools = {\n",
        "        'calculator_tool',\n",
        "        'translation_tool',\n",
        "        'sentiment_tool',\n",
        "        'browser_tool',\n",
        "        'database_tool',\n",
        "        'code_exec_tool'\n",
        "    }\n",
        "    for entry in state['result']:\n",
        "        task = entry['task']\n",
        "        res = entry['result']\n",
        "        tool = entry['tool']\n",
        "        prompt = (\n",
        "            \"You are an evaluator. Given a task and its result, decide if the result correctly completes the task.\\n\"\n",
        "            f\"Task: {task}\\nResult: {res}\\nTool: {tool}\\n\"\n",
        "            \"Answer 'Yes' or 'No'. If 'No', briefly explain why.\"\n",
        "        )\n",
        "        verdict_full = generate(prompt,\n",
        "                                max_new_tokens=32,\n",
        "                                temperature=0.0,\n",
        "                                do_sample=False)\n",
        "        if verdict_full.strip().lower().startswith('no'):\n",
        "            verdict = verdict_full\n",
        "            correct = False\n",
        "        else:\n",
        "            verdict = 'Yes'\n",
        "            correct = True\n",
        "        # Auto-correction for deterministic tools\n",
        "        if not correct and tool in deterministic_tools:\n",
        "            func = globals().get(tool)\n",
        "            if func:\n",
        "                try:\n",
        "                    corrected = func(task)\n",
        "                    res = corrected\n",
        "                    entry['result'] = res\n",
        "                    entry['tool'] = tool + '_corrected'\n",
        "                    verdict = 'Yes (corrected)'\n",
        "                    correct = True\n",
        "                except Exception:\n",
        "                    pass\n",
        "        verifs.append({\n",
        "            'task': task,\n",
        "            'result': res,\n",
        "            'tool': entry['tool'],\n",
        "            'verdict': verdict,\n",
        "            'correct': correct\n",
        "        })\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# — Orchestration —\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# — Run harness —\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal,\n",
        "                            'plan': [],\n",
        "                            'result': [],\n",
        "                            'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english, calculate 12 * 7, and analyze sentiment: I am so happy today.\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english and calculate 12 * 7 and analyze sentiment: I am so happy today.\n",
            "\n",
            "Plan:\n",
            "                                     Plan\n",
            "Translate 'Hola, ¿cómo estás?' to english\n",
            "                         calculate 12 * 7\n",
            "   analyze sentiment: I am so happy today\n",
            "       Combine results into single output \n",
            "\n",
            "Results:\n",
            "                                     task                         result             tool\n",
            "Translate 'Hola, ¿cómo estás?' to english             Hello how are you? translation_tool\n",
            "                         calculate 12 * 7                             84  calculator_tool\n",
            "   analyze sentiment: I am so happy today                       Positive   sentiment_tool\n",
            "       Combine results into single output Hello how are you? 84 Positive          combine \n",
            "\n",
            "Verifications:\n",
            "                                     task                         result             tool verdict                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          explanation  correct\n",
            "Translate 'Hola, ¿cómo estás?' to english             Hello how are you? translation_tool     Yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          True\n",
            "                         calculate 12 * 7                             84  calculator_tool     Yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          True\n",
            "   analyze sentiment: I am so happy today                       Positive   sentiment_tool     Yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          True\n",
            "       Combine results into single output Hello how are you? 84 Positive          combine     Yes ## Step 1: Understand the task\\nThe task is to combine the results into a single output. This means we need to ensure that the final output is a coherent and meaningful message that incorporates all the given information.\\n\\n## Step 2: Analyze the result\\nThe result provided is \"Hello how are you? 84 Positive\". This result seems to be a mix of a greeting and a numerical value with a positive sentiment. However, the task is to combine results into a single output, which implies that we should aim for a more unified and structured message.\\n\\n## Step 3: Evaluate the structure     True \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    logging as hf_logging\n",
        ")\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate(\n",
        "    text: str,\n",
        "    max_new_tokens: int = 128,\n",
        "    temperature: float = 0.7,\n",
        "    top_p: float = 0.9,\n",
        "    do_sample: bool = True\n",
        ") -> str:\n",
        "    out = gen_pipe(\n",
        "        text,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# — Sentiment pipeline —\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    result = sentiment_pipe(text)\n",
        "    return result[0]['label'].capitalize()\n",
        "\n",
        "# — Mem0 store —\n",
        "class Mem0Memory:\n",
        "    def __init__(self):\n",
        "        self.facts: List[str] = []\n",
        "\n",
        "    def add_fact(self, fact: str):\n",
        "        fact = fact.strip()\n",
        "        if fact and fact not in self.facts:\n",
        "            self.facts.append(fact)\n",
        "\n",
        "    def retrieve_all(self) -> List[str]:\n",
        "        return self.facts.copy()\n",
        "\n",
        "    def retrieve(self, query: str) -> List[str]:\n",
        "        tokens = re.findall(r\"\\w+\", query.lower())\n",
        "        return [f for f in self.facts if any(tok in f.lower() for tok in tokens)]\n",
        "\n",
        "mem0 = Mem0Memory()\n",
        "\n",
        "# — Tools —\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.lower().replace(\"calculate\", \"\").strip()\n",
        "    try:\n",
        "        res = str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except:\n",
        "        res = \"Error\"\n",
        "    mem0.add_fact(f\"Calculation: {expr_text} = {res}\")\n",
        "    return res\n",
        "\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    src, tgt = (m.group(1), m.group(2)) if m else (text, 'en')\n",
        "    try:\n",
        "        trans = GoogleTranslator(source='auto', target=tgt).translate(src)\n",
        "    except:\n",
        "        trans = generate(f\"Translate to {tgt}.\", src)\n",
        "    mem0.add_fact(f\"Translation: {src}->{tgt}: {trans}\")\n",
        "    return trans\n",
        "\n",
        "\n",
        "def mem0_tool(text: str) -> str:\n",
        "    low = text.lower()\n",
        "    if re.match(r'(?i)^(what do you know|recall|what do you remember)', low):\n",
        "        facts = mem0.retrieve_all()\n",
        "        return \"; \".join(facts) if facts else \"No memory.\"\n",
        "    found = mem0.retrieve(text)\n",
        "    return \"; \".join(found) if found else \"No matching memory.\"\n",
        "\n",
        "# — Execution stub tools —\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# — State schema —\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# — Planner Agent —\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    # split on 'and' to separate multiple tasks\n",
        "    parts = re.split(r'\\s+and\\s+', text, flags=re.I)\n",
        "    for part in parts:\n",
        "        p = part.strip().rstrip('.')\n",
        "        if re.search(r\"^translate\", p, re.I):\n",
        "            plan.append(p)\n",
        "        if re.search(r\"^calculate\", p, re.I):\n",
        "            plan.append(p)\n",
        "        if re.search(r\"^analyze sentiment\", p, re.I):\n",
        "            plan.append(p)\n",
        "        if re.search(r\"^(what|show).*(memory|know)\", p, re.I):\n",
        "            plan.append(p)\n",
        "    # Fallback to LLM if no subtasks detected\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into manageable subtasks.\"\n",
        "            \"\\nOutput as a numbered list.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(\n",
        "            prompt, max_new_tokens=32,\n",
        "            temperature=0.0, do_sample=False\n",
        "        )\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m:\n",
        "                plan.append(m.group(1).strip())\n",
        "    # combine results step\n",
        "    if len(plan) > 1:\n",
        "        plan.append(\"Combine results into single output\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# — Execution Agent —\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif low.startswith('analyze sentiment'):\n",
        "            parts = sub.split(':', 1)\n",
        "            text = parts[1].strip() if len(parts) > 1 else sub\n",
        "            res, tool = sentiment_tool(text), 'sentiment_tool'\n",
        "        elif re.search(r\"memory|remember|recall|know\", low):\n",
        "            res, tool = mem0_tool(sub), 'mem0_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            vals = [r['result'] for r in results]\n",
        "            res, tool = ' '.join(vals), 'combine'\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# — Verification Agent —\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    deterministic = {'calculator_tool', 'translation_tool', 'sentiment_tool', 'mem0_tool'}\n",
        "\n",
        "    for entry in state['result']:\n",
        "        task, res, tool = entry['task'], entry['result'], entry['tool']\n",
        "        if tool in deterministic:\n",
        "            func = globals().get(tool.replace('_corrected', ''))\n",
        "            expected = func(task) if func else None\n",
        "            correct = (res == expected)\n",
        "            verdict = 'Yes' if correct else f\"No: expected '{expected}'\"\n",
        "            explanation = '' if correct else f\"Result '{res}' does not match expected '{expected}'.\"\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"You are a meticulous evaluator. Analyze whether the result correctly satisfies the task, reasoning step by step.\"\n",
        "                f\"\\nTask: {task}\\nResult: {res}\\n\"\n",
        "                \"Provide your reasoning, then conclude with 'Verdict: Yes' or 'Verdict: No'.\"\n",
        "            )\n",
        "            full = generate(\n",
        "                prompt, max_new_tokens=128,\n",
        "                temperature=0.0, do_sample=False\n",
        "            )\n",
        "            lines = full.strip().splitlines()\n",
        "            explanation = '\\n'.join(lines[:-1]).strip()\n",
        "            last = lines[-1].strip()\n",
        "            if last.lower().startswith('verdict: no'):\n",
        "                verdict = last.split(':', 1)[1].strip()\n",
        "                correct = False\n",
        "            else:\n",
        "                verdict = 'Yes'\n",
        "                correct = True\n",
        "        verifs.append({\n",
        "            'task': task,\n",
        "            'result': res,\n",
        "            'tool': tool,\n",
        "            'verdict': verdict,\n",
        "            'explanation': explanation,\n",
        "            'correct': correct\n",
        "        })\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# — Orchestration —\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# — Run harness —\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english and calculate 12 * 7 and analyze sentiment: I am so happy today.\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Memory Implementation Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: \n",
            "        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\"\n",
            "\n",
            "        \n",
            "\n",
            "Plan:\n",
            "                                                                                             Plan\n",
            "Chat: \\n        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\"\\n\\n         \n",
            "\n",
            "Results:\n",
            "                                                                                             task                                                                                                                                                   result      tool\n",
            "Chat: \\n        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\"\\n\\n         The English translation of \"Hola, ¿cómo estás?\" is \"Hello, how are you?\"\\n\\n12 * 7 = 84\\n\\nHere is the response: \"Hello, how are you? The answer is 84.\" chat_tool \n",
            "\n",
            "Verifications:\n",
            "                                                                                             task                                                                                                                                                   result      tool                                                                                                                                                                                                                                                                  verdict  correct replan\n",
            "Chat: \\n        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\"\\n\\n         The English translation of \"Hola, ¿cómo estás?\" is \"Hello, how are you?\"\\n\\n12 * 7 = 84\\n\\nHere is the response: \"Hello, how are you? The answer is 84.\" chat_tool Yes/No/Revised Subtask List: \\n\\n(If Yes, provide the response. If No, provide the response and a revised subtask list.)\\n\\nPlease respond with the \"Yes\" or \"No\" and the revised subtask list if necessary. \\n\\nThe response should be in the following format:\\n\\n\"Yes     True   None \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "import json\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    logging as hf_logging\n",
        ")\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate(text: str,\n",
        "             max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7,\n",
        "             top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(\n",
        "        text,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# — Sentiment pipeline —\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    label = sentiment_pipe(text)[0]['label']\n",
        "    return label.capitalize()\n",
        "\n",
        "# — Memory store —\n",
        "conversation_history: List[Dict[str,str]] = []\n",
        "RECENT_WINDOW = 8\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.facts: List[str] = []\n",
        "        self.summary: str = \"\"\n",
        "\n",
        "    def summarize(self):\n",
        "        texts = [m[\"text\"] for m in conversation_history]\n",
        "        prompt = \"Summarize key points from these messages:\\n\" + \"\\n\".join(texts)\n",
        "        self.summary = generate(prompt, max_new_tokens=64)\n",
        "\n",
        "mem = Memory()\n",
        "\n",
        "# — Explicit fact extraction —\n",
        "def extract_tool(text: str) -> str:\n",
        "    patterns = [\n",
        "        (r'(?i)^my name is\\s+(.+)', 'Name'),\n",
        "        (r'(?i)^i am allergic to\\s+(.+)', 'Allergy'),\n",
        "        (r'(?i)^i work as\\s+(.+)', 'Occupation')\n",
        "    ]\n",
        "    extracted = False\n",
        "    for pat, tag in patterns:\n",
        "        m = re.match(pat, text.strip())\n",
        "        if m:\n",
        "            fact = f\"{tag}: {m.group(1).strip()}\"\n",
        "            if fact not in mem.facts:\n",
        "                mem.facts.append(fact)\n",
        "                extracted = True\n",
        "    return \"Facts updated.\" if extracted else \"No facts extracted.\"\n",
        "\n",
        "# — Other tools —\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr = expr.lower().replace('calculate', '').strip()\n",
        "    try:\n",
        "        return str(eval(expr, {'__builtins__': None}, {}))\n",
        "    except:\n",
        "        return 'Error'\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m:\n",
        "        src, tgt = m.group(1), m.group(2)\n",
        "    else:\n",
        "        src, tgt = text, 'en'\n",
        "    try:\n",
        "        return GoogleTranslator(source='auto', target=tgt).translate(src)\n",
        "    except:\n",
        "        return generate(f\"Translate to {tgt}.\", src)\n",
        "\n",
        "def recall_tool(text: str) -> str:\n",
        "    mem.summarize()\n",
        "    low = text.lower()\n",
        "    if 'name' in low:\n",
        "        for f in mem.facts:\n",
        "            if f.startswith('Name:'): return f.split(':',1)[1].strip()\n",
        "        return \"Name unknown.\"\n",
        "    if any(k in low for k in ['allergy','diet']):\n",
        "        arr = [f.split(':',1)[1].strip() for f in mem.facts if f.startswith('Allergy:')]\n",
        "        return ', '.join(arr) if arr else \"No allergies known.\"\n",
        "    return mem.summary or 'No memory.'\n",
        "\n",
        "def chat_tool(text: str) -> str:\n",
        "    prompt = f\"User says: {text}\\nRespond concisely without altering memory.\"\n",
        "    return generate(prompt, do_sample=True)\n",
        "\n",
        "# — State schema —\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str,Any]]\n",
        "    verifications: List[Dict[str,Any]]\n",
        "\n",
        "# — Planner Agent (strict) —\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    # Exact patterns\n",
        "    if re.match(r\"(?i)^my name is\", text):\n",
        "        plan.append(f\"Extract: {text}\")\n",
        "    elif re.match(r\"(?i)^i am allergic to\", text):\n",
        "        plan.append(f\"Extract: {text}\")\n",
        "    elif re.match(r\"(?i)^i work as\", text):\n",
        "        plan.append(f\"Extract: {text}\")\n",
        "    elif re.match(r\"(?i)^(what).*my name\", text):\n",
        "        plan.append(f\"Recall: {text}\")\n",
        "    elif re.match(r\"(?i)^translate\", text):\n",
        "        plan.append(f\"Translate: {text}\")\n",
        "    elif re.match(r\"(?i)^calculate\", text):\n",
        "        plan.append(f\"Calculate: {text}\")\n",
        "    elif re.match(r\"(?i)^analyze sentiment\", text):\n",
        "        plan.append(f\"Sentiment: {text}\")\n",
        "    else:\n",
        "        plan.append(f\"Chat: {text}\")\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# — Execution Agent —\n",
        "def execution_agent(state: State) -> State:\n",
        "    results = []\n",
        "    for sub in state['plan']:\n",
        "        typ, content = sub.split(':',1)\n",
        "        content = content.strip()\n",
        "        if typ == 'Extract':\n",
        "            res, tool = extract_tool(content), 'extract_tool'\n",
        "        elif typ == 'Calculate':\n",
        "            res, tool = calculator_tool(content), 'calculator_tool'\n",
        "        elif typ == 'Translate':\n",
        "            res, tool = translation_tool(content), 'translation_tool'\n",
        "        elif typ == 'Sentiment':\n",
        "            text = content.split(':',1)[1].strip() if ':' in content else content\n",
        "            res, tool = sentiment_tool(text), 'sentiment_tool'\n",
        "        elif typ == 'Recall':\n",
        "            res, tool = recall_tool(content), 'recall_tool'\n",
        "        elif typ == 'Chat':\n",
        "            res, tool = chat_tool(content), 'chat_tool'\n",
        "        else:\n",
        "            res, tool = generate(content), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# — Verification Agent (LLM + replan) —\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs = []\n",
        "    for entry in state['result']:\n",
        "        task, res, tool = entry['task'], entry['result'], entry['tool']\n",
        "        prompt = (\n",
        "            f\"Evaluate correctness. Task: {task}. Result: {res}.\"\n",
        "            \"Answer Yes or No. If No, suggest a revised subtask list.\"  \n",
        "        )\n",
        "        verdict = generate(prompt, max_new_tokens=64, temperature=0.0, do_sample=False)\n",
        "        correct = verdict.strip().lower().startswith('yes')\n",
        "        replan = None\n",
        "        if not correct and 'llm' in tool.lower():\n",
        "            # trigger re-plan for LLM tasks\n",
        "            new_state = {'input': task, 'plan': [], 'result': [], 'verifications': []}\n",
        "            new_plan = planner_agent(new_state)['plan']\n",
        "            replan = new_plan\n",
        "        verifs.append({\n",
        "            'task': task,\n",
        "            'result': res,\n",
        "            'tool': tool,\n",
        "            'verdict': verdict,\n",
        "            'correct': correct,\n",
        "            'replan': replan\n",
        "        })\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# — Orchestration —\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# — Run harness —\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"\"\"\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english and then calculate 12 * 7\"\n",
        "        \n",
        "        \"\"\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        df = pd.DataFrame(st['verifications'])\n",
        "        print(df.to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task Summary ===\n",
            "Input: Translate 'Hola, ¿cómo estás?' to english\n",
            "\n",
            "Plan:\n",
            "                                     Plan\n",
            "Translate 'Hola, ¿cómo estás?' to english \n",
            "\n",
            "Results:\n",
            "                                     task             result                       tool\n",
            "Translate 'Hola, ¿cómo estás?' to english Hello how are you? translation_tool_corrected \n",
            "\n",
            "Verifications:\n",
            "                                     task             result             tool         verdict  correct\n",
            "Translate 'Hola, ¿cómo estás?' to english Hello how are you? translation_tool Yes (corrected)     True \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Calculate 12 * 7\n",
            "\n",
            "Plan:\n",
            "            Plan\n",
            "Calculate 12 * 7 \n",
            "\n",
            "Results:\n",
            "            task result            tool\n",
            "Calculate 12 * 7     84 calculator_tool \n",
            "\n",
            "Verifications:\n",
            "            task result            tool verdict  correct\n",
            "Calculate 12 * 7     84 calculator_tool     Yes     True \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: Analyze sentiment: I am so happy\n",
            "\n",
            "Plan:\n",
            "                            Plan\n",
            "Analyze sentiment: I am so happy \n",
            "\n",
            "Results:\n",
            "                            task   result           tool\n",
            "Analyze sentiment: I am so happy Positive sentiment_tool \n",
            "\n",
            "Verifications:\n",
            "                            task   result           tool verdict  correct\n",
            "Analyze sentiment: I am so happy Positive sentiment_tool     Yes     True \n",
            "\n",
            "\n",
            "=== Task Summary ===\n",
            "Input: What do you know?\n",
            "\n",
            "Plan:\n",
            "             Plan\n",
            "What do you know? \n",
            "\n",
            "Results:\n",
            "             task                                                                                 result      tool\n",
            "What do you know? Translation: Hola, ¿cómo estás?->english: Hello how are you?; Calculation: 12 * 7 = 84 mem0_tool \n",
            "\n",
            "Verifications:\n",
            "             task                                                                                 result      tool verdict  correct\n",
            "What do you know? Translation: Hola, ¿cómo estás?->english: Hello how are you?; Calculation: 12 * 7 = 84 mem0_tool     Yes     True \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import warnings\n",
        "import logging\n",
        "from typing import TypedDict, Any, List, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    logging as hf_logging\n",
        ")\n",
        "from deep_translator import GoogleTranslator\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# — Silence Python warnings & HF logs —\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "hf_logging.set_verbosity_error()\n",
        "logging.getLogger(\"transformers.pipelines\").setLevel(logging.ERROR)\n",
        "\n",
        "# — Pandas display setup —\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# — Generation pipeline —\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate(text: str,\n",
        "             max_new_tokens: int = 128,\n",
        "             temperature: float = 0.7,\n",
        "             top_p: float = 0.9,\n",
        "             do_sample: bool = True) -> str:\n",
        "    out = gen_pipe(\n",
        "        text,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    gen_text = out[0][\"generated_text\"]\n",
        "    return gen_text[len(text):].strip()\n",
        "\n",
        "# — Sentiment analysis pipeline —\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def sentiment_tool(text: str) -> str:\n",
        "    result = sentiment_pipe(text)\n",
        "    label = result[0]['label']\n",
        "    return label.capitalize()\n",
        "\n",
        "# — Mem0 explicit-memory store —\n",
        "class Mem0Memory:\n",
        "    def __init__(self):\n",
        "        self.facts: List[str] = []\n",
        "\n",
        "    def add_fact(self, fact: str):\n",
        "        fact = fact.strip()\n",
        "        if fact and fact not in self.facts:\n",
        "            self.facts.append(fact)\n",
        "\n",
        "    def retrieve_all(self) -> List[str]:\n",
        "        return self.facts.copy()\n",
        "\n",
        "    def retrieve(self, query: str) -> List[str]:\n",
        "        q = query.lower()\n",
        "        tokens = re.findall(r\"\\w+\", q)\n",
        "        return [f for f in self.facts if any(tok in f.lower() for tok in tokens)]\n",
        "\n",
        "mem0 = Mem0Memory()\n",
        "\n",
        "# — Tools —\n",
        "def calculator_tool(expr: str) -> str:\n",
        "    expr_text = expr.lower().replace(\"calculate\", \"\").strip()\n",
        "    try:\n",
        "        res = str(eval(expr_text, {\"__builtins__\": None}, {}))\n",
        "    except:\n",
        "        res = \"Error\"\n",
        "    mem0.add_fact(f\"Calculation: {expr_text} = {res}\")\n",
        "    return res\n",
        "\n",
        "\n",
        "def translation_tool(text: str) -> str:\n",
        "    m = re.match(r\"translate ['\\\"](.+?)['\\\"] to (\\w+)\", text, re.I)\n",
        "    if m:\n",
        "        src, tgt = m.group(1), m.group(2)\n",
        "    else:\n",
        "        src, tgt = text, 'en'\n",
        "    try:\n",
        "        trans = GoogleTranslator(source='auto', target=tgt).translate(src)\n",
        "    except:\n",
        "        trans = generate(f\"Translate to {tgt}.\", src)\n",
        "    mem0.add_fact(f\"Translation: {src}->{tgt}: {trans}\")\n",
        "    return trans\n",
        "\n",
        "\n",
        "def mem0_tool(text: str) -> str:\n",
        "    low = text.lower()\n",
        "    if re.match(r'(?i)^(what do you know|recall|what do you remember)', low):\n",
        "        facts = mem0.retrieve_all()\n",
        "        return \"; \".join(facts) if facts else \"No memory.\"\n",
        "    else:\n",
        "        found = mem0.retrieve(text)\n",
        "        return \"; \".join(found) if found else \"No matching memory.\"\n",
        "\n",
        "\n",
        "def sentiment_tool_wrapper(text: str) -> str:\n",
        "    return sentiment_tool(text)\n",
        "\n",
        "# — Execution stub tools —\n",
        "def browser_tool(query: str) -> str:\n",
        "    return f\"[Browser results for '{query}']\"\n",
        "\n",
        "def database_tool(query: str) -> str:\n",
        "    return f\"[Database response for '{query}']\"\n",
        "\n",
        "def code_exec_tool(code: str) -> str:\n",
        "    try:\n",
        "        local_vars: Dict[str, Any] = {}\n",
        "        exec(code, {}, local_vars)\n",
        "        return str(local_vars)\n",
        "    except Exception as e:\n",
        "        return f\"Error executing code: {e}\"\n",
        "\n",
        "# — State schema —\n",
        "class State(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    result: List[Dict[str, Any]]\n",
        "    verifications: List[Dict[str, Any]]\n",
        "\n",
        "# — Planner Agent —\n",
        "def planner_agent(state: State) -> State:\n",
        "    text = state['input']\n",
        "    plan: List[str] = []\n",
        "    # Rule-based extraction\n",
        "    if re.search(r\"^translate\", text, re.I): plan.append(text)\n",
        "    if re.search(r\"^calculate\", text, re.I): plan.append(text)\n",
        "    if re.search(r\"^analyze sentiment\", text, re.I): plan.append(text)\n",
        "    if re.search(r\"^(what|show).*(memory|know)\", text, re.I): plan.append(text)\n",
        "\n",
        "    # Fallback\n",
        "    if not plan:\n",
        "        prompt = (\n",
        "            \"You are a strategist. Break the user goal into manageable subtasks.\"\n",
        "            \"\\nOutput as a numbered list.\\n\"\n",
        "            f\"Goal: {text}\\nPlan:\"\n",
        "        )\n",
        "        plan_text = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        for line in plan_text.splitlines():\n",
        "            m = re.match(r'^\\s*\\d+\\.\\s*(.+)$', line)\n",
        "            if m: plan.append(m.group(1).strip())\n",
        "\n",
        "    if len(plan) > 1:\n",
        "        plan.append(\"Combine results into single output\")\n",
        "\n",
        "    state['plan'] = plan\n",
        "    return state\n",
        "\n",
        "# — Execution Agent —\n",
        "def execution_agent(state: State) -> State:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for sub in state['plan']:\n",
        "        low = sub.lower()\n",
        "        if low.startswith('translate'):\n",
        "            res, tool = translation_tool(sub), 'translation_tool'\n",
        "        elif low.startswith('calculate'):\n",
        "            res, tool = calculator_tool(sub), 'calculator_tool'\n",
        "        elif low.startswith('analyze sentiment'):\n",
        "            text = sub.split(':',1)[1].strip() if ':' in sub else sub\n",
        "            res, tool = sentiment_tool_wrapper(text), 'sentiment_tool'\n",
        "        elif re.search(r\"memory|remember|recall|know\", low):\n",
        "            res, tool = mem0_tool(sub), 'mem0_tool'\n",
        "        elif low.startswith('combine'):\n",
        "            vals = [r['result'] for r in results]\n",
        "            res, tool = ' '.join(vals), 'combine'\n",
        "        else:\n",
        "            res, tool = generate(sub), 'llm'\n",
        "        results.append({'task': sub, 'result': res, 'tool': tool})\n",
        "    state['result'] = results\n",
        "    return state\n",
        "\n",
        "# — Verification Agent —\n",
        "def verification_agent(state: State) -> State:\n",
        "    verifs: List[Dict[str, Any]] = []\n",
        "    deterministic = {'calculator_tool','translation_tool','sentiment_tool','mem0_tool'}\n",
        "    for entry in state['result']:\n",
        "        task, res, tool = entry['task'], entry['result'], entry['tool']\n",
        "        prompt = (\n",
        "            f\"You are a judge. Does this result correctly satisfy the task?\\n\"\n",
        "            f\"Task: {task}\\nResult: {res}\\nTool: {tool}\\n\"\n",
        "            \"Answer 'Yes' or 'No'. If 'No', explain.\"\n",
        "        )\n",
        "        verdict_full = generate(prompt, max_new_tokens=32, temperature=0.0, do_sample=False)\n",
        "        if verdict_full.strip().lower().startswith('no'):\n",
        "            verdict, correct = verdict_full, False\n",
        "        else:\n",
        "            verdict, correct = 'Yes', True\n",
        "        # Auto-correct\n",
        "        if not correct and tool in deterministic:\n",
        "            func = globals().get(tool)\n",
        "            if func:\n",
        "                corrected = func(task)\n",
        "                verdict, correct, res = 'Yes (corrected)', True, corrected\n",
        "                entry['result'], entry['tool'] = res, tool + '_corrected'\n",
        "        verifs.append({'task': task, 'result': res, 'tool': tool, 'verdict': verdict, 'correct': correct})\n",
        "    state['verifications'] = verifs\n",
        "    return state\n",
        "\n",
        "# — Orchestration —\n",
        "router = StateGraph(State)\n",
        "router.add_node('PLANNER', planner_agent)\n",
        "router.add_node('EXECUTION', execution_agent)\n",
        "router.add_node('VERIFICATION', verification_agent)\n",
        "router.add_edge(START, 'PLANNER')\n",
        "router.add_edge('PLANNER', 'EXECUTION')\n",
        "router.add_edge('EXECUTION', 'VERIFICATION')\n",
        "router.add_edge('VERIFICATION', END)\n",
        "router.set_entry_point('PLANNER')\n",
        "workflow = router.compile()\n",
        "\n",
        "# — Run harness —\n",
        "def run_task(goal: str) -> State:\n",
        "    return workflow.invoke({'input': goal, 'plan': [], 'result': [], 'verifications': []})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tasks = [\n",
        "        \"Translate 'Hola, ¿cómo estás?' to english\",\n",
        "        \"Calculate 12 * 7\",\n",
        "        \"Analyze sentiment: I am so happy\",\n",
        "        \"What do you know?\"\n",
        "    ]\n",
        "    for goal in tasks:\n",
        "        st = run_task(goal)\n",
        "        print('\\n=== Task Summary ===')\n",
        "        print('Input:', st['input'])\n",
        "        print('\\nPlan:')\n",
        "        print(pd.DataFrame(st['plan'], columns=['Plan']).to_string(index=False), '\\n')\n",
        "        print('Results:')\n",
        "        print(pd.DataFrame(st['result']).to_string(index=False), '\\n')\n",
        "        print('Verifications:')\n",
        "        print(pd.DataFrame(st['verifications']).to_string(index=False), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sLY7F_dfbPO5",
        "xJEVtLkzj4Gt",
        "M-PR34eQfv1V",
        "Ks7Q5-uV1GZX"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00f2a74c56e6443a8d3550c8f3ecb9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e1a330a94b47a8b716d840818d467c",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60bdfc219fb443f7af0af0afabc9d455",
            "value": 189
          }
        },
        "01b4126830dc4f54b8972c87467e596a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027c490ce17e4b119b9107a070e9633a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752bbc57e61543eda632d5d0d07baacb",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebc99c6287fb4bb682d1758c52bd720a",
            "value": 9085657
          }
        },
        "041deba5e08649c18ce29976a6dc01b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160d4aabaecc4bb7a4d0b65e0148b8fa",
            "placeholder": "​",
            "style": "IPY_MODEL_f775e8e56d524c0381591d505c8e44fe",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 27.9MB/s]"
          }
        },
        "0523b16f4ff8430b87f22e8eff3a106b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0635f8a67dac458e9c01083c68f496ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "076c01e20ae34c3e9d0256fe2ec7081a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd3e859522764a4a89b924f5f22d71b6",
              "IPY_MODEL_6322a652148142d084a252d901213bc0",
              "IPY_MODEL_f28730bbf1b14685ac9d3331a1edbb6c"
            ],
            "layout": "IPY_MODEL_553fd4f7dfc042d98d9d193940b9218a"
          }
        },
        "07a33c5fd5c9416d823b95568b6795e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "092c548443dd400785b3037d11f26c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af4e7c616ef44289e4b66d31fcb8ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9152fc7baec4988a960adbcbab9001a",
            "placeholder": "​",
            "style": "IPY_MODEL_f2cf5d4a3c4b41c5861a1343a444bb37",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0b8f8edcf1c74672aac7c5b384d9e303": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd617d32f654e3c8caf79617d9475e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cf53efbd5a44412b5bf86ab49ff6219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0defc8ed7d9848109c81c10bce3e8dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0eaebcc421fa40abb0d6d33882dfe9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342dc63c654b452cb1fef1f7176d74c4",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c5d9ae541304ae3b5ba12f70650ac15",
            "value": 296
          }
        },
        "10662f6ab9b043248dfe28e759263c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10b9671347c148eaa22099f91a412e37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11dc43d3001f4eb2b8488a3bbc07b05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "132016c2eb634da6ae445e52ebb01244": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b947dc78cd944814996466b701ef9c79",
              "IPY_MODEL_c1bcbca1f48a402abad0fe4675528b0c",
              "IPY_MODEL_3cbd8e7dae8d4dbb9cec5e4dbd428eb7"
            ],
            "layout": "IPY_MODEL_468c361da9df4569a07aec6fe797813e"
          }
        },
        "13458e691bce4e559bc5fab08712a3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135af3971b134b91928c2f5dde27662e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156fe75e182f49119e74a928771e18ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160d4aabaecc4bb7a4d0b65e0148b8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160e3cccc5f54f9aa37e9d2c4f5561fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16e032370c514232a0f8e565ca0a352e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e1a330a94b47a8b716d840818d467c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e24ffbbc4b487ea6c8effe4cdd13f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1972fe14f83747a2a31e19242bfc2144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b35e39737084042baa7f30fc000bcbf",
              "IPY_MODEL_8c9220d775744b3b909d4c767ae5e800",
              "IPY_MODEL_392478b9fd204839b2edd2c8abb9964b"
            ],
            "layout": "IPY_MODEL_135af3971b134b91928c2f5dde27662e"
          }
        },
        "1a60b61062e149b3b9ba90d432fced2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbf38ef8ed254369a9c25aee8a21df4d",
              "IPY_MODEL_027c490ce17e4b119b9107a070e9633a",
              "IPY_MODEL_3b42166d080a44ddabd0e7c2256d0ba2"
            ],
            "layout": "IPY_MODEL_43853bce3e134304a560eaf4194b6dce"
          }
        },
        "1a640896c15f4b31bc6e18b9b58cbc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a86a3bb4a494e77a96fef5303c6666e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc562e6ad08468d9dc1510e1dcae481",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cd617d32f654e3c8caf79617d9475e8",
            "value": 4
          }
        },
        "1af3df3806534cf5bd8cd568c9ea738c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1af76a5387ac49bfb3b8e0ae26fd4ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77acea273143462d9f46be4dd5c4cfc0",
            "placeholder": "​",
            "style": "IPY_MODEL_42b8b32c1af347f19c76d39478b183f3",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 1.49MB/s]"
          }
        },
        "1b35e39737084042baa7f30fc000bcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710133641e1e4331a6b352bde8218ded",
            "placeholder": "​",
            "style": "IPY_MODEL_f5cf69e91b5e48b9b262ecebb62e76ed",
            "value": "Fetching 2 files: 100%"
          }
        },
        "1b6d9e4fedbf44efa3bea0ddf6c0a262": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc0bbc3531e46b3baf79d8fdf4580d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5d9ae541304ae3b5ba12f70650ac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ce6e3daddad4e3db6b3170362e4b772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d55036b07be4591bbe5ffb46f1e57e4",
              "IPY_MODEL_a4da4cfa5f0b46b482ed6f0eda1ee3b4",
              "IPY_MODEL_fc228261781d462698568e898a8b884b"
            ],
            "layout": "IPY_MODEL_26e280e34aab478d8ad5fd1d61e42de9"
          }
        },
        "1ea6f6e45ac04b80a96f27aa3b06e531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_fde27f29082b45729ea5ec4a0b314ea0"
          }
        },
        "216cde96870240dfb24a9469f63dfe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "216e525fdc0c49c6b026c783e3e46204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "252951f7c313483c82a6ba17f2a4c8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c6935d9b4d4633891cc3e6984941b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984d3d15533c4f6eba793a12f23ff31e",
            "placeholder": "​",
            "style": "IPY_MODEL_9494e7c04046400b85457f4c6b4c650b",
            "value": "generation_config.json: 100%"
          }
        },
        "25cd5f10a66f464c8069cee705c4b685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95230a32defa476fa5048a61ca7d60ac",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c344e6f00924c32aa94bbb10cdaa84c",
            "value": 878
          }
        },
        "26e280e34aab478d8ad5fd1d61e42de9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276ce81400874e239375508be694b566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ad67425f33144b7b3097a3bd4354f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1804ff9b82b4d18afef7c9dbd78a981",
            "placeholder": "​",
            "style": "IPY_MODEL_518ae6aa6970405cb70934cf18e966dc",
            "value": " 4/4 [01:13&lt;00:00, 15.48s/it]"
          }
        },
        "2bb5a6cfc9f74c4a859195417438f849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c02f8aa75a1484da36c4d1d8d2426a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce34b04c09c4eefb5a7ecc0bf5f16b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec5dd85624c47d0a359560740c8c0a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6d5899af9c4c13841b43cceaeef3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3029955fc3cb465da05451f6b0984c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3064a064898147ff90de97f2a48efcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f9ecfaff1f452bb2f9355a7a8e4b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_276ce81400874e239375508be694b566",
            "value": "tokenizer.json: 100%"
          }
        },
        "313138ee3e3e4e4386ca08d13df1b81b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33206f1e514e4ab8b52d3ad8c7dfab8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3945d5d8fc8d48daa28581e4d96cd9fe",
            "placeholder": "​",
            "style": "IPY_MODEL_8b40252f3ac14f69adf12b1c7c3d736e",
            "value": " 2/2 [00:39&lt;00:00, 39.88s/it]"
          }
        },
        "342dc63c654b452cb1fef1f7176d74c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b464c50e1c41549ac286f54ba1bd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35965ed47607478dbf1acb5779b03f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "392478b9fd204839b2edd2c8abb9964b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baeae91b7184482c83b2bc39780e9b03",
            "placeholder": "​",
            "style": "IPY_MODEL_8f25c30e7a5948f6991264d672e53474",
            "value": " 2/2 [01:02&lt;00:00, 62.59s/it]"
          }
        },
        "3929f076b095471d904034eb88c05fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3945d5d8fc8d48daa28581e4d96cd9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a116f4260f0404896e62e4400dfcaa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab8e68f63174cefbfdb1d6c5e4b92ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b42166d080a44ddabd0e7c2256d0ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a755aaacd948a7a8839e88149b73a5",
            "placeholder": "​",
            "style": "IPY_MODEL_74b7f562f5264fd0aa5ef5411f519f9a",
            "value": " 9.09M/9.09M [00:01&lt;00:00, 5.71MB/s]"
          }
        },
        "3c344e6f00924c32aa94bbb10cdaa84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c53da3fc3c144b1a4753e2412b5db62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cbd8e7dae8d4dbb9cec5e4dbd428eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d268415081492bab323dff1e946384",
            "placeholder": "​",
            "style": "IPY_MODEL_bc04fe1b6ec84fd8beed6a00e179f714",
            "value": " 1.46G/1.46G [00:16&lt;00:00, 98.0MB/s]"
          }
        },
        "3d55036b07be4591bbe5ffb46f1e57e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3f93b8265b452d8e14aad0617346cf",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f58c93c9024835a5f25b687f0bd317",
            "value": "config.json: 100%"
          }
        },
        "3fd84cb29d0c491688984aded8abca0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40192cbe8be7419c97927f02ff4107a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40d709ccd174468a995cc6e0603686c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4151aed2a9734a5582dbd7df78139bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7237a44037ed4256944dba035aa64471",
              "IPY_MODEL_1a86a3bb4a494e77a96fef5303c6666e",
              "IPY_MODEL_2ad67425f33144b7b3097a3bd4354f56"
            ],
            "layout": "IPY_MODEL_9e257f53910947eca7ee84b5a54c0f4c"
          }
        },
        "42b8b32c1af347f19c76d39478b183f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43853bce3e134304a560eaf4194b6dce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43874c1a2d2343d28f65bbca41558ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3171cfff82343eb9f7e0f98df8ee895",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0defc8ed7d9848109c81c10bce3e8dd4",
            "value": 2
          }
        },
        "4537074db99d429d8ba01d326f7a9eda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4563e95c2a8f40b1af8736f35f7a10df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45d268415081492bab323dff1e946384": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ecdf1d8bde4fa0ac0261d5706b10eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468c361da9df4569a07aec6fe797813e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4733f3f2c16940f0b3fe01bcca90518c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f18e3ab974498fb5b20dd12c271e1e",
            "placeholder": "​",
            "style": "IPY_MODEL_3c53da3fc3c144b1a4753e2412b5db62",
            "value": " 4.97G/4.97G [00:39&lt;00:00, 237MB/s]"
          }
        },
        "48ea7e77403f4ddaa805be7101b38319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c05d2a965e4414a581542a5943dc7e",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_216cde96870240dfb24a9469f63dfe4c",
            "value": 296
          }
        },
        "4a0ec43708e049a79909dcdcfc621395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5dc40a01b140c6bff16babf3a9a741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52fb30e2e5844fa69db2b1019513fe4e",
              "IPY_MODEL_fdae88c0fdf54688ac596de802bdbf60",
              "IPY_MODEL_fda49688c2f9438c8817a87900398225"
            ],
            "layout": "IPY_MODEL_529c2dad421140b58ef92f2f662fc633"
          }
        },
        "503b11916caa4939b3eb0e8156b92ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86d0d99926b47d8bd7698c5de0b5c3c",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83a3a4db0dcc41a49727f95ca08e7067",
            "value": 4965799096
          }
        },
        "518ae6aa6970405cb70934cf18e966dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a8d32261eb40faba1f986b1cd48b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba36e7f4aedc477482b2a9ca7195e977",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a33aa892ec9d44fc81a019585b872c63",
            "value": 20919
          }
        },
        "529c2dad421140b58ef92f2f662fc633": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fb30e2e5844fa69db2b1019513fe4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61cf6d2c5844effbe70ef31b7c992f9",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0c81a4455b48a7b725f524efaf8fd5",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "5352687422e848a3b15f05ee376f3616": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539c222985124410b05cd9d0cf11f215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548259078d2841c98d865ece13ce4030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553fd4f7dfc042d98d9d193940b9218a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55dbb2d8848e42de9dbd5666b85b758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc50f4b20e5847d6bd814210c751ac31",
              "IPY_MODEL_503b11916caa4939b3eb0e8156b92ed0",
              "IPY_MODEL_dfe4f7ad54444ff18e3c0d1a5c12e318"
            ],
            "layout": "IPY_MODEL_a7df713e8fbd49919c8a12a6b6e37f48"
          }
        },
        "57f67546f674410b8efc556432e961da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_814b36416625470887377ec92ecb9e3f",
              "IPY_MODEL_c57dd3c3be3c4ce9b93940984b0433af",
              "IPY_MODEL_b8ef3262cf4c47aeba2269afcd5b0d05"
            ],
            "layout": "IPY_MODEL_bff7049222c4457eb8f365bbdceeb29e"
          }
        },
        "59a6d93b7e2e430f8217a60fa9f641b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3064a064898147ff90de97f2a48efcb2",
              "IPY_MODEL_f19ee82dd4e146adbebcd67aee8b292d",
              "IPY_MODEL_041deba5e08649c18ce29976a6dc01b1"
            ],
            "layout": "IPY_MODEL_b333996217974f93840c4259608fac98"
          }
        },
        "5a9636b2d1c54e51abf0846a954c0ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc3fc4f11dc4dc59095194edfc60a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e035a1aad7e47b0a3359b0c2092ceec",
            "placeholder": "​",
            "style": "IPY_MODEL_16e032370c514232a0f8e565ca0a352e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "60bdfc219fb443f7af0af0afabc9d455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6322a652148142d084a252d901213bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c373de8cac4eba998ceee6a3f44bb8",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7b60e8fb278484bba84bbc181825bf6",
            "value": 1459729952
          }
        },
        "66074442522643e78e0906257ba3f272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66387a54837a4283bf79128b80523444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665ebce977f2475f8bfcf475868b310c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cff641cb82b94bc1917e501822b0cc11",
              "IPY_MODEL_af3fe804d76d4d25ac10eb43a9922651",
              "IPY_MODEL_33206f1e514e4ab8b52d3ad8c7dfab8d"
            ],
            "layout": "IPY_MODEL_d34b4af08460444b8211fc52ed6926b1"
          }
        },
        "6662c05d5f914d3991ce85179381681d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b745ce98d6459e850461a7e7a3a30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6765b6628c5d48deaf6c15d496648a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2364a15b5aa4d6fa8bb736295a3c4e8",
              "IPY_MODEL_43874c1a2d2343d28f65bbca41558ee2",
              "IPY_MODEL_fcab66aafa3243d0b70a11c95b508087"
            ],
            "layout": "IPY_MODEL_bb81da29489b4e97a47ce7b9162250eb"
          }
        },
        "6b2c858d4b1947bd8b692a7f6fbabda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb8b66413d7427dbd0c03ce245a8584",
            "placeholder": "​",
            "style": "IPY_MODEL_66074442522643e78e0906257ba3f272",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6c60944e9b1b4d3c9f0caa6798f7c607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca91b458e9f407f866cdf7d95b50223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cb8b66413d7427dbd0c03ce245a8584": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d24d762a5a14ef8957c3ba9b24f30ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc0bbc3531e46b3baf79d8fdf4580d9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af3df3806534cf5bd8cd568c9ea738c",
            "value": 2
          }
        },
        "6d82faf1a6904ddca44282a7ea7dd04b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f357b77a6034b4ea250b180c2b496a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f3f93b8265b452d8e14aad0617346cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c373de8cac4eba998ceee6a3f44bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710133641e1e4331a6b352bde8218ded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7151628435d84b789a08c5fa41b2568f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7237a44037ed4256944dba035aa64471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b12409746a86473eada4edb01cd5abfa",
            "placeholder": "​",
            "style": "IPY_MODEL_1a640896c15f4b31bc6e18b9b58cbc29",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7302ecc0cf2143d886b43ea08ec7c8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b7f562f5264fd0aa5ef5411f519f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "752bbc57e61543eda632d5d0d07baacb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f9ecfaff1f452bb2f9355a7a8e4b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7730fd7cbbf44f80a996ad49d347e6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a57217c14f41ff803b463fac4f9589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4a1321123bb4927985df361a36c0511",
              "IPY_MODEL_db5073e09eeb471e976ed76ff21db665",
              "IPY_MODEL_8d9d8c10de5e47fbb91dae20d4775f84"
            ],
            "layout": "IPY_MODEL_252951f7c313483c82a6ba17f2a4c8b5"
          }
        },
        "77acea273143462d9f46be4dd5c4cfc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b964f14456a4b57bf3d5bfb5cbdb721": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb12941bc10433eafd2fdcadd26487a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e035a1aad7e47b0a3359b0c2092ceec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec03e6f25cb49c9a5b162a1c9dfbdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f13359e5c2e48e3bdebd24f3876b083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f9290c5a1a54fe5b6ecdca3aa663a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2f8ad7635b4e5a81dd965796056622",
            "placeholder": "​",
            "style": "IPY_MODEL_9561acea8a7648dfa3fa1ff27b726a0a",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "803b6dbc1d7e44b78512b9293b7bff7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809ca645768047229cfb293dd6c36804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80f9b5d658444b1b8ea6adb6c32f085a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1328638f19428380db1b22e7a7291c",
            "placeholder": "​",
            "style": "IPY_MODEL_6f357b77a6034b4ea250b180c2b496a5",
            "value": "config.json: 100%"
          }
        },
        "814b36416625470887377ec92ecb9e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b9671347c148eaa22099f91a412e37",
            "placeholder": "​",
            "style": "IPY_MODEL_7f13359e5c2e48e3bdebd24f3876b083",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "832293f704934c0f9cbb2e93cc8e80e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523b16f4ff8430b87f22e8eff3a106b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b75be6c61944f56a8134655e1e45d0e",
            "value": "generation_config.json: 100%"
          }
        },
        "8323ae8af35b4d1b908073a7d19d20f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13458e691bce4e559bc5fab08712a3c7",
            "placeholder": "​",
            "style": "IPY_MODEL_4563e95c2a8f40b1af8736f35f7a10df",
            "value": " 122/122 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "83a3a4db0dcc41a49727f95ca08e7067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8430f8c37b3644cba5efed933701e339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875931cc2c954eea9b853f349bdc80ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88cfe2c399e74278b7003efffc30700a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b2c858d4b1947bd8b692a7f6fbabda4",
              "IPY_MODEL_0eaebcc421fa40abb0d6d33882dfe9b1",
              "IPY_MODEL_9239466fe1034184a37ca027f25339d6"
            ],
            "layout": "IPY_MODEL_5a9636b2d1c54e51abf0846a954c0ddb"
          }
        },
        "8950c606519d41148468bc6b670c08af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6e76cf76d14a1ea5844a9ba17ee25c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aec626266cd4c64ad2f10b6ee20bc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25c6935d9b4d4633891cc3e6984941b8",
              "IPY_MODEL_e4f975613a294c08a506f6d307bee40d",
              "IPY_MODEL_8323ae8af35b4d1b908073a7d19d20f2"
            ],
            "layout": "IPY_MODEL_f90bb79b745942e887d1b03e2700379a"
          }
        },
        "8b40252f3ac14f69adf12b1c7c3d736e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b858d02623a4a6b9911ef4c97e4dcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80f9b5d658444b1b8ea6adb6c32f085a",
              "IPY_MODEL_25cd5f10a66f464c8069cee705c4b685",
              "IPY_MODEL_d974fa183863484a9304460b95fcd8cb"
            ],
            "layout": "IPY_MODEL_c3feaacb507b4d2b86b563fe8c21a88b"
          }
        },
        "8c9220d775744b3b909d4c767ae5e800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2ebe06a5f1497b97703efc90338912",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_216e525fdc0c49c6b026c783e3e46204",
            "value": 2
          }
        },
        "8d3c926a8a764cb4bbfefe88c63fe0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc42c94ceaad4ef48bb9ae4e5d408c41",
              "IPY_MODEL_962fa279640f4a43aaf2dff7e40a47f1",
              "IPY_MODEL_e9fb2cb99c46481b932f0b538854aea0"
            ],
            "layout": "IPY_MODEL_8a6e76cf76d14a1ea5844a9ba17ee25c"
          }
        },
        "8d9d8c10de5e47fbb91dae20d4775f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b4e3b7df04441082da89c8f3700a93",
            "placeholder": "​",
            "style": "IPY_MODEL_7151628435d84b789a08c5fa41b2568f",
            "value": " 189/189 [00:00&lt;00:00, 11.6kB/s]"
          }
        },
        "8f25c30e7a5948f6991264d672e53474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "907f7fa9a2764b1594d0987334491d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4537074db99d429d8ba01d326f7a9eda",
            "placeholder": "​",
            "style": "IPY_MODEL_092c548443dd400785b3037d11f26c0b",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "91508574c043447186cae2cbf2c71f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91908f93c55d42ec98f890c83a00b05e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9239466fe1034184a37ca027f25339d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b964f14456a4b57bf3d5bfb5cbdb721",
            "placeholder": "​",
            "style": "IPY_MODEL_c01c9801b1fb4efc819bf791a935e84c",
            "value": " 296/296 [00:00&lt;00:00, 26.4kB/s]"
          }
        },
        "9494e7c04046400b85457f4c6b4c650b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95230a32defa476fa5048a61ca7d60ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9561acea8a7648dfa3fa1ff27b726a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "962fa279640f4a43aaf2dff7e40a47f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e898c4b5086b4559b879a9f865c9841e",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ca91b458e9f407f866cdf7d95b50223",
            "value": 54528
          }
        },
        "965410f83f7d42d6b1c29d19e29c8ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984d3d15533c4f6eba793a12f23ff31e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f18e3ab974498fb5b20dd12c271e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991239566f2241a69f3a532190531eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b3c93f14354db19c5cf2b619640a45",
            "placeholder": "​",
            "style": "IPY_MODEL_b74817eaff2641018feaaf699b89b1f3",
            "value": " 2/2 [00:25&lt;00:00, 11.70s/it]"
          }
        },
        "9b2ebe06a5f1497b97703efc90338912": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5e3be3609b4781bd6b8fdd23590374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f9290c5a1a54fe5b6ecdca3aa663a03",
              "IPY_MODEL_a5e8b6d12cfc4413890ceda96f3194d2",
              "IPY_MODEL_4733f3f2c16940f0b3fe01bcca90518c"
            ],
            "layout": "IPY_MODEL_fca5ed9efc4842039e4e9338996ebf0f"
          }
        },
        "9b75be6c61944f56a8134655e1e45d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9daefeb18fbf47e5a367ff415f68a45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_832293f704934c0f9cbb2e93cc8e80e2",
              "IPY_MODEL_00f2a74c56e6443a8d3550c8f3ecb9cc",
              "IPY_MODEL_c9a68a01c90b44f1a8b1f4cf3e5e27f2"
            ],
            "layout": "IPY_MODEL_2f6d5899af9c4c13841b43cceaeef3b7"
          }
        },
        "9e257f53910947eca7ee84b5a54c0f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b4e3b7df04441082da89c8f3700a93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ec2c7f22c34f8e8f8b180879bc2f32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2cb4f687daf497293ac49d566990790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3171cfff82343eb9f7e0f98df8ee895": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33aa892ec9d44fc81a019585b872c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3a618a0684c4852945dadc809e94d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4da4cfa5f0b46b482ed6f0eda1ee3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7302ecc0cf2143d886b43ea08ec7c8e1",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe51aa205b04a80a15852c5636a5a4c",
            "value": 878
          }
        },
        "a5e8b6d12cfc4413890ceda96f3194d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26729ca0e724b6f9c7223a01b0e1c2f",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0635f8a67dac458e9c01083c68f496ce",
            "value": 4965799096
          }
        },
        "a629ea89636640a0bc8ff5999fc34a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8430f8c37b3644cba5efed933701e339",
            "placeholder": "​",
            "style": "IPY_MODEL_07a33c5fd5c9416d823b95568b6795e3",
            "value": " 296/296 [00:00&lt;00:00, 26.6kB/s]"
          }
        },
        "a7df713e8fbd49919c8a12a6b6e37f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84e2e98134a4cdcb84f7d6a085afdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aacacfe42c5a4a33abda4d63f636de9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5160a9de63459f9a4fe0cfb3b99a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1cf97c6d7e4d45ac37eefdeabf49fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af3fe804d76d4d25ac10eb43a9922651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3029955fc3cb465da05451f6b0984c3a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d66b008d61f24eff8ad06e071006241b",
            "value": 2
          }
        },
        "b12409746a86473eada4edb01cd5abfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1804ff9b82b4d18afef7c9dbd78a981": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2364a15b5aa4d6fa8bb736295a3c4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7730fd7cbbf44f80a996ad49d347e6f5",
            "placeholder": "​",
            "style": "IPY_MODEL_a84e2e98134a4cdcb84f7d6a085afdbf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b333996217974f93840c4259608fac98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ed49941df248d58c35508b56e8f699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6d82faf1a6904ddca44282a7ea7dd04b",
            "style": "IPY_MODEL_3929f076b095471d904034eb88c05fbf",
            "tooltip": ""
          }
        },
        "b74817eaff2641018feaaf699b89b1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e82b6d4a5f42139065c96d1b0e8862": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ef3262cf4c47aeba2269afcd5b0d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6662c05d5f914d3991ce85179381681d",
            "placeholder": "​",
            "style": "IPY_MODEL_7bb12941bc10433eafd2fdcadd26487a",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 4.73MB/s]"
          }
        },
        "b947dc78cd944814996466b701ef9c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aacacfe42c5a4a33abda4d63f636de9e",
            "placeholder": "​",
            "style": "IPY_MODEL_af1cf97c6d7e4d45ac37eefdeabf49fc",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "ba2c6daa79fc4ee7998f136950f95637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba36e7f4aedc477482b2a9ca7195e977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baeae91b7184482c83b2bc39780e9b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb81da29489b4e97a47ce7b9162250eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe2fe809e1a43f1a1bf18d914552911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf38ef8ed254369a9c25aee8a21df4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb5a6cfc9f74c4a859195417438f849",
            "placeholder": "​",
            "style": "IPY_MODEL_45ecdf1d8bde4fa0ac0261d5706b10eb",
            "value": "tokenizer.json: 100%"
          }
        },
        "bc04fe1b6ec84fd8beed6a00e179f714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc42c94ceaad4ef48bb9ae4e5d408c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b4126830dc4f54b8972c87467e596a",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a3b1ee488847a7857c29da93ce3ed5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bf2f8ad7635b4e5a81dd965796056622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff7049222c4457eb8f365bbdceeb29e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c01c9801b1fb4efc819bf791a935e84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c086f329d5344149a630881df762358f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a3b1ee488847a7857c29da93ce3ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bcbca1f48a402abad0fe4675528b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5352687422e848a3b15f05ee376f3616",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7183a51bc934036919b5f0b8eb6b579",
            "value": 1459729952
          }
        },
        "c1f58c93c9024835a5f25b687f0bd317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3feaacb507b4d2b86b563fe8c21a88b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c515b82692bd4046aedf3b766fbf7d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec5dd85624c47d0a359560740c8c0a6",
            "placeholder": "​",
            "style": "IPY_MODEL_35965ed47607478dbf1acb5779b03f44",
            "value": "Connecting..."
          }
        },
        "c57dd3c3be3c4ce9b93940984b0433af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b8f8edcf1c74672aac7c5b384d9e303",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10662f6ab9b043248dfe28e759263c29",
            "value": 54528
          }
        },
        "c9a68a01c90b44f1a8b1f4cf3e5e27f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ec2c7f22c34f8e8f8b180879bc2f32",
            "placeholder": "​",
            "style": "IPY_MODEL_dec725ab2172452581dcbf6f3c789e92",
            "value": " 189/189 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "cc1328638f19428380db1b22e7a7291c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc50f4b20e5847d6bd814210c751ac31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab8e68f63174cefbfdb1d6c5e4b92ce",
            "placeholder": "​",
            "style": "IPY_MODEL_f8a6069ac40e485b9e778c756a29a50b",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "cdc562e6ad08468d9dc1510e1dcae481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0c81a4455b48a7b725f524efaf8fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe51aa205b04a80a15852c5636a5a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cff641cb82b94bc1917e501822b0cc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91908f93c55d42ec98f890c83a00b05e",
            "placeholder": "​",
            "style": "IPY_MODEL_e792b7ea2df74339bc169a44f2806c1d",
            "value": "Fetching 2 files: 100%"
          }
        },
        "d23783c7d0a742be83768e98fb5f9c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6ef8f783b64cd5a5595462f6273efb",
              "IPY_MODEL_51a8d32261eb40faba1f986b1cd48b6d",
              "IPY_MODEL_1af76a5387ac49bfb3b8e0ae26fd4ea4"
            ],
            "layout": "IPY_MODEL_4a0ec43708e049a79909dcdcfc621395"
          }
        },
        "d26729ca0e724b6f9c7223a01b0e1c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34b4af08460444b8211fc52ed6926b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a1321123bb4927985df361a36c0511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548259078d2841c98d865ece13ce4030",
            "placeholder": "​",
            "style": "IPY_MODEL_a2cb4f687daf497293ac49d566990790",
            "value": "generation_config.json: 100%"
          }
        },
        "d66b008d61f24eff8ad06e071006241b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9152fc7baec4988a960adbcbab9001a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d974fa183863484a9304460b95fcd8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c086f329d5344149a630881df762358f",
            "placeholder": "​",
            "style": "IPY_MODEL_875931cc2c954eea9b853f349bdc80ed",
            "value": " 878/878 [00:00&lt;00:00, 64.6kB/s]"
          }
        },
        "db34d8998a464fdc8a1f555b98cf634a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db5073e09eeb471e976ed76ff21db665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803b6dbc1d7e44b78512b9293b7bff7d",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad5160a9de63459f9a4fe0cfb3b99a37",
            "value": 189
          }
        },
        "dc357fffea2f4d5b8d2576ad6d126dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_313138ee3e3e4e4386ca08d13df1b81b",
            "style": "IPY_MODEL_7ec03e6f25cb49c9a5b162a1c9dfbdbf",
            "value": true
          }
        },
        "dd3e859522764a4a89b924f5f22d71b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3dd3015602f485d99cb81d34290e380",
            "placeholder": "​",
            "style": "IPY_MODEL_18e24ffbbc4b487ea6c8effe4cdd13f9",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "de13f1e46e3a469294c3b2e432d59305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3a116f4260f0404896e62e4400dfcaa6",
            "placeholder": "​",
            "style": "IPY_MODEL_809ca645768047229cfb293dd6c36804",
            "value": ""
          }
        },
        "de1ce5c6c5d9495d90dc6756a08048fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0af4e7c616ef44289e4b66d31fcb8ff2",
              "IPY_MODEL_6d24d762a5a14ef8957c3ba9b24f30ae",
              "IPY_MODEL_991239566f2241a69f3a532190531eb3"
            ],
            "layout": "IPY_MODEL_156fe75e182f49119e74a928771e18ca"
          }
        },
        "dec725ab2172452581dcbf6f3c789e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfe4f7ad54444ff18e3c0d1a5c12e318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965410f83f7d42d6b1c29d19e29c8ed6",
            "placeholder": "​",
            "style": "IPY_MODEL_0cf53efbd5a44412b5bf86ab49ff6219",
            "value": " 4.97G/4.97G [01:02&lt;00:00, 118MB/s]"
          }
        },
        "e1a9a13c528740c5b2522d336f21b07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f08f5a19669a457bb93e8a65570a3e11",
              "IPY_MODEL_48ea7e77403f4ddaa805be7101b38319",
              "IPY_MODEL_a629ea89636640a0bc8ff5999fc34a4b"
            ],
            "layout": "IPY_MODEL_8950c606519d41148468bc6b670c08af"
          }
        },
        "e3f49973616042c9ae191fcc640c1db2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f975613a294c08a506f6d307bee40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91508574c043447186cae2cbf2c71f48",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3a618a0684c4852945dadc809e94d7e",
            "value": 122
          }
        },
        "e7183a51bc934036919b5f0b8eb6b579": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e792b7ea2df74339bc169a44f2806c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86d0d99926b47d8bd7698c5de0b5c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e898c4b5086b4559b879a9f865c9841e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fb2cb99c46481b932f0b538854aea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f49973616042c9ae191fcc640c1db2",
            "placeholder": "​",
            "style": "IPY_MODEL_34b464c50e1c41549ac286f54ba1bd56",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 4.18MB/s]"
          }
        },
        "ebc99c6287fb4bb682d1758c52bd720a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f08f5a19669a457bb93e8a65570a3e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c02f8aa75a1484da36c4d1d8d2426a7",
            "placeholder": "​",
            "style": "IPY_MODEL_40192cbe8be7419c97927f02ff4107a6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f19ee82dd4e146adbebcd67aee8b292d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c60944e9b1b4d3c9f0caa6798f7c607",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_160e3cccc5f54f9aa37e9d2c4f5561fd",
            "value": 9085657
          }
        },
        "f28730bbf1b14685ac9d3331a1edbb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66387a54837a4283bf79128b80523444",
            "placeholder": "​",
            "style": "IPY_MODEL_bbe2fe809e1a43f1a1bf18d914552911",
            "value": " 1.46G/1.46G [00:32&lt;00:00, 98.5MB/s]"
          }
        },
        "f2cf5d4a3c4b41c5861a1343a444bb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3dd3015602f485d99cb81d34290e380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5cf69e91b5e48b9b262ecebb62e76ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f61cf6d2c5844effbe70ef31b7c992f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f775e8e56d524c0381591d505c8e44fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7a755aaacd948a7a8839e88149b73a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b60e8fb278484bba84bbc181825bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7c05d2a965e4414a581542a5943dc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a6069ac40e485b9e778c756a29a50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f90bb79b745942e887d1b03e2700379a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b3c93f14354db19c5cf2b619640a45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc228261781d462698568e898a8b884b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd84cb29d0c491688984aded8abca0c",
            "placeholder": "​",
            "style": "IPY_MODEL_11dc43d3001f4eb2b8488a3bbc07b05a",
            "value": " 878/878 [00:00&lt;00:00, 103kB/s]"
          }
        },
        "fca5ed9efc4842039e4e9338996ebf0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcab66aafa3243d0b70a11c95b508087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e82b6d4a5f42139065c96d1b0e8862",
            "placeholder": "​",
            "style": "IPY_MODEL_539c222985124410b05cd9d0cf11f215",
            "value": " 2/2 [00:30&lt;00:00, 13.88s/it]"
          }
        },
        "fd6ef8f783b64cd5a5595462f6273efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d709ccd174468a995cc6e0603686c7",
            "placeholder": "​",
            "style": "IPY_MODEL_ba2c6daa79fc4ee7998f136950f95637",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "fda49688c2f9438c8817a87900398225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce34b04c09c4eefb5a7ecc0bf5f16b2",
            "placeholder": "​",
            "style": "IPY_MODEL_66b745ce98d6459e850461a7e7a3a30d",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 1.52MB/s]"
          }
        },
        "fdae88c0fdf54688ac596de802bdbf60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6d9e4fedbf44efa3bea0ddf6c0a262",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db34d8998a464fdc8a1f555b98cf634a",
            "value": 20919
          }
        },
        "fde27f29082b45729ea5ec4a0b314ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
